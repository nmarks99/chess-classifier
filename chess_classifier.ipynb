{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "66240b07-f98d-4443-aa2b-855c9ab2f5a9",
        "_uuid": "bb0e65ca-ab55-4d15-a6e0-bc6a040fa868",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.079316Z",
          "iopub.status.busy": "2022-03-14T16:24:57.078588Z",
          "iopub.status.idle": "2022-03-14T16:24:57.084741Z",
          "shell.execute_reply": "2022-03-14T16:24:57.083768Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.079255Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "augyEluuEX8E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "66dafa92-4c17-4e67-abda-cfbedcf6b794",
        "_uuid": "fc94861b-96c3-4083-a1cd-b8d84c1e1c0a",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.087033Z",
          "iopub.status.busy": "2022-03-14T16:24:57.08675Z",
          "iopub.status.idle": "2022-03-14T16:24:57.106857Z",
          "shell.execute_reply": "2022-03-14T16:24:57.106144Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.086997Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp3BxLB2EX8K",
        "outputId": "0ca059c9-e13f-4c61-d475-516bbf9769d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup torch device, using GPU if its available \n",
        "# Training with the CPU on my laptop is very very slow, so using a GPU with Google colab is preferred\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    warnings.warn(\"It is recommended to use train on a GPU, perhaps through Google colab, for performance\")\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "To begin, we will start by importing the data. The dataset used in this project was found on Kaggle ([link](https://www.kaggle.com/datasets/anshulmehtakaggl/chess-pieces-detection-images-dataset)) and contains labelled images of chess pieces, including both digital and real images. This is good since I would like my model to have the ability to classify images of chess pieces from online games and well as live over-the-board chess games.\n",
        "\n",
        "The code below imports the data from a chess_pieces directory in the same directory and this project, and separates it into training and validation data. It then creates PyTorch DataLoader objects from the data to be used later on. At this point, this is mostly \"boilerplate\" PyTorch."
      ],
      "metadata": {
        "id": "Cm2fTDo4yoJi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforming the Data\n",
        "Some transformations were applied to the data before proceeding which seek to improve the model's ability to classify the images, and make things easier later on. Here I have chosen to apply the RandomHorizontalFlip and RandomRotation transforms. The ToTensor transform is just necessary for using PyTorch."
      ],
      "metadata": {
        "id": "iPONYcoqz5r2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l2LSvAUvEX8N"
      },
      "outputs": [],
      "source": [
        "# Define transformations for training\n",
        "input_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p = 0.4),\n",
        "    transforms.RandomRotation(30),\n",
        "    #transforms.Normalize((0.5, 0.5 ,0.5), (0.5, 0.5 ,0.5))    \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf chess_pieces/.ipynb_checkpoints/"
      ],
      "metadata": {
        "id": "PTEaiPQyLTpU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4aH9UzJ0EX8P"
      },
      "outputs": [],
      "source": [
        "# Load in the dataset\n",
        "dataset_path = \"/content/chess_pieces\"\n",
        "dataset = ImageFolder(dataset_path, transform=input_transforms)\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(\n",
        "    dataset,\n",
        "    [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)]\n",
        ")\n",
        "\n",
        "val_data, test_data = torch.utils.data.random_split(\n",
        "    val_data,\n",
        "    [int(len(val_data)*0.8), len(val_data) - int(len(val_data)*0.8)]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 16, shuffle = True)\n",
        "val_loader = DataLoader(val_data, batch_size = 16, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 1, shuffle = True)\n",
        "test_loader_ordered = DataLoader(test_data, batch_size = 1, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining a Model\n",
        "Throughout our machine learning studies this quarter, we have not discussed deep learning, seeing as that is the topic of next quarter, however, in order to obtain reasonable results for a wide range of chess pieces, I have decided to use a convolutional neural network (CNN) for the model. This is because CNNs are notoriously good at classifying images and although we didn't learn much about them, many of the topics we did learn about still apply. \n",
        "\n",
        "To implement a CNN in PyTorch, we define a Python class that inherits from the nn.Module class. In this case, I have chosen to use the resnet50 model from the torchvision library. Although the mathematics behind this model (a residual neural network, which is a special case of a convolutional neural network) is beyond the scope of my understanding and our EE475 course, I have chosen to use it since implementing it with PyTorch was no more difficult that using another type of model, and residual neural networks have shown to be extremely good at classifying images. "
      ],
      "metadata": {
        "id": "wmfjjGtu1VZF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "_cell_guid": "4db1772a-4fc5-48c2-97cc-b00f0e418c20",
        "_uuid": "a6644ddf-144b-4d36-a0e2-8e9a87bd93b4",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.108527Z",
          "iopub.status.busy": "2022-03-14T16:24:57.108271Z",
          "iopub.status.idle": "2022-03-14T16:24:57.115135Z",
          "shell.execute_reply": "2022-03-14T16:24:57.11424Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.108493Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "UGBXb8MYEX8Q"
      },
      "outputs": [],
      "source": [
        "# Define a neural network as a class that inherits from the torch.nn.Module class \n",
        "class ChessCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessCNN, self).__init__()\n",
        "\n",
        "        # use ResNet, a deep neural network model, which is particularly good for image classification\n",
        "        self.model = torchvision.models.resnet50(pretrained = True)\n",
        "\n",
        "        for parameter in self.model.parameters():\n",
        "            parameter.requires_grad = False\n",
        "\n",
        "        # Define the model of each layer TODO: is this correct?\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 5)\n",
        "        )\n",
        "\n",
        "    # forward propogation step\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Training Parameters\n",
        "The model is first instantiated for later use, then we define several parameters like the learning rate, number of iterations, the optimizer that we will use, and the loss function. \n",
        "\n",
        "**Learning Rate**\n",
        "\n",
        "Here we set the learning rate to 0.00001. This was chosen after testing several learning rates both higher and lower. Higher learning rates result in faster training, however the loss oscillates or doesn't reach as small a value. An even smaller learning rate may be better, however I have access to only a limited amount of computing power (GPU access through Google Colab) so this learning rate is sufficient for this project.\n",
        "\n",
        "**Number of iterations**\n",
        "The number of iterations was chosen mostly because of time considerations but also and you can see from the output of the training step later on, after several hundred iterations, there are very few new best weights that are found that make the loss function any smaller. \n",
        "\n",
        "**Optimizer**\n",
        "\n"
      ],
      "metadata": {
        "id": "cDbqlC2A4l8B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "_cell_guid": "d1600f55-ba5f-431f-b183-db612f9dac68",
        "_uuid": "66e06d27-17d7-4244-9e28-8979c52c791a",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:59.750758Z",
          "iopub.status.busy": "2022-03-14T16:29:59.750106Z",
          "iopub.status.idle": "2022-03-14T16:30:00.282854Z",
          "shell.execute_reply": "2022-03-14T16:30:00.28215Z",
          "shell.execute_reply.started": "2022-03-14T16:29:59.750683Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egaO9oxAEX8S",
        "outputId": "1fefed72-a962-4507-cc55-33246f5f42ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChessCNN(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=1000, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "model = ChessCNN() # instantiate the neural net class\n",
        "# learning_rate = 0.00001 # define the learning rate\n",
        "learning_rate = 0.001\n",
        "max_its = 1000 \n",
        "\n",
        "# Define the optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.001)\n",
        "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.01)\n",
        "\n",
        "# Define the loss function\n",
        "loss_func = nn.CrossEntropyLoss() # use cross entropy loss function\n",
        "min_loss = np.inf\n",
        "model.to(device) # set model to use the appropriate defice (GPU or CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "_cell_guid": "7e11bfe7-4a3a-449f-b9a5-6daa591956f1",
        "_uuid": "d2af0b73-a6f0-48a9-a844-d3b454eb6985",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:38.98681Z",
          "iopub.status.busy": "2022-03-14T16:29:38.986272Z",
          "iopub.status.idle": "2022-03-14T16:29:38.99915Z",
          "shell.execute_reply": "2022-03-14T16:29:38.998375Z",
          "shell.execute_reply.started": "2022-03-14T16:29:38.986771Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "8pWcNsNGEX8U"
      },
      "outputs": [],
      "source": [
        "def train(model, max_its, min_loss):\n",
        "    for step in range(max_its):\n",
        "        training_loss = 0\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            yhat = model(images)\n",
        "            loss = loss_func(yhat, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.item()\n",
        "            \n",
        "            del images, labels\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "\n",
        "        valid_loss = 0\n",
        "        valid_accuracy = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                yhat = model(images)\n",
        "                loss = loss_func(yhat, labels)\n",
        "                valid_loss += loss.item()\n",
        "                yhat = nn.Softmax(dim = 1)(yhat)\n",
        "                top_p, top_class = yhat.topk(1, dim = 1)\n",
        "                num_correct = top_class == labels.view(-1,1)\n",
        "                valid_accuracy += num_correct.sum().item()\n",
        "\n",
        "                del(images)\n",
        "                del(labels)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # print(\"Step: {} \\tTraining loss: {:.4f} \\tValidation loss: {:.4f} \\tAccuracy: {:.2f}%\".format(step, training_loss, valid_loss, (valid_accuracy/len(val_data))*100))\n",
        "        print(f\"Step: {step} \\tTraining loss: {training_loss:.4f} \\tValidation loss: {valid_loss:.4f} \\tAccuracy: {valid_accuracy/len(val_data)*100:.2f}%\")\n",
        "\n",
        "        # whenever a new minimum loss for the model is found replace the previous best model\n",
        "        if valid_loss <= min_loss:\n",
        "            print(f\"New minumum loss found! = {valid_loss:.4f}\\tSaving model...\")\n",
        "            torch.save(model.state_dict(), \"trained_model.pt\")\n",
        "            min_loss = valid_loss # set new minumum loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "Running the cell below will begin the training process. This can be very slow, especially on an average CPU. Therefore, to train the model I have chosen to use Google Colab which offers free (but limited) GPU usage."
      ],
      "metadata": {
        "id": "GrIoWzMi-nBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "390812cb-c782-49ea-a31f-9e02f66b696f",
        "_uuid": "0a81eef0-af1a-4588-bd0c-5adadc3e6d02",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:39.587801Z",
          "iopub.status.busy": "2022-03-14T16:29:39.587267Z",
          "iopub.status.idle": "2022-03-14T16:29:48.921548Z",
          "shell.execute_reply": "2022-03-14T16:29:48.92036Z",
          "shell.execute_reply.started": "2022-03-14T16:29:39.587756Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXbpKApuEX8W",
        "outputId": "33daa680-d1c5-4be3-e6d1-a91bc2c726a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0 \tTraining loss: 52.5991 \tValidation loss: 11.1866 \tAccuracy: 19.23%\n",
            "New minumum loss found! = 11.1866\tSaving model...\n",
            "Step: 1 \tTraining loss: 52.0676 \tValidation loss: 11.0467 \tAccuracy: 23.08%\n",
            "New minumum loss found! = 11.0467\tSaving model...\n",
            "Step: 2 \tTraining loss: 51.5682 \tValidation loss: 10.9403 \tAccuracy: 24.04%\n",
            "New minumum loss found! = 10.9403\tSaving model...\n",
            "Step: 3 \tTraining loss: 51.3615 \tValidation loss: 11.0087 \tAccuracy: 23.08%\n",
            "Step: 4 \tTraining loss: 51.0128 \tValidation loss: 10.9905 \tAccuracy: 24.04%\n",
            "Step: 5 \tTraining loss: 50.5236 \tValidation loss: 10.8132 \tAccuracy: 23.08%\n",
            "New minumum loss found! = 10.8132\tSaving model...\n",
            "Step: 6 \tTraining loss: 50.4258 \tValidation loss: 10.8142 \tAccuracy: 26.92%\n",
            "Step: 7 \tTraining loss: 50.0904 \tValidation loss: 10.7325 \tAccuracy: 30.77%\n",
            "New minumum loss found! = 10.7325\tSaving model...\n",
            "Step: 8 \tTraining loss: 50.0430 \tValidation loss: 10.6826 \tAccuracy: 33.65%\n",
            "New minumum loss found! = 10.6826\tSaving model...\n",
            "Step: 9 \tTraining loss: 49.6718 \tValidation loss: 10.6526 \tAccuracy: 30.77%\n",
            "New minumum loss found! = 10.6526\tSaving model...\n",
            "Step: 10 \tTraining loss: 49.4147 \tValidation loss: 10.6455 \tAccuracy: 35.58%\n",
            "New minumum loss found! = 10.6455\tSaving model...\n",
            "Step: 11 \tTraining loss: 49.1774 \tValidation loss: 10.5632 \tAccuracy: 33.65%\n",
            "New minumum loss found! = 10.5632\tSaving model...\n",
            "Step: 12 \tTraining loss: 48.9922 \tValidation loss: 10.5605 \tAccuracy: 39.42%\n",
            "New minumum loss found! = 10.5605\tSaving model...\n",
            "Step: 13 \tTraining loss: 48.4251 \tValidation loss: 10.4538 \tAccuracy: 34.62%\n",
            "New minumum loss found! = 10.4538\tSaving model...\n",
            "Step: 14 \tTraining loss: 48.3065 \tValidation loss: 10.5246 \tAccuracy: 37.50%\n",
            "Step: 15 \tTraining loss: 47.8282 \tValidation loss: 10.4609 \tAccuracy: 40.38%\n",
            "Step: 16 \tTraining loss: 47.6092 \tValidation loss: 10.4209 \tAccuracy: 39.42%\n",
            "New minumum loss found! = 10.4209\tSaving model...\n",
            "Step: 17 \tTraining loss: 47.6498 \tValidation loss: 10.4091 \tAccuracy: 40.38%\n",
            "New minumum loss found! = 10.4091\tSaving model...\n",
            "Step: 18 \tTraining loss: 47.1031 \tValidation loss: 10.1646 \tAccuracy: 41.35%\n",
            "New minumum loss found! = 10.1646\tSaving model...\n",
            "Step: 19 \tTraining loss: 46.9132 \tValidation loss: 10.2492 \tAccuracy: 41.35%\n",
            "Step: 20 \tTraining loss: 46.6145 \tValidation loss: 10.1002 \tAccuracy: 49.04%\n",
            "New minumum loss found! = 10.1002\tSaving model...\n",
            "Step: 21 \tTraining loss: 46.2962 \tValidation loss: 10.1900 \tAccuracy: 46.15%\n",
            "Step: 22 \tTraining loss: 45.5970 \tValidation loss: 10.0529 \tAccuracy: 44.23%\n",
            "New minumum loss found! = 10.0529\tSaving model...\n",
            "Step: 23 \tTraining loss: 45.6977 \tValidation loss: 10.1017 \tAccuracy: 50.00%\n",
            "Step: 24 \tTraining loss: 45.8881 \tValidation loss: 9.9260 \tAccuracy: 46.15%\n",
            "New minumum loss found! = 9.9260\tSaving model...\n",
            "Step: 25 \tTraining loss: 45.3283 \tValidation loss: 10.0050 \tAccuracy: 51.92%\n",
            "Step: 26 \tTraining loss: 45.1128 \tValidation loss: 9.8046 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.8046\tSaving model...\n",
            "Step: 27 \tTraining loss: 44.4795 \tValidation loss: 9.7845 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.7845\tSaving model...\n",
            "Step: 28 \tTraining loss: 44.3956 \tValidation loss: 9.7843 \tAccuracy: 52.88%\n",
            "New minumum loss found! = 9.7843\tSaving model...\n",
            "Step: 29 \tTraining loss: 44.0264 \tValidation loss: 9.7751 \tAccuracy: 55.77%\n",
            "New minumum loss found! = 9.7751\tSaving model...\n",
            "Step: 30 \tTraining loss: 44.0840 \tValidation loss: 9.7928 \tAccuracy: 48.08%\n",
            "Step: 31 \tTraining loss: 43.8021 \tValidation loss: 9.6741 \tAccuracy: 55.77%\n",
            "New minumum loss found! = 9.6741\tSaving model...\n",
            "Step: 32 \tTraining loss: 43.3347 \tValidation loss: 9.4852 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.4852\tSaving model...\n",
            "Step: 33 \tTraining loss: 42.7415 \tValidation loss: 9.3649 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.3649\tSaving model...\n",
            "Step: 34 \tTraining loss: 42.9762 \tValidation loss: 9.4923 \tAccuracy: 54.81%\n",
            "Step: 35 \tTraining loss: 42.3717 \tValidation loss: 9.4160 \tAccuracy: 56.73%\n",
            "Step: 36 \tTraining loss: 41.8444 \tValidation loss: 9.3751 \tAccuracy: 59.62%\n",
            "Step: 37 \tTraining loss: 41.7260 \tValidation loss: 9.4366 \tAccuracy: 50.96%\n",
            "Step: 38 \tTraining loss: 41.8472 \tValidation loss: 9.3115 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 9.3115\tSaving model...\n",
            "Step: 39 \tTraining loss: 41.3333 \tValidation loss: 9.3717 \tAccuracy: 52.88%\n",
            "Step: 40 \tTraining loss: 41.1596 \tValidation loss: 9.2649 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.2649\tSaving model...\n",
            "Step: 41 \tTraining loss: 40.7539 \tValidation loss: 9.1197 \tAccuracy: 50.96%\n",
            "New minumum loss found! = 9.1197\tSaving model...\n",
            "Step: 42 \tTraining loss: 40.2026 \tValidation loss: 9.0209 \tAccuracy: 58.65%\n",
            "New minumum loss found! = 9.0209\tSaving model...\n",
            "Step: 43 \tTraining loss: 40.1832 \tValidation loss: 9.1366 \tAccuracy: 52.88%\n",
            "Step: 44 \tTraining loss: 39.8085 \tValidation loss: 9.0666 \tAccuracy: 54.81%\n",
            "Step: 45 \tTraining loss: 39.4757 \tValidation loss: 9.0408 \tAccuracy: 59.62%\n",
            "Step: 46 \tTraining loss: 39.2347 \tValidation loss: 8.9293 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.9293\tSaving model...\n",
            "Step: 47 \tTraining loss: 39.1563 \tValidation loss: 8.7611 \tAccuracy: 56.73%\n",
            "New minumum loss found! = 8.7611\tSaving model...\n",
            "Step: 48 \tTraining loss: 38.6258 \tValidation loss: 9.1302 \tAccuracy: 57.69%\n",
            "Step: 49 \tTraining loss: 38.7502 \tValidation loss: 8.6896 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.6896\tSaving model...\n",
            "Step: 50 \tTraining loss: 38.4608 \tValidation loss: 8.8416 \tAccuracy: 56.73%\n",
            "Step: 51 \tTraining loss: 37.8564 \tValidation loss: 9.1362 \tAccuracy: 57.69%\n",
            "Step: 52 \tTraining loss: 37.9259 \tValidation loss: 8.6381 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.6381\tSaving model...\n",
            "Step: 53 \tTraining loss: 37.0479 \tValidation loss: 8.5727 \tAccuracy: 58.65%\n",
            "New minumum loss found! = 8.5727\tSaving model...\n",
            "Step: 54 \tTraining loss: 37.6856 \tValidation loss: 8.7726 \tAccuracy: 51.92%\n",
            "Step: 55 \tTraining loss: 37.0523 \tValidation loss: 8.7236 \tAccuracy: 58.65%\n",
            "Step: 56 \tTraining loss: 36.9225 \tValidation loss: 8.4729 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.4729\tSaving model...\n",
            "Step: 57 \tTraining loss: 36.1185 \tValidation loss: 8.2569 \tAccuracy: 60.58%\n",
            "New minumum loss found! = 8.2569\tSaving model...\n",
            "Step: 58 \tTraining loss: 37.0555 \tValidation loss: 8.2410 \tAccuracy: 62.50%\n",
            "New minumum loss found! = 8.2410\tSaving model...\n",
            "Step: 59 \tTraining loss: 36.1872 \tValidation loss: 8.2618 \tAccuracy: 60.58%\n",
            "Step: 60 \tTraining loss: 35.2695 \tValidation loss: 8.3383 \tAccuracy: 59.62%\n",
            "Step: 61 \tTraining loss: 35.5450 \tValidation loss: 8.5062 \tAccuracy: 51.92%\n",
            "Step: 62 \tTraining loss: 35.2219 \tValidation loss: 8.3266 \tAccuracy: 59.62%\n",
            "Step: 63 \tTraining loss: 35.4683 \tValidation loss: 8.1720 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.1720\tSaving model...\n",
            "Step: 64 \tTraining loss: 35.0937 \tValidation loss: 8.0965 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.0965\tSaving model...\n",
            "Step: 65 \tTraining loss: 35.0091 \tValidation loss: 8.3946 \tAccuracy: 60.58%\n",
            "Step: 66 \tTraining loss: 34.2874 \tValidation loss: 8.1204 \tAccuracy: 61.54%\n",
            "Step: 67 \tTraining loss: 34.5223 \tValidation loss: 8.1259 \tAccuracy: 58.65%\n",
            "Step: 68 \tTraining loss: 34.3045 \tValidation loss: 8.1135 \tAccuracy: 62.50%\n",
            "Step: 69 \tTraining loss: 33.5903 \tValidation loss: 7.5438 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 7.5438\tSaving model...\n",
            "Step: 70 \tTraining loss: 33.2729 \tValidation loss: 8.1467 \tAccuracy: 63.46%\n",
            "Step: 71 \tTraining loss: 34.2840 \tValidation loss: 8.2335 \tAccuracy: 59.62%\n",
            "Step: 72 \tTraining loss: 33.0637 \tValidation loss: 8.1306 \tAccuracy: 60.58%\n",
            "Step: 73 \tTraining loss: 32.6399 \tValidation loss: 7.8608 \tAccuracy: 60.58%\n",
            "Step: 74 \tTraining loss: 33.2786 \tValidation loss: 8.0927 \tAccuracy: 53.85%\n",
            "Step: 75 \tTraining loss: 32.0788 \tValidation loss: 7.7872 \tAccuracy: 61.54%\n",
            "Step: 76 \tTraining loss: 32.9177 \tValidation loss: 7.7935 \tAccuracy: 64.42%\n",
            "Step: 77 \tTraining loss: 31.7253 \tValidation loss: 7.7864 \tAccuracy: 54.81%\n",
            "Step: 78 \tTraining loss: 31.9380 \tValidation loss: 7.9716 \tAccuracy: 61.54%\n",
            "Step: 79 \tTraining loss: 31.8901 \tValidation loss: 7.7532 \tAccuracy: 61.54%\n",
            "Step: 80 \tTraining loss: 30.6829 \tValidation loss: 7.8062 \tAccuracy: 61.54%\n",
            "Step: 81 \tTraining loss: 32.1526 \tValidation loss: 7.6969 \tAccuracy: 62.50%\n",
            "Step: 82 \tTraining loss: 30.9184 \tValidation loss: 7.5611 \tAccuracy: 60.58%\n",
            "Step: 83 \tTraining loss: 31.1558 \tValidation loss: 7.4389 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 7.4389\tSaving model...\n",
            "Step: 84 \tTraining loss: 30.9566 \tValidation loss: 7.8846 \tAccuracy: 56.73%\n",
            "Step: 85 \tTraining loss: 30.7312 \tValidation loss: 7.3764 \tAccuracy: 61.54%\n",
            "New minumum loss found! = 7.3764\tSaving model...\n",
            "Step: 86 \tTraining loss: 30.4453 \tValidation loss: 7.1924 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 7.1924\tSaving model...\n",
            "Step: 87 \tTraining loss: 30.6058 \tValidation loss: 7.6602 \tAccuracy: 56.73%\n",
            "Step: 88 \tTraining loss: 30.2667 \tValidation loss: 7.3040 \tAccuracy: 59.62%\n",
            "Step: 89 \tTraining loss: 30.3125 \tValidation loss: 7.5349 \tAccuracy: 62.50%\n",
            "Step: 90 \tTraining loss: 30.5207 \tValidation loss: 7.4473 \tAccuracy: 62.50%\n",
            "Step: 91 \tTraining loss: 30.1158 \tValidation loss: 7.6044 \tAccuracy: 56.73%\n",
            "Step: 92 \tTraining loss: 30.0818 \tValidation loss: 7.4366 \tAccuracy: 63.46%\n",
            "Step: 93 \tTraining loss: 29.3016 \tValidation loss: 7.4945 \tAccuracy: 57.69%\n",
            "Step: 94 \tTraining loss: 28.9778 \tValidation loss: 7.8343 \tAccuracy: 60.58%\n",
            "Step: 95 \tTraining loss: 28.8212 \tValidation loss: 7.6412 \tAccuracy: 57.69%\n",
            "Step: 96 \tTraining loss: 28.8608 \tValidation loss: 7.3603 \tAccuracy: 61.54%\n",
            "Step: 97 \tTraining loss: 27.8929 \tValidation loss: 7.2808 \tAccuracy: 65.38%\n",
            "Step: 98 \tTraining loss: 28.5459 \tValidation loss: 6.8073 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.8073\tSaving model...\n",
            "Step: 99 \tTraining loss: 28.5000 \tValidation loss: 7.3569 \tAccuracy: 59.62%\n",
            "Step: 100 \tTraining loss: 29.2340 \tValidation loss: 7.2785 \tAccuracy: 66.35%\n",
            "Step: 101 \tTraining loss: 28.0712 \tValidation loss: 7.4633 \tAccuracy: 55.77%\n",
            "Step: 102 \tTraining loss: 27.9715 \tValidation loss: 7.1656 \tAccuracy: 56.73%\n",
            "Step: 103 \tTraining loss: 27.6648 \tValidation loss: 7.1196 \tAccuracy: 62.50%\n",
            "Step: 104 \tTraining loss: 28.4753 \tValidation loss: 7.5008 \tAccuracy: 61.54%\n",
            "Step: 105 \tTraining loss: 27.8787 \tValidation loss: 7.1354 \tAccuracy: 62.50%\n",
            "Step: 106 \tTraining loss: 27.6722 \tValidation loss: 7.1331 \tAccuracy: 68.27%\n",
            "Step: 107 \tTraining loss: 26.8911 \tValidation loss: 6.6467 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 6.6467\tSaving model...\n",
            "Step: 108 \tTraining loss: 27.9749 \tValidation loss: 7.0439 \tAccuracy: 62.50%\n",
            "Step: 109 \tTraining loss: 27.7526 \tValidation loss: 7.3107 \tAccuracy: 66.35%\n",
            "Step: 110 \tTraining loss: 27.2972 \tValidation loss: 6.9586 \tAccuracy: 59.62%\n",
            "Step: 111 \tTraining loss: 26.6418 \tValidation loss: 7.0882 \tAccuracy: 62.50%\n",
            "Step: 112 \tTraining loss: 27.5590 \tValidation loss: 6.5459 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.5459\tSaving model...\n",
            "Step: 113 \tTraining loss: 26.8400 \tValidation loss: 7.2287 \tAccuracy: 55.77%\n",
            "Step: 114 \tTraining loss: 26.7706 \tValidation loss: 6.8493 \tAccuracy: 58.65%\n",
            "Step: 115 \tTraining loss: 26.5400 \tValidation loss: 6.7344 \tAccuracy: 68.27%\n",
            "Step: 116 \tTraining loss: 26.7867 \tValidation loss: 6.6368 \tAccuracy: 65.38%\n",
            "Step: 117 \tTraining loss: 26.5454 \tValidation loss: 7.2154 \tAccuracy: 60.58%\n",
            "Step: 118 \tTraining loss: 26.2878 \tValidation loss: 7.0085 \tAccuracy: 58.65%\n",
            "Step: 119 \tTraining loss: 25.2550 \tValidation loss: 6.9326 \tAccuracy: 63.46%\n",
            "Step: 120 \tTraining loss: 25.1723 \tValidation loss: 6.9002 \tAccuracy: 60.58%\n",
            "Step: 121 \tTraining loss: 25.1298 \tValidation loss: 7.2259 \tAccuracy: 61.54%\n",
            "Step: 122 \tTraining loss: 25.9963 \tValidation loss: 6.7753 \tAccuracy: 61.54%\n",
            "Step: 123 \tTraining loss: 25.4132 \tValidation loss: 6.7011 \tAccuracy: 66.35%\n",
            "Step: 124 \tTraining loss: 25.8240 \tValidation loss: 7.0693 \tAccuracy: 60.58%\n",
            "Step: 125 \tTraining loss: 25.0822 \tValidation loss: 6.9605 \tAccuracy: 62.50%\n",
            "Step: 126 \tTraining loss: 25.5908 \tValidation loss: 6.9876 \tAccuracy: 64.42%\n",
            "Step: 127 \tTraining loss: 25.8303 \tValidation loss: 6.6582 \tAccuracy: 63.46%\n",
            "Step: 128 \tTraining loss: 25.8644 \tValidation loss: 6.7056 \tAccuracy: 66.35%\n",
            "Step: 129 \tTraining loss: 24.6861 \tValidation loss: 7.0517 \tAccuracy: 55.77%\n",
            "Step: 130 \tTraining loss: 24.3970 \tValidation loss: 6.6435 \tAccuracy: 62.50%\n",
            "Step: 131 \tTraining loss: 24.7874 \tValidation loss: 6.3372 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.3372\tSaving model...\n",
            "Step: 132 \tTraining loss: 24.8988 \tValidation loss: 6.8781 \tAccuracy: 58.65%\n",
            "Step: 133 \tTraining loss: 24.6578 \tValidation loss: 6.9026 \tAccuracy: 65.38%\n",
            "Step: 134 \tTraining loss: 25.9561 \tValidation loss: 6.5364 \tAccuracy: 64.42%\n",
            "Step: 135 \tTraining loss: 24.5596 \tValidation loss: 6.7633 \tAccuracy: 58.65%\n",
            "Step: 136 \tTraining loss: 24.5156 \tValidation loss: 6.2888 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.2888\tSaving model...\n",
            "Step: 137 \tTraining loss: 23.8718 \tValidation loss: 6.7294 \tAccuracy: 63.46%\n",
            "Step: 138 \tTraining loss: 24.6960 \tValidation loss: 7.0993 \tAccuracy: 61.54%\n",
            "Step: 139 \tTraining loss: 24.4926 \tValidation loss: 6.8994 \tAccuracy: 58.65%\n",
            "Step: 140 \tTraining loss: 23.7279 \tValidation loss: 6.3603 \tAccuracy: 68.27%\n",
            "Step: 141 \tTraining loss: 24.9253 \tValidation loss: 6.6534 \tAccuracy: 61.54%\n",
            "Step: 142 \tTraining loss: 24.7270 \tValidation loss: 6.6425 \tAccuracy: 62.50%\n",
            "Step: 143 \tTraining loss: 23.5710 \tValidation loss: 6.4272 \tAccuracy: 64.42%\n",
            "Step: 144 \tTraining loss: 24.0679 \tValidation loss: 6.1754 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.1754\tSaving model...\n",
            "Step: 145 \tTraining loss: 23.5520 \tValidation loss: 6.9511 \tAccuracy: 62.50%\n",
            "Step: 146 \tTraining loss: 23.3087 \tValidation loss: 6.7328 \tAccuracy: 63.46%\n",
            "Step: 147 \tTraining loss: 23.8358 \tValidation loss: 6.2304 \tAccuracy: 64.42%\n",
            "Step: 148 \tTraining loss: 24.6708 \tValidation loss: 6.5486 \tAccuracy: 69.23%\n",
            "Step: 149 \tTraining loss: 23.8848 \tValidation loss: 6.7716 \tAccuracy: 58.65%\n",
            "Step: 150 \tTraining loss: 22.7480 \tValidation loss: 6.6829 \tAccuracy: 66.35%\n",
            "Step: 151 \tTraining loss: 23.1454 \tValidation loss: 7.0069 \tAccuracy: 61.54%\n",
            "Step: 152 \tTraining loss: 24.4213 \tValidation loss: 6.8490 \tAccuracy: 58.65%\n",
            "Step: 153 \tTraining loss: 22.8205 \tValidation loss: 6.7403 \tAccuracy: 64.42%\n",
            "Step: 154 \tTraining loss: 22.7997 \tValidation loss: 6.8014 \tAccuracy: 60.58%\n",
            "Step: 155 \tTraining loss: 22.3203 \tValidation loss: 6.0107 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.0107\tSaving model...\n",
            "Step: 156 \tTraining loss: 22.5092 \tValidation loss: 6.4970 \tAccuracy: 62.50%\n",
            "Step: 157 \tTraining loss: 22.3366 \tValidation loss: 6.9660 \tAccuracy: 57.69%\n",
            "Step: 158 \tTraining loss: 24.2384 \tValidation loss: 6.6770 \tAccuracy: 57.69%\n",
            "Step: 159 \tTraining loss: 23.0698 \tValidation loss: 6.7664 \tAccuracy: 63.46%\n",
            "Step: 160 \tTraining loss: 22.2441 \tValidation loss: 6.9394 \tAccuracy: 60.58%\n",
            "Step: 161 \tTraining loss: 23.0574 \tValidation loss: 6.0820 \tAccuracy: 67.31%\n",
            "Step: 162 \tTraining loss: 22.7763 \tValidation loss: 6.0503 \tAccuracy: 64.42%\n",
            "Step: 163 \tTraining loss: 21.5364 \tValidation loss: 6.5436 \tAccuracy: 66.35%\n",
            "Step: 164 \tTraining loss: 22.5297 \tValidation loss: 6.3723 \tAccuracy: 61.54%\n",
            "Step: 165 \tTraining loss: 22.9449 \tValidation loss: 6.1879 \tAccuracy: 67.31%\n",
            "Step: 166 \tTraining loss: 22.8832 \tValidation loss: 6.1841 \tAccuracy: 64.42%\n",
            "Step: 167 \tTraining loss: 22.1595 \tValidation loss: 6.4657 \tAccuracy: 61.54%\n",
            "Step: 168 \tTraining loss: 22.1527 \tValidation loss: 7.0875 \tAccuracy: 57.69%\n",
            "Step: 169 \tTraining loss: 22.6103 \tValidation loss: 6.5623 \tAccuracy: 67.31%\n",
            "Step: 170 \tTraining loss: 22.5480 \tValidation loss: 6.1340 \tAccuracy: 66.35%\n",
            "Step: 171 \tTraining loss: 20.3296 \tValidation loss: 6.9484 \tAccuracy: 61.54%\n",
            "Step: 172 \tTraining loss: 21.6362 \tValidation loss: 6.7202 \tAccuracy: 62.50%\n",
            "Step: 173 \tTraining loss: 21.6923 \tValidation loss: 6.4830 \tAccuracy: 70.19%\n",
            "Step: 174 \tTraining loss: 21.6964 \tValidation loss: 6.2595 \tAccuracy: 65.38%\n",
            "Step: 175 \tTraining loss: 21.6110 \tValidation loss: 5.7732 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 5.7732\tSaving model...\n",
            "Step: 176 \tTraining loss: 21.3992 \tValidation loss: 6.5094 \tAccuracy: 63.46%\n",
            "Step: 177 \tTraining loss: 20.6099 \tValidation loss: 6.0911 \tAccuracy: 65.38%\n",
            "Step: 178 \tTraining loss: 21.2664 \tValidation loss: 5.8487 \tAccuracy: 67.31%\n",
            "Step: 179 \tTraining loss: 21.9883 \tValidation loss: 6.4759 \tAccuracy: 60.58%\n",
            "Step: 180 \tTraining loss: 21.9220 \tValidation loss: 6.4761 \tAccuracy: 62.50%\n",
            "Step: 181 \tTraining loss: 21.2158 \tValidation loss: 6.8444 \tAccuracy: 60.58%\n",
            "Step: 182 \tTraining loss: 19.7739 \tValidation loss: 6.1564 \tAccuracy: 66.35%\n",
            "Step: 183 \tTraining loss: 20.5253 \tValidation loss: 6.8139 \tAccuracy: 60.58%\n",
            "Step: 184 \tTraining loss: 21.2265 \tValidation loss: 6.3922 \tAccuracy: 65.38%\n",
            "Step: 185 \tTraining loss: 22.0942 \tValidation loss: 5.9082 \tAccuracy: 68.27%\n",
            "Step: 186 \tTraining loss: 22.1114 \tValidation loss: 6.2147 \tAccuracy: 65.38%\n",
            "Step: 187 \tTraining loss: 20.3717 \tValidation loss: 5.8426 \tAccuracy: 66.35%\n",
            "Step: 188 \tTraining loss: 21.6382 \tValidation loss: 5.9900 \tAccuracy: 65.38%\n",
            "Step: 189 \tTraining loss: 20.1414 \tValidation loss: 6.1114 \tAccuracy: 66.35%\n",
            "Step: 190 \tTraining loss: 21.8786 \tValidation loss: 5.8501 \tAccuracy: 69.23%\n",
            "Step: 191 \tTraining loss: 20.8548 \tValidation loss: 5.8862 \tAccuracy: 68.27%\n",
            "Step: 192 \tTraining loss: 20.9515 \tValidation loss: 6.4102 \tAccuracy: 66.35%\n",
            "Step: 193 \tTraining loss: 19.8175 \tValidation loss: 6.0604 \tAccuracy: 62.50%\n",
            "Step: 194 \tTraining loss: 20.6397 \tValidation loss: 5.9300 \tAccuracy: 63.46%\n",
            "Step: 195 \tTraining loss: 21.6693 \tValidation loss: 6.6223 \tAccuracy: 65.38%\n",
            "Step: 196 \tTraining loss: 19.9015 \tValidation loss: 6.5496 \tAccuracy: 64.42%\n",
            "Step: 197 \tTraining loss: 21.6241 \tValidation loss: 5.8695 \tAccuracy: 66.35%\n",
            "Step: 198 \tTraining loss: 19.7842 \tValidation loss: 6.6390 \tAccuracy: 63.46%\n",
            "Step: 199 \tTraining loss: 20.7016 \tValidation loss: 6.1399 \tAccuracy: 68.27%\n",
            "Step: 200 \tTraining loss: 19.4250 \tValidation loss: 6.0519 \tAccuracy: 68.27%\n",
            "Step: 201 \tTraining loss: 20.7546 \tValidation loss: 5.9509 \tAccuracy: 65.38%\n",
            "Step: 202 \tTraining loss: 19.5340 \tValidation loss: 6.2937 \tAccuracy: 64.42%\n",
            "Step: 203 \tTraining loss: 20.0412 \tValidation loss: 6.3779 \tAccuracy: 65.38%\n",
            "Step: 204 \tTraining loss: 19.6465 \tValidation loss: 6.0508 \tAccuracy: 62.50%\n",
            "Step: 205 \tTraining loss: 19.3248 \tValidation loss: 6.1312 \tAccuracy: 67.31%\n",
            "Step: 206 \tTraining loss: 20.8100 \tValidation loss: 6.0976 \tAccuracy: 67.31%\n",
            "Step: 207 \tTraining loss: 19.4915 \tValidation loss: 6.4424 \tAccuracy: 65.38%\n",
            "Step: 208 \tTraining loss: 20.4420 \tValidation loss: 6.5292 \tAccuracy: 64.42%\n",
            "Step: 209 \tTraining loss: 19.4907 \tValidation loss: 6.5267 \tAccuracy: 66.35%\n",
            "Step: 210 \tTraining loss: 18.5375 \tValidation loss: 6.3972 \tAccuracy: 64.42%\n",
            "Step: 211 \tTraining loss: 20.5128 \tValidation loss: 5.9302 \tAccuracy: 68.27%\n",
            "Step: 212 \tTraining loss: 20.2942 \tValidation loss: 5.9337 \tAccuracy: 62.50%\n",
            "Step: 213 \tTraining loss: 19.5934 \tValidation loss: 6.5564 \tAccuracy: 59.62%\n",
            "Step: 214 \tTraining loss: 20.1703 \tValidation loss: 6.2770 \tAccuracy: 65.38%\n",
            "Step: 215 \tTraining loss: 19.5200 \tValidation loss: 6.2516 \tAccuracy: 64.42%\n",
            "Step: 216 \tTraining loss: 20.4215 \tValidation loss: 5.8037 \tAccuracy: 67.31%\n",
            "Step: 217 \tTraining loss: 19.5838 \tValidation loss: 6.3404 \tAccuracy: 63.46%\n",
            "Step: 218 \tTraining loss: 19.0968 \tValidation loss: 6.3928 \tAccuracy: 65.38%\n",
            "Step: 219 \tTraining loss: 19.4548 \tValidation loss: 6.3041 \tAccuracy: 63.46%\n",
            "Step: 220 \tTraining loss: 19.6589 \tValidation loss: 5.9812 \tAccuracy: 65.38%\n",
            "Step: 221 \tTraining loss: 19.2982 \tValidation loss: 6.4144 \tAccuracy: 66.35%\n",
            "Step: 222 \tTraining loss: 20.9302 \tValidation loss: 5.7400 \tAccuracy: 72.12%\n",
            "New minumum loss found! = 5.7400\tSaving model...\n",
            "Step: 223 \tTraining loss: 18.9358 \tValidation loss: 6.2603 \tAccuracy: 64.42%\n",
            "Step: 224 \tTraining loss: 19.5891 \tValidation loss: 5.9467 \tAccuracy: 62.50%\n",
            "Step: 225 \tTraining loss: 19.5948 \tValidation loss: 6.3375 \tAccuracy: 63.46%\n",
            "Step: 226 \tTraining loss: 18.7808 \tValidation loss: 5.2446 \tAccuracy: 74.04%\n",
            "New minumum loss found! = 5.2446\tSaving model...\n",
            "Step: 227 \tTraining loss: 19.7662 \tValidation loss: 6.3103 \tAccuracy: 68.27%\n",
            "Step: 228 \tTraining loss: 19.2367 \tValidation loss: 5.7649 \tAccuracy: 66.35%\n",
            "Step: 229 \tTraining loss: 18.7522 \tValidation loss: 6.0732 \tAccuracy: 70.19%\n",
            "Step: 230 \tTraining loss: 19.2569 \tValidation loss: 6.7883 \tAccuracy: 61.54%\n",
            "Step: 231 \tTraining loss: 18.6262 \tValidation loss: 5.8928 \tAccuracy: 65.38%\n",
            "Step: 232 \tTraining loss: 19.4097 \tValidation loss: 5.9408 \tAccuracy: 63.46%\n",
            "Step: 233 \tTraining loss: 20.6748 \tValidation loss: 6.1615 \tAccuracy: 66.35%\n",
            "Step: 234 \tTraining loss: 19.0169 \tValidation loss: 5.9804 \tAccuracy: 66.35%\n",
            "Step: 235 \tTraining loss: 18.7026 \tValidation loss: 6.4024 \tAccuracy: 64.42%\n",
            "Step: 236 \tTraining loss: 18.2789 \tValidation loss: 6.6618 \tAccuracy: 59.62%\n",
            "Step: 237 \tTraining loss: 20.0526 \tValidation loss: 6.2530 \tAccuracy: 68.27%\n",
            "Step: 238 \tTraining loss: 18.7606 \tValidation loss: 6.5749 \tAccuracy: 63.46%\n",
            "Step: 239 \tTraining loss: 19.2734 \tValidation loss: 6.7041 \tAccuracy: 68.27%\n",
            "Step: 240 \tTraining loss: 19.6255 \tValidation loss: 6.4957 \tAccuracy: 64.42%\n",
            "Step: 241 \tTraining loss: 19.2447 \tValidation loss: 5.8192 \tAccuracy: 69.23%\n",
            "Step: 242 \tTraining loss: 19.3965 \tValidation loss: 6.0073 \tAccuracy: 68.27%\n",
            "Step: 243 \tTraining loss: 17.5602 \tValidation loss: 5.8137 \tAccuracy: 68.27%\n",
            "Step: 244 \tTraining loss: 18.9945 \tValidation loss: 6.5122 \tAccuracy: 66.35%\n",
            "Step: 245 \tTraining loss: 18.3282 \tValidation loss: 6.4542 \tAccuracy: 64.42%\n",
            "Step: 246 \tTraining loss: 18.8242 \tValidation loss: 5.4519 \tAccuracy: 72.12%\n",
            "Step: 247 \tTraining loss: 17.7483 \tValidation loss: 5.8936 \tAccuracy: 68.27%\n",
            "Step: 248 \tTraining loss: 18.4956 \tValidation loss: 6.0083 \tAccuracy: 64.42%\n",
            "Step: 249 \tTraining loss: 18.6679 \tValidation loss: 6.0946 \tAccuracy: 66.35%\n",
            "Step: 250 \tTraining loss: 18.5184 \tValidation loss: 5.7992 \tAccuracy: 65.38%\n",
            "Step: 251 \tTraining loss: 18.4590 \tValidation loss: 5.8522 \tAccuracy: 66.35%\n",
            "Step: 252 \tTraining loss: 17.9796 \tValidation loss: 5.8915 \tAccuracy: 67.31%\n",
            "Step: 253 \tTraining loss: 17.2912 \tValidation loss: 6.2045 \tAccuracy: 68.27%\n",
            "Step: 254 \tTraining loss: 17.9011 \tValidation loss: 5.8654 \tAccuracy: 63.46%\n",
            "Step: 255 \tTraining loss: 19.0574 \tValidation loss: 5.9433 \tAccuracy: 67.31%\n",
            "Step: 256 \tTraining loss: 17.8506 \tValidation loss: 6.4164 \tAccuracy: 65.38%\n",
            "Step: 257 \tTraining loss: 18.0356 \tValidation loss: 5.9744 \tAccuracy: 67.31%\n",
            "Step: 258 \tTraining loss: 18.2001 \tValidation loss: 5.6118 \tAccuracy: 66.35%\n",
            "Step: 259 \tTraining loss: 17.5492 \tValidation loss: 5.9324 \tAccuracy: 67.31%\n",
            "Step: 260 \tTraining loss: 17.4059 \tValidation loss: 6.0026 \tAccuracy: 66.35%\n",
            "Step: 261 \tTraining loss: 18.8581 \tValidation loss: 6.2402 \tAccuracy: 66.35%\n",
            "Step: 262 \tTraining loss: 17.2705 \tValidation loss: 5.7319 \tAccuracy: 68.27%\n",
            "Step: 263 \tTraining loss: 17.0890 \tValidation loss: 5.9722 \tAccuracy: 69.23%\n",
            "Step: 264 \tTraining loss: 15.8426 \tValidation loss: 6.3561 \tAccuracy: 69.23%\n",
            "Step: 265 \tTraining loss: 18.1803 \tValidation loss: 5.9836 \tAccuracy: 68.27%\n",
            "Step: 266 \tTraining loss: 17.4099 \tValidation loss: 6.0331 \tAccuracy: 65.38%\n",
            "Step: 267 \tTraining loss: 17.4641 \tValidation loss: 6.4134 \tAccuracy: 63.46%\n",
            "Step: 268 \tTraining loss: 18.7435 \tValidation loss: 6.0334 \tAccuracy: 66.35%\n",
            "Step: 269 \tTraining loss: 18.3412 \tValidation loss: 6.0627 \tAccuracy: 69.23%\n",
            "Step: 270 \tTraining loss: 17.3466 \tValidation loss: 5.5635 \tAccuracy: 70.19%\n",
            "Step: 271 \tTraining loss: 16.6685 \tValidation loss: 5.8903 \tAccuracy: 65.38%\n",
            "Step: 272 \tTraining loss: 18.1734 \tValidation loss: 6.2667 \tAccuracy: 61.54%\n",
            "Step: 273 \tTraining loss: 18.3103 \tValidation loss: 6.1715 \tAccuracy: 63.46%\n",
            "Step: 274 \tTraining loss: 17.0616 \tValidation loss: 5.8677 \tAccuracy: 65.38%\n",
            "Step: 275 \tTraining loss: 17.2066 \tValidation loss: 6.3201 \tAccuracy: 65.38%\n",
            "Step: 276 \tTraining loss: 18.3136 \tValidation loss: 5.8187 \tAccuracy: 72.12%\n",
            "Step: 277 \tTraining loss: 18.1596 \tValidation loss: 6.4829 \tAccuracy: 62.50%\n",
            "Step: 278 \tTraining loss: 17.7979 \tValidation loss: 6.6198 \tAccuracy: 66.35%\n",
            "Step: 279 \tTraining loss: 17.0858 \tValidation loss: 5.7645 \tAccuracy: 68.27%\n",
            "Step: 280 \tTraining loss: 17.9447 \tValidation loss: 6.9663 \tAccuracy: 63.46%\n",
            "Step: 281 \tTraining loss: 16.8029 \tValidation loss: 6.6406 \tAccuracy: 65.38%\n",
            "Step: 282 \tTraining loss: 18.0827 \tValidation loss: 6.7903 \tAccuracy: 65.38%\n",
            "Step: 283 \tTraining loss: 17.8062 \tValidation loss: 6.3030 \tAccuracy: 66.35%\n",
            "Step: 284 \tTraining loss: 16.1556 \tValidation loss: 5.5794 \tAccuracy: 67.31%\n",
            "Step: 285 \tTraining loss: 17.6603 \tValidation loss: 5.4455 \tAccuracy: 69.23%\n",
            "Step: 286 \tTraining loss: 17.1149 \tValidation loss: 6.8227 \tAccuracy: 59.62%\n",
            "Step: 287 \tTraining loss: 17.8231 \tValidation loss: 6.1822 \tAccuracy: 62.50%\n",
            "Step: 288 \tTraining loss: 16.7697 \tValidation loss: 5.6949 \tAccuracy: 72.12%\n",
            "Step: 289 \tTraining loss: 17.0445 \tValidation loss: 5.8212 \tAccuracy: 67.31%\n",
            "Step: 290 \tTraining loss: 15.9531 \tValidation loss: 6.3357 \tAccuracy: 60.58%\n",
            "Step: 291 \tTraining loss: 16.9082 \tValidation loss: 5.8991 \tAccuracy: 68.27%\n",
            "Step: 292 \tTraining loss: 16.4403 \tValidation loss: 6.6116 \tAccuracy: 59.62%\n",
            "Step: 293 \tTraining loss: 18.2584 \tValidation loss: 6.2964 \tAccuracy: 65.38%\n",
            "Step: 294 \tTraining loss: 16.5324 \tValidation loss: 7.0033 \tAccuracy: 62.50%\n",
            "Step: 295 \tTraining loss: 16.7613 \tValidation loss: 5.7511 \tAccuracy: 66.35%\n",
            "Step: 296 \tTraining loss: 17.1838 \tValidation loss: 5.7467 \tAccuracy: 67.31%\n",
            "Step: 297 \tTraining loss: 17.1074 \tValidation loss: 5.9495 \tAccuracy: 66.35%\n",
            "Step: 298 \tTraining loss: 16.8789 \tValidation loss: 5.6331 \tAccuracy: 69.23%\n",
            "Step: 299 \tTraining loss: 17.5506 \tValidation loss: 6.7969 \tAccuracy: 59.62%\n",
            "Step: 300 \tTraining loss: 16.8546 \tValidation loss: 6.0675 \tAccuracy: 68.27%\n",
            "Step: 301 \tTraining loss: 15.3696 \tValidation loss: 6.5835 \tAccuracy: 61.54%\n",
            "Step: 302 \tTraining loss: 16.7296 \tValidation loss: 6.1946 \tAccuracy: 69.23%\n",
            "Step: 303 \tTraining loss: 18.4573 \tValidation loss: 5.0605 \tAccuracy: 72.12%\n",
            "New minumum loss found! = 5.0605\tSaving model...\n",
            "Step: 304 \tTraining loss: 15.8065 \tValidation loss: 5.8822 \tAccuracy: 71.15%\n",
            "Step: 305 \tTraining loss: 17.2544 \tValidation loss: 5.8519 \tAccuracy: 67.31%\n",
            "Step: 306 \tTraining loss: 15.6800 \tValidation loss: 6.8673 \tAccuracy: 60.58%\n",
            "Step: 307 \tTraining loss: 16.2724 \tValidation loss: 6.7493 \tAccuracy: 63.46%\n",
            "Step: 308 \tTraining loss: 17.2696 \tValidation loss: 6.0035 \tAccuracy: 69.23%\n",
            "Step: 309 \tTraining loss: 16.3094 \tValidation loss: 6.4037 \tAccuracy: 66.35%\n",
            "Step: 310 \tTraining loss: 16.5594 \tValidation loss: 5.4867 \tAccuracy: 69.23%\n",
            "Step: 311 \tTraining loss: 16.2765 \tValidation loss: 6.5757 \tAccuracy: 67.31%\n",
            "Step: 312 \tTraining loss: 15.5121 \tValidation loss: 5.9615 \tAccuracy: 72.12%\n",
            "Step: 313 \tTraining loss: 16.1633 \tValidation loss: 5.2913 \tAccuracy: 69.23%\n",
            "Step: 314 \tTraining loss: 16.5539 \tValidation loss: 5.6901 \tAccuracy: 67.31%\n",
            "Step: 315 \tTraining loss: 16.0828 \tValidation loss: 5.9191 \tAccuracy: 63.46%\n",
            "Step: 316 \tTraining loss: 16.6901 \tValidation loss: 6.0357 \tAccuracy: 67.31%\n",
            "Step: 317 \tTraining loss: 15.7921 \tValidation loss: 5.6921 \tAccuracy: 66.35%\n",
            "Step: 318 \tTraining loss: 16.8236 \tValidation loss: 5.4787 \tAccuracy: 72.12%\n",
            "Step: 319 \tTraining loss: 17.9447 \tValidation loss: 5.7053 \tAccuracy: 70.19%\n",
            "Step: 320 \tTraining loss: 17.6682 \tValidation loss: 6.0628 \tAccuracy: 68.27%\n",
            "Step: 321 \tTraining loss: 17.5656 \tValidation loss: 6.0533 \tAccuracy: 69.23%\n",
            "Step: 322 \tTraining loss: 17.1263 \tValidation loss: 5.9399 \tAccuracy: 69.23%\n",
            "Step: 323 \tTraining loss: 15.8426 \tValidation loss: 5.8360 \tAccuracy: 67.31%\n",
            "Step: 324 \tTraining loss: 16.9513 \tValidation loss: 6.2312 \tAccuracy: 65.38%\n",
            "Step: 325 \tTraining loss: 16.4452 \tValidation loss: 6.3824 \tAccuracy: 65.38%\n",
            "Step: 326 \tTraining loss: 16.6166 \tValidation loss: 5.8896 \tAccuracy: 69.23%\n",
            "Step: 327 \tTraining loss: 15.2849 \tValidation loss: 6.1652 \tAccuracy: 70.19%\n",
            "Step: 328 \tTraining loss: 15.6551 \tValidation loss: 6.7464 \tAccuracy: 65.38%\n",
            "Step: 329 \tTraining loss: 17.1626 \tValidation loss: 7.3049 \tAccuracy: 61.54%\n",
            "Step: 330 \tTraining loss: 15.6469 \tValidation loss: 5.7456 \tAccuracy: 67.31%\n",
            "Step: 331 \tTraining loss: 16.2067 \tValidation loss: 5.9870 \tAccuracy: 65.38%\n",
            "Step: 332 \tTraining loss: 17.0443 \tValidation loss: 5.3576 \tAccuracy: 74.04%\n",
            "Step: 333 \tTraining loss: 15.9682 \tValidation loss: 6.2796 \tAccuracy: 63.46%\n",
            "Step: 334 \tTraining loss: 16.8662 \tValidation loss: 6.5043 \tAccuracy: 64.42%\n",
            "Step: 335 \tTraining loss: 15.5723 \tValidation loss: 6.5844 \tAccuracy: 62.50%\n",
            "Step: 336 \tTraining loss: 15.8198 \tValidation loss: 5.3716 \tAccuracy: 66.35%\n",
            "Step: 337 \tTraining loss: 16.0463 \tValidation loss: 6.0457 \tAccuracy: 70.19%\n",
            "Step: 338 \tTraining loss: 16.7264 \tValidation loss: 5.9268 \tAccuracy: 64.42%\n",
            "Step: 339 \tTraining loss: 15.9415 \tValidation loss: 6.4150 \tAccuracy: 71.15%\n",
            "Step: 340 \tTraining loss: 15.8605 \tValidation loss: 5.8527 \tAccuracy: 68.27%\n",
            "Step: 341 \tTraining loss: 15.5344 \tValidation loss: 5.8561 \tAccuracy: 69.23%\n",
            "Step: 342 \tTraining loss: 16.1696 \tValidation loss: 5.6340 \tAccuracy: 67.31%\n",
            "Step: 343 \tTraining loss: 16.7569 \tValidation loss: 5.7346 \tAccuracy: 65.38%\n",
            "Step: 344 \tTraining loss: 15.3957 \tValidation loss: 6.0728 \tAccuracy: 66.35%\n",
            "Step: 345 \tTraining loss: 15.9443 \tValidation loss: 6.9542 \tAccuracy: 61.54%\n",
            "Step: 346 \tTraining loss: 17.0690 \tValidation loss: 5.0601 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 5.0601\tSaving model...\n",
            "Step: 347 \tTraining loss: 15.3187 \tValidation loss: 6.3018 \tAccuracy: 71.15%\n",
            "Step: 348 \tTraining loss: 15.1761 \tValidation loss: 6.6604 \tAccuracy: 61.54%\n",
            "Step: 349 \tTraining loss: 16.1718 \tValidation loss: 5.7534 \tAccuracy: 67.31%\n",
            "Step: 350 \tTraining loss: 14.0176 \tValidation loss: 6.3215 \tAccuracy: 69.23%\n",
            "Step: 351 \tTraining loss: 15.8845 \tValidation loss: 5.9624 \tAccuracy: 64.42%\n",
            "Step: 352 \tTraining loss: 16.3358 \tValidation loss: 6.0887 \tAccuracy: 65.38%\n",
            "Step: 353 \tTraining loss: 16.5013 \tValidation loss: 5.7827 \tAccuracy: 67.31%\n",
            "Step: 354 \tTraining loss: 14.8226 \tValidation loss: 5.4334 \tAccuracy: 71.15%\n",
            "Step: 355 \tTraining loss: 16.7156 \tValidation loss: 6.2743 \tAccuracy: 62.50%\n",
            "Step: 356 \tTraining loss: 16.1529 \tValidation loss: 5.6636 \tAccuracy: 72.12%\n",
            "Step: 357 \tTraining loss: 15.5296 \tValidation loss: 4.7589 \tAccuracy: 74.04%\n",
            "New minumum loss found! = 4.7589\tSaving model...\n",
            "Step: 358 \tTraining loss: 13.9401 \tValidation loss: 5.5232 \tAccuracy: 66.35%\n",
            "Step: 359 \tTraining loss: 15.3671 \tValidation loss: 5.7195 \tAccuracy: 66.35%\n",
            "Step: 360 \tTraining loss: 15.5186 \tValidation loss: 5.9594 \tAccuracy: 69.23%\n",
            "Step: 361 \tTraining loss: 15.3834 \tValidation loss: 5.9647 \tAccuracy: 66.35%\n",
            "Step: 362 \tTraining loss: 15.6251 \tValidation loss: 6.3725 \tAccuracy: 66.35%\n",
            "Step: 363 \tTraining loss: 16.2810 \tValidation loss: 5.2577 \tAccuracy: 68.27%\n",
            "Step: 364 \tTraining loss: 16.0699 \tValidation loss: 5.9253 \tAccuracy: 66.35%\n",
            "Step: 365 \tTraining loss: 16.6199 \tValidation loss: 5.5860 \tAccuracy: 66.35%\n",
            "Step: 366 \tTraining loss: 14.7786 \tValidation loss: 6.2875 \tAccuracy: 66.35%\n",
            "Step: 367 \tTraining loss: 15.9392 \tValidation loss: 6.8235 \tAccuracy: 63.46%\n",
            "Step: 368 \tTraining loss: 17.3167 \tValidation loss: 6.4860 \tAccuracy: 67.31%\n",
            "Step: 369 \tTraining loss: 15.4588 \tValidation loss: 6.1184 \tAccuracy: 70.19%\n",
            "Step: 370 \tTraining loss: 14.8414 \tValidation loss: 5.7192 \tAccuracy: 67.31%\n",
            "Step: 371 \tTraining loss: 15.5053 \tValidation loss: 5.9325 \tAccuracy: 68.27%\n",
            "Step: 372 \tTraining loss: 16.0260 \tValidation loss: 6.0674 \tAccuracy: 69.23%\n",
            "Step: 373 \tTraining loss: 15.2773 \tValidation loss: 5.8999 \tAccuracy: 69.23%\n",
            "Step: 374 \tTraining loss: 14.8461 \tValidation loss: 5.4744 \tAccuracy: 70.19%\n",
            "Step: 375 \tTraining loss: 14.4948 \tValidation loss: 6.7623 \tAccuracy: 66.35%\n",
            "Step: 376 \tTraining loss: 15.7124 \tValidation loss: 6.0443 \tAccuracy: 63.46%\n",
            "Step: 377 \tTraining loss: 15.1161 \tValidation loss: 6.1620 \tAccuracy: 66.35%\n",
            "Step: 378 \tTraining loss: 15.3758 \tValidation loss: 5.6271 \tAccuracy: 66.35%\n",
            "Step: 379 \tTraining loss: 15.1847 \tValidation loss: 5.9502 \tAccuracy: 71.15%\n",
            "Step: 380 \tTraining loss: 13.9747 \tValidation loss: 5.7393 \tAccuracy: 71.15%\n",
            "Step: 381 \tTraining loss: 15.3114 \tValidation loss: 5.3109 \tAccuracy: 66.35%\n",
            "Step: 382 \tTraining loss: 15.1674 \tValidation loss: 5.8631 \tAccuracy: 68.27%\n",
            "Step: 383 \tTraining loss: 15.0485 \tValidation loss: 5.9115 \tAccuracy: 63.46%\n",
            "Step: 384 \tTraining loss: 15.7866 \tValidation loss: 5.7878 \tAccuracy: 70.19%\n",
            "Step: 385 \tTraining loss: 14.8830 \tValidation loss: 5.6056 \tAccuracy: 69.23%\n",
            "Step: 386 \tTraining loss: 14.4776 \tValidation loss: 5.4346 \tAccuracy: 68.27%\n",
            "Step: 387 \tTraining loss: 14.2152 \tValidation loss: 7.5482 \tAccuracy: 58.65%\n",
            "Step: 388 \tTraining loss: 17.3403 \tValidation loss: 6.1200 \tAccuracy: 61.54%\n",
            "Step: 389 \tTraining loss: 16.0641 \tValidation loss: 5.6186 \tAccuracy: 72.12%\n",
            "Step: 390 \tTraining loss: 13.9263 \tValidation loss: 6.3288 \tAccuracy: 68.27%\n",
            "Step: 391 \tTraining loss: 16.7266 \tValidation loss: 6.1620 \tAccuracy: 66.35%\n",
            "Step: 392 \tTraining loss: 15.2334 \tValidation loss: 6.1244 \tAccuracy: 68.27%\n",
            "Step: 393 \tTraining loss: 15.9673 \tValidation loss: 6.0832 \tAccuracy: 65.38%\n",
            "Step: 394 \tTraining loss: 15.0058 \tValidation loss: 5.2490 \tAccuracy: 69.23%\n",
            "Step: 395 \tTraining loss: 14.0214 \tValidation loss: 6.2147 \tAccuracy: 62.50%\n",
            "Step: 396 \tTraining loss: 14.4264 \tValidation loss: 5.3615 \tAccuracy: 68.27%\n",
            "Step: 397 \tTraining loss: 14.5739 \tValidation loss: 6.5602 \tAccuracy: 63.46%\n",
            "Step: 398 \tTraining loss: 13.6593 \tValidation loss: 5.6683 \tAccuracy: 68.27%\n",
            "Step: 399 \tTraining loss: 15.3002 \tValidation loss: 6.4638 \tAccuracy: 61.54%\n",
            "Step: 400 \tTraining loss: 13.7799 \tValidation loss: 6.8532 \tAccuracy: 69.23%\n",
            "Step: 401 \tTraining loss: 14.4899 \tValidation loss: 5.4919 \tAccuracy: 64.42%\n",
            "Step: 402 \tTraining loss: 13.7015 \tValidation loss: 5.9519 \tAccuracy: 64.42%\n",
            "Step: 403 \tTraining loss: 13.5797 \tValidation loss: 5.9671 \tAccuracy: 67.31%\n",
            "Step: 404 \tTraining loss: 14.0277 \tValidation loss: 5.2886 \tAccuracy: 70.19%\n",
            "Step: 405 \tTraining loss: 13.6640 \tValidation loss: 6.7936 \tAccuracy: 69.23%\n",
            "Step: 406 \tTraining loss: 15.0093 \tValidation loss: 5.7865 \tAccuracy: 68.27%\n",
            "Step: 407 \tTraining loss: 14.8194 \tValidation loss: 6.1334 \tAccuracy: 71.15%\n",
            "Step: 408 \tTraining loss: 15.2821 \tValidation loss: 6.5259 \tAccuracy: 65.38%\n",
            "Step: 409 \tTraining loss: 15.6360 \tValidation loss: 6.0372 \tAccuracy: 74.04%\n",
            "Step: 410 \tTraining loss: 14.5127 \tValidation loss: 6.8654 \tAccuracy: 69.23%\n",
            "Step: 411 \tTraining loss: 14.7736 \tValidation loss: 5.2449 \tAccuracy: 69.23%\n",
            "Step: 412 \tTraining loss: 14.6731 \tValidation loss: 5.7769 \tAccuracy: 67.31%\n",
            "Step: 413 \tTraining loss: 14.7193 \tValidation loss: 6.1042 \tAccuracy: 68.27%\n",
            "Step: 414 \tTraining loss: 15.0937 \tValidation loss: 5.7492 \tAccuracy: 72.12%\n",
            "Step: 415 \tTraining loss: 14.8725 \tValidation loss: 5.9233 \tAccuracy: 70.19%\n",
            "Step: 416 \tTraining loss: 14.9544 \tValidation loss: 5.9671 \tAccuracy: 66.35%\n",
            "Step: 417 \tTraining loss: 14.0616 \tValidation loss: 6.4449 \tAccuracy: 68.27%\n",
            "Step: 418 \tTraining loss: 14.6921 \tValidation loss: 6.4773 \tAccuracy: 64.42%\n",
            "Step: 419 \tTraining loss: 15.3762 \tValidation loss: 6.3897 \tAccuracy: 69.23%\n",
            "Step: 420 \tTraining loss: 14.5874 \tValidation loss: 6.0309 \tAccuracy: 66.35%\n",
            "Step: 421 \tTraining loss: 15.0333 \tValidation loss: 5.6008 \tAccuracy: 68.27%\n",
            "Step: 422 \tTraining loss: 13.6544 \tValidation loss: 5.8954 \tAccuracy: 74.04%\n",
            "Step: 423 \tTraining loss: 14.3865 \tValidation loss: 5.9194 \tAccuracy: 69.23%\n",
            "Step: 424 \tTraining loss: 13.9782 \tValidation loss: 5.8787 \tAccuracy: 64.42%\n",
            "Step: 425 \tTraining loss: 15.3112 \tValidation loss: 6.5601 \tAccuracy: 66.35%\n",
            "Step: 426 \tTraining loss: 13.8454 \tValidation loss: 5.5228 \tAccuracy: 67.31%\n",
            "Step: 427 \tTraining loss: 14.3740 \tValidation loss: 6.2047 \tAccuracy: 66.35%\n",
            "Step: 428 \tTraining loss: 14.4410 \tValidation loss: 5.6614 \tAccuracy: 71.15%\n",
            "Step: 429 \tTraining loss: 13.8633 \tValidation loss: 5.8746 \tAccuracy: 72.12%\n",
            "Step: 430 \tTraining loss: 15.3875 \tValidation loss: 5.3364 \tAccuracy: 72.12%\n",
            "Step: 431 \tTraining loss: 13.1613 \tValidation loss: 6.1663 \tAccuracy: 70.19%\n",
            "Step: 432 \tTraining loss: 14.1445 \tValidation loss: 6.7319 \tAccuracy: 63.46%\n",
            "Step: 433 \tTraining loss: 14.7063 \tValidation loss: 5.6001 \tAccuracy: 69.23%\n",
            "Step: 434 \tTraining loss: 13.2639 \tValidation loss: 6.2757 \tAccuracy: 66.35%\n",
            "Step: 435 \tTraining loss: 14.7677 \tValidation loss: 5.6694 \tAccuracy: 65.38%\n",
            "Step: 436 \tTraining loss: 14.6198 \tValidation loss: 5.4192 \tAccuracy: 70.19%\n",
            "Step: 437 \tTraining loss: 13.2098 \tValidation loss: 5.6336 \tAccuracy: 65.38%\n",
            "Step: 438 \tTraining loss: 14.4295 \tValidation loss: 5.8751 \tAccuracy: 66.35%\n",
            "Step: 439 \tTraining loss: 14.2172 \tValidation loss: 6.9131 \tAccuracy: 63.46%\n",
            "Step: 440 \tTraining loss: 12.9976 \tValidation loss: 5.5948 \tAccuracy: 71.15%\n",
            "Step: 441 \tTraining loss: 14.7216 \tValidation loss: 6.0669 \tAccuracy: 67.31%\n",
            "Step: 442 \tTraining loss: 13.4396 \tValidation loss: 6.0510 \tAccuracy: 67.31%\n",
            "Step: 443 \tTraining loss: 14.8411 \tValidation loss: 5.7527 \tAccuracy: 69.23%\n",
            "Step: 444 \tTraining loss: 14.3682 \tValidation loss: 5.9482 \tAccuracy: 66.35%\n",
            "Step: 445 \tTraining loss: 14.2227 \tValidation loss: 6.4622 \tAccuracy: 66.35%\n",
            "Step: 446 \tTraining loss: 14.7167 \tValidation loss: 5.9315 \tAccuracy: 67.31%\n",
            "Step: 447 \tTraining loss: 13.3271 \tValidation loss: 5.7511 \tAccuracy: 69.23%\n",
            "Step: 448 \tTraining loss: 14.2046 \tValidation loss: 7.1569 \tAccuracy: 62.50%\n",
            "Step: 449 \tTraining loss: 14.0776 \tValidation loss: 6.6375 \tAccuracy: 60.58%\n",
            "Step: 450 \tTraining loss: 13.5138 \tValidation loss: 5.8782 \tAccuracy: 67.31%\n",
            "Step: 451 \tTraining loss: 15.7159 \tValidation loss: 7.5262 \tAccuracy: 62.50%\n",
            "Step: 452 \tTraining loss: 14.7842 \tValidation loss: 6.1509 \tAccuracy: 69.23%\n",
            "Step: 453 \tTraining loss: 13.9251 \tValidation loss: 6.4639 \tAccuracy: 61.54%\n",
            "Step: 454 \tTraining loss: 14.6088 \tValidation loss: 6.7470 \tAccuracy: 67.31%\n",
            "Step: 455 \tTraining loss: 14.6132 \tValidation loss: 6.3085 \tAccuracy: 67.31%\n",
            "Step: 456 \tTraining loss: 13.3377 \tValidation loss: 5.3568 \tAccuracy: 70.19%\n",
            "Step: 457 \tTraining loss: 13.2773 \tValidation loss: 6.1257 \tAccuracy: 63.46%\n",
            "Step: 458 \tTraining loss: 13.8150 \tValidation loss: 6.4214 \tAccuracy: 65.38%\n",
            "Step: 459 \tTraining loss: 14.5171 \tValidation loss: 5.7522 \tAccuracy: 71.15%\n",
            "Step: 460 \tTraining loss: 13.9883 \tValidation loss: 6.2828 \tAccuracy: 64.42%\n",
            "Step: 461 \tTraining loss: 13.0318 \tValidation loss: 6.7331 \tAccuracy: 63.46%\n",
            "Step: 462 \tTraining loss: 14.1320 \tValidation loss: 5.5066 \tAccuracy: 70.19%\n",
            "Step: 463 \tTraining loss: 14.6401 \tValidation loss: 6.3206 \tAccuracy: 70.19%\n",
            "Step: 464 \tTraining loss: 14.8112 \tValidation loss: 6.0543 \tAccuracy: 70.19%\n",
            "Step: 465 \tTraining loss: 13.7966 \tValidation loss: 6.0070 \tAccuracy: 64.42%\n",
            "Step: 466 \tTraining loss: 13.9145 \tValidation loss: 4.9915 \tAccuracy: 72.12%\n",
            "Step: 467 \tTraining loss: 14.4583 \tValidation loss: 6.2960 \tAccuracy: 69.23%\n",
            "Step: 468 \tTraining loss: 12.4578 \tValidation loss: 6.3600 \tAccuracy: 64.42%\n",
            "Step: 469 \tTraining loss: 14.3989 \tValidation loss: 5.6752 \tAccuracy: 64.42%\n",
            "Step: 470 \tTraining loss: 14.4782 \tValidation loss: 6.2214 \tAccuracy: 68.27%\n",
            "Step: 471 \tTraining loss: 15.0164 \tValidation loss: 5.8517 \tAccuracy: 67.31%\n",
            "Step: 472 \tTraining loss: 14.3881 \tValidation loss: 5.4682 \tAccuracy: 69.23%\n",
            "Step: 473 \tTraining loss: 13.0447 \tValidation loss: 6.0243 \tAccuracy: 64.42%\n",
            "Step: 474 \tTraining loss: 14.3361 \tValidation loss: 5.9155 \tAccuracy: 71.15%\n",
            "Step: 475 \tTraining loss: 13.3525 \tValidation loss: 6.5497 \tAccuracy: 66.35%\n",
            "Step: 476 \tTraining loss: 14.1116 \tValidation loss: 6.2214 \tAccuracy: 63.46%\n",
            "Step: 477 \tTraining loss: 13.7718 \tValidation loss: 6.1334 \tAccuracy: 69.23%\n",
            "Step: 478 \tTraining loss: 14.1457 \tValidation loss: 5.8272 \tAccuracy: 67.31%\n",
            "Step: 479 \tTraining loss: 14.5549 \tValidation loss: 5.7541 \tAccuracy: 68.27%\n",
            "Step: 480 \tTraining loss: 14.0360 \tValidation loss: 6.4927 \tAccuracy: 66.35%\n",
            "Step: 481 \tTraining loss: 13.6293 \tValidation loss: 5.5723 \tAccuracy: 66.35%\n",
            "Step: 482 \tTraining loss: 13.5128 \tValidation loss: 6.1968 \tAccuracy: 66.35%\n",
            "Step: 483 \tTraining loss: 13.6693 \tValidation loss: 6.0755 \tAccuracy: 68.27%\n",
            "Step: 484 \tTraining loss: 14.9461 \tValidation loss: 6.1338 \tAccuracy: 69.23%\n",
            "Step: 485 \tTraining loss: 12.9358 \tValidation loss: 6.4383 \tAccuracy: 70.19%\n",
            "Step: 486 \tTraining loss: 13.3199 \tValidation loss: 6.4212 \tAccuracy: 67.31%\n",
            "Step: 487 \tTraining loss: 12.1954 \tValidation loss: 6.3147 \tAccuracy: 64.42%\n",
            "Step: 488 \tTraining loss: 13.3055 \tValidation loss: 5.6937 \tAccuracy: 69.23%\n",
            "Step: 489 \tTraining loss: 13.3865 \tValidation loss: 6.2480 \tAccuracy: 65.38%\n",
            "Step: 490 \tTraining loss: 13.6940 \tValidation loss: 5.2576 \tAccuracy: 71.15%\n",
            "Step: 491 \tTraining loss: 13.6484 \tValidation loss: 6.0021 \tAccuracy: 69.23%\n",
            "Step: 492 \tTraining loss: 13.9260 \tValidation loss: 6.1813 \tAccuracy: 64.42%\n",
            "Step: 493 \tTraining loss: 13.1838 \tValidation loss: 5.9816 \tAccuracy: 64.42%\n",
            "Step: 494 \tTraining loss: 13.5105 \tValidation loss: 6.7630 \tAccuracy: 63.46%\n",
            "Step: 495 \tTraining loss: 12.7147 \tValidation loss: 6.0275 \tAccuracy: 68.27%\n",
            "Step: 496 \tTraining loss: 13.6252 \tValidation loss: 6.5690 \tAccuracy: 70.19%\n",
            "Step: 497 \tTraining loss: 13.9254 \tValidation loss: 6.0499 \tAccuracy: 68.27%\n",
            "Step: 498 \tTraining loss: 13.8524 \tValidation loss: 5.9053 \tAccuracy: 71.15%\n",
            "Step: 499 \tTraining loss: 13.3685 \tValidation loss: 6.3409 \tAccuracy: 67.31%\n",
            "Step: 500 \tTraining loss: 13.6885 \tValidation loss: 6.5846 \tAccuracy: 64.42%\n",
            "Step: 501 \tTraining loss: 13.6828 \tValidation loss: 5.5871 \tAccuracy: 65.38%\n",
            "Step: 502 \tTraining loss: 12.1839 \tValidation loss: 6.3268 \tAccuracy: 66.35%\n",
            "Step: 503 \tTraining loss: 13.4183 \tValidation loss: 6.3927 \tAccuracy: 65.38%\n",
            "Step: 504 \tTraining loss: 13.6543 \tValidation loss: 6.3012 \tAccuracy: 68.27%\n",
            "Step: 505 \tTraining loss: 14.7371 \tValidation loss: 6.6019 \tAccuracy: 66.35%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ef1f9e7907dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_its\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-947fefb80bb8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, max_its, min_loss)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill, resample)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;31m# we need to set -angle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_inverse_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_output_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;31m# grid will be generated on the same device as theta and img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gen_affine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train(model, max_its, min_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "_cell_guid": "de154d7e-1447-455b-b4a7-28bd514bf366",
        "_uuid": "d11e3af8-2c8f-46d5-8b0f-269c38121410",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:31:02.333657Z",
          "iopub.status.busy": "2022-03-14T16:31:02.333404Z",
          "iopub.status.idle": "2022-03-14T16:31:03.894833Z",
          "shell.execute_reply": "2022-03-14T16:31:03.894065Z",
          "shell.execute_reply.started": "2022-03-14T16:31:02.333627Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18b2mMlcEX8X",
        "outputId": "60a3aac5-98de-4946-b57f-7bb500d7f3f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: knight-resize\t Confidence: 91.07%\t Actual label: knight-resize\n",
            "Prediction: pawn_resized\t Confidence: 70.94%\t Actual label: pawn_resized\n",
            "Prediction: pawn_resized\t Confidence: 82.59%\t Actual label: pawn_resized\n",
            "Prediction: pawn_resized\t Confidence: 54.78%\t Actual label: knight-resize\n",
            "Prediction: bishop_resized\t Confidence: 81.30%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 44.94%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 42.89%\t Actual label: bishop_resized\n",
            "Prediction: pawn_resized\t Confidence: 93.54%\t Actual label: pawn_resized\n",
            "Prediction: Rook-resize\t Confidence: 44.92%\t Actual label: Rook-resize\n",
            "Prediction: bishop_resized\t Confidence: 54.95%\t Actual label: bishop_resized\n",
            "Prediction: pawn_resized\t Confidence: 51.17%\t Actual label: bishop_resized\n",
            "Prediction: pawn_resized\t Confidence: 90.56%\t Actual label: pawn_resized\n",
            "Prediction: bishop_resized\t Confidence: 93.47%\t Actual label: bishop_resized\n",
            "Prediction: knight-resize\t Confidence: 98.07%\t Actual label: knight-resize\n",
            "Prediction: bishop_resized\t Confidence: 91.11%\t Actual label: bishop_resized\n",
            "Prediction: bishop_resized\t Confidence: 33.52%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 55.36%\t Actual label: bishop_resized\n",
            "Prediction: knight-resize\t Confidence: 98.46%\t Actual label: knight-resize\n",
            "Prediction: pawn_resized\t Confidence: 46.44%\t Actual label: Queen-Resized\n",
            "Prediction: Queen-Resized\t Confidence: 98.33%\t Actual label: Queen-Resized\n",
            "Prediction: knight-resize\t Confidence: 75.49%\t Actual label: pawn_resized\n",
            "Prediction: bishop_resized\t Confidence: 78.10%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 77.20%\t Actual label: Queen-Resized\n",
            "Prediction: Queen-Resized\t Confidence: 89.66%\t Actual label: Queen-Resized\n",
            "Prediction: Rook-resize\t Confidence: 98.81%\t Actual label: Rook-resize\n",
            "Prediction: knight-resize\t Confidence: 88.39%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 75.49%\t Actual label: knight-resize\n",
            "Accuracy:\n",
            "=========\n",
            "Total Correct: 19/27\n",
            "Accuracy: 70.37%\n"
          ]
        }
      ],
      "source": [
        "total_correct = 0\n",
        "count = 0\n",
        "classes = dataset.classes\n",
        "model.load_state_dict(torch.load('./trained_model.pt'))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        yhat = model(images)\n",
        "        yhat = nn.Softmax(dim = 1)(yhat)\n",
        "        top_p, top_class = yhat.topk(1, dim = 1)\n",
        "        eq = top_class == labels.view(-1, 1)\n",
        "        # print(classes[top_class.item()])\n",
        "        total_correct += eq.sum().item()\n",
        "        \n",
        "        if count % 1 == 0:\n",
        "            print(\"Prediction: {}\\t Confidence: {:.2f}%\\t Actual label: {}\".format(classes[top_class.item()], top_p.item() * 100, classes[labels.item()]))\n",
        "        else:\n",
        "            print(f\"count%1 = {count % 1}\")\n",
        "        count += 1\n",
        "\n",
        "print(\"Accuracy:\\n=========\")\n",
        "print(f\"Total Correct: {total_correct}/{len(test_data)}\")\n",
        "print(f\"Accuracy: {(total_correct/len(test_data)) * 100:.2f}%\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "for images, labels in test_loader_ordered:\n",
        "  images = images.to(device)\n",
        "  test_images.append(images)\n",
        "  labels = labels.to(device)\n",
        "  test_labels.append(labels)\n",
        "\n",
        "ind = 6\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  yp = model(test_images[ind])\n",
        "  yp = nn.Softmax(dim=1)(yp)\n",
        "  top_p, top_class = yp.topk(1, dim = 1)\n",
        "  print(classes[top_class.item()])\n",
        "  print(top_p*100)\n"
      ],
      "metadata": {
        "id": "lbwvJQilwJMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322ffb28-a047-496d-ac86-5a540ff471a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pawn\n",
            "tensor([[94.5549]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array(test_loader.dataset)\n",
        "plt.imshow(np.array(t[ind][0][2]))"
      ],
      "metadata": {
        "id": "pPOn_6V-5P4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "eb34fa68-e784-4733-9e12-b7a923bcd0b3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-8deadce74f61>:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  t = np.array(test_loader.dataset)\n",
            "<ipython-input-28-8deadce74f61>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  t = np.array(test_loader.dataset)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb5fcce9eb0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pmn2k39_OJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(dataset.imgs[23][0])"
      ],
      "metadata": {
        "id": "V7l6uQfjOdQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "jZeF-YP70p7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "U27n0nOJAwGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52UyoHRdDD82"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}