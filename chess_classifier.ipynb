{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "66240b07-f98d-4443-aa2b-855c9ab2f5a9",
        "_uuid": "bb0e65ca-ab55-4d15-a6e0-bc6a040fa868",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.079316Z",
          "iopub.status.busy": "2022-03-14T16:24:57.078588Z",
          "iopub.status.idle": "2022-03-14T16:24:57.084741Z",
          "shell.execute_reply": "2022-03-14T16:24:57.083768Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.079255Z"
        },
        "id": "augyEluuEX8E",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "66dafa92-4c17-4e67-abda-cfbedcf6b794",
        "_uuid": "fc94861b-96c3-4083-a1cd-b8d84c1e1c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.087033Z",
          "iopub.status.busy": "2022-03-14T16:24:57.08675Z",
          "iopub.status.idle": "2022-03-14T16:24:57.106857Z",
          "shell.execute_reply": "2022-03-14T16:24:57.106144Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.086997Z"
        },
        "id": "tp3BxLB2EX8K",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "0ca059c9-e13f-4c61-d475-516bbf9769d4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_48160/4162326941.py:6: UserWarning: It is recommended to use train on a GPU, perhaps through Google colab, for performance\n",
            "  warnings.warn(\"It is recommended to use train on a GPU, perhaps through Google colab, for performance\")\n"
          ]
        }
      ],
      "source": [
        "# Setup torch device, using GPU if its available \n",
        "# Training with the CPU on my laptop is very very slow, so using a GPU (perhaps with Google colab) is preferred\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    warnings.warn(\"It is recommended to use train on a GPU, perhaps through Google colab, for performance\")\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm2fTDo4yoJi"
      },
      "source": [
        "# Setup\n",
        "To begin, we will start by importing the data. The dataset used in this project was found on Kaggle ([link](https://www.kaggle.com/datasets/anshulmehtakaggl/chess-pieces-detection-images-dataset)) and contains labelled images of chess pieces, including both digital and real images. This is good since I would like my model to have the ability to classify images of chess pieces from online games and well as live over-the-board chess games.\n",
        "\n",
        "The code below imports the data from a chess_pieces directory in the same directory and this project, and separates it into training and validation data. It then creates PyTorch DataLoader objects from the data to be used later on. At this point, this is mostly \"boilerplate\" PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPONYcoqz5r2"
      },
      "source": [
        "## Transforming the Data\n",
        "Some transformations were applied to the data before proceeding which seek to improve the model's ability to classify the images, and make things easier later on. Here I have chosen to apply the RandomHorizontalFlip and RandomRotation transforms. The ToTensor transform is just necessary for using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "l2LSvAUvEX8N"
      },
      "outputs": [],
      "source": [
        "# Define transformations for training\n",
        "input_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p = 0.4),\n",
        "    transforms.RandomRotation(30),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4aH9UzJ0EX8P"
      },
      "outputs": [],
      "source": [
        "# Load in the dataset\n",
        "dataset_path = \"./datasets/chess_pieces\"\n",
        "dataset = ImageFolder(dataset_path, transform=input_transforms)\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(\n",
        "    dataset,\n",
        "    [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)]\n",
        ")\n",
        "\n",
        "val_data, test_data = torch.utils.data.random_split(\n",
        "    val_data,\n",
        "    [int(len(val_data)*0.8), len(val_data) - int(len(val_data)*0.8)]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 16, shuffle = True)\n",
        "val_loader = DataLoader(val_data, batch_size = 16, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 1, shuffle = True)\n",
        "test_loader_ordered = DataLoader(test_data, batch_size = 1, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmfjjGtu1VZF"
      },
      "source": [
        "# Defining a Model\n",
        "Throughout our machine learning studies this quarter, we have not discussed deep learning, seeing as that is the topic of next quarter, however, in order to obtain reasonable results for a wide range of chess pieces, I have decided to use a convolutional neural network (CNN) for the model. This is because CNNs are notoriously good at classifying images and although we didn't learn much about them, many of the topics we did learn about still apply. \n",
        "\n",
        "To implement a CNN in PyTorch, we define a Python class that inherits from the nn.Module class. In this case, I have chosen to use the resnet50 model from the torchvision library. Although the mathematics behind this model (a residual neural network, which is a special case of a convolutional neural network) is beyond the scope of my understanding and our EE475 course, I have chosen to use it since implementing it with PyTorch was no more difficult that using another type of model, and residual neural networks have shown to be extremely good at classifying images. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_cell_guid": "4db1772a-4fc5-48c2-97cc-b00f0e418c20",
        "_uuid": "a6644ddf-144b-4d36-a0e2-8e9a87bd93b4",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.108527Z",
          "iopub.status.busy": "2022-03-14T16:24:57.108271Z",
          "iopub.status.idle": "2022-03-14T16:24:57.115135Z",
          "shell.execute_reply": "2022-03-14T16:24:57.11424Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.108493Z"
        },
        "id": "UGBXb8MYEX8Q",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a neural network as a class that inherits from the torch.nn.Module class \n",
        "class ChessCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessCNN, self).__init__()\n",
        "\n",
        "        # use ResNet, a deep neural network model, which is particularly good for image classification\n",
        "        self.model = torchvision.models.resnet50(pretrained = True)\n",
        "\n",
        "        for parameter in self.model.parameters():\n",
        "            parameter.requires_grad = False\n",
        "\n",
        "        # Define the model of each layer TODO: is this correct?\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 5)\n",
        "        )\n",
        "\n",
        "    # forward propogation step\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDbqlC2A4l8B"
      },
      "source": [
        "## Defining Training Parameters\n",
        "The model is first instantiated for later use, then we define several parameters like the learning rate, number of iterations, the optimizer that we will use, and the loss function. \n",
        "\n",
        "**Learning Rate**\n",
        "\n",
        "Here we set the learning rate to 0.00001. This was chosen after testing several learning rates both higher and lower. Higher learning rates result in faster training, however the loss oscillates or doesn't reach as small a value. An even smaller learning rate may be better, however I have access to only a limited amount of computing power (GPU access through Google Colab) so this learning rate is sufficient for this project.\n",
        "\n",
        "**Number of iterations**\n",
        "The number of iterations was chosen mostly because of time considerations but also and you can see from the output of the training step later on, after several hundred iterations, there are very few new best weights that are found that make the loss function any smaller. \n",
        "\n",
        "**Optimizer**\n",
        "There are many choices for the optimizer to use for this problem. I have chosen two different optimizers to try for this project and to compare performance. The first optimizer I tried was Stochaistic Gradient Descent (SGD), which is much like the standard gradient descent (GD) algorithm we have been using in class, however it will update weights faster than basic gradient descent since it doesn't need to step through the entire training set to update weigths. SGD results in many more oscillations but faster training than GD.\n",
        "\n",
        "The second optimizer I tried was the Adam optimizer. This optimizer is an special implementation of SGD that is based on adaptive estimations of first and second order moments and can be shown to perform better for some problems. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "d1600f55-ba5f-431f-b183-db612f9dac68",
        "_uuid": "66e06d27-17d7-4244-9e28-8979c52c791a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:59.750758Z",
          "iopub.status.busy": "2022-03-14T16:29:59.750106Z",
          "iopub.status.idle": "2022-03-14T16:30:00.282854Z",
          "shell.execute_reply": "2022-03-14T16:30:00.28215Z",
          "shell.execute_reply.started": "2022-03-14T16:29:59.750683Z"
        },
        "id": "egaO9oxAEX8S",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "1fefed72-a962-4507-cc55-33246f5f42ad",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nick/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/nick/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ChessCNN(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=1000, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChessCNN() # instantiate the neural net class\n",
        "# learning_rate = 0.00001 # define the learning rate\n",
        "learning_rate = 0.001\n",
        "max_its = 1000 \n",
        "\n",
        "# Define the optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.001)\n",
        "optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=0.01)\n",
        "\n",
        "# Define the loss function\n",
        "loss_func = nn.CrossEntropyLoss() # use cross entropy loss function\n",
        "min_loss = np.inf\n",
        "model.to(device) # set model to use the appropriate defice (GPU or CPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training\n",
        "To train the model using the chosen loss function and optimizer (SGD or Adam) I created the function below to make it easier. The training function loops through the data in the training set, computes the loss, and updates the weights. It then uses the validation set to check the performance at each step and if its better than the previous best performing model, it will save the current model as the new best. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "_cell_guid": "7e11bfe7-4a3a-449f-b9a5-6daa591956f1",
        "_uuid": "d2af0b73-a6f0-48a9-a844-d3b454eb6985",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:38.98681Z",
          "iopub.status.busy": "2022-03-14T16:29:38.986272Z",
          "iopub.status.idle": "2022-03-14T16:29:38.99915Z",
          "shell.execute_reply": "2022-03-14T16:29:38.998375Z",
          "shell.execute_reply.started": "2022-03-14T16:29:38.986771Z"
        },
        "id": "8pWcNsNGEX8U",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(model, max_its, min_loss):\n",
        "    for step in range(max_its):\n",
        "        training_loss = 0\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            yp = model(images)\n",
        "            loss = loss_func(yp, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.item()\n",
        "            \n",
        "            del images, labels\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "\n",
        "        valid_loss = 0\n",
        "        valid_accuracy = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                yp = model(images)\n",
        "                loss = loss_func(yp, labels)\n",
        "                valid_loss += loss.item()\n",
        "                yp = nn.Softmax(dim = 1)(yp)\n",
        "                _, top_class = yp.topk(1, dim = 1)\n",
        "                num_correct = top_class == labels.view(-1,1)\n",
        "                valid_accuracy += num_correct.sum().item()\n",
        "\n",
        "                # clear data to ensure there isn't confusion\n",
        "                del(images)\n",
        "                del(labels)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # print(\"Step: {} \\tTraining loss: {:.4f} \\tValidation loss: {:.4f} \\tAccuracy: {:.2f}%\".format(step, training_loss, valid_loss, (valid_accuracy/len(val_data))*100))\n",
        "        print(f\"Step: {step} \\tTraining loss: {training_loss:.4f} \\tValidation loss: {valid_loss:.4f} \\tAccuracy: {valid_accuracy/len(val_data)*100:.2f}%\")\n",
        "\n",
        "        # whenever a new minimum loss for the model is found replace the previous best model\n",
        "        if valid_loss <= min_loss:\n",
        "            print(f\"New minumum loss found! = {valid_loss:.4f}\\tSaving model...\")\n",
        "            torch.save(model.state_dict(), \"trained_model.pt\")\n",
        "            min_loss = valid_loss # set new minumum loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrIoWzMi-nBr"
      },
      "source": [
        "# Training\n",
        "Running the cell below will begin the training process. This can be very slow, especially on an average CPU. Therefore, to train the model I have chosen to use Google Colab which offers free (but limited) GPU usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "_cell_guid": "390812cb-c782-49ea-a31f-9e02f66b696f",
        "_uuid": "0a81eef0-af1a-4588-bd0c-5adadc3e6d02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:39.587801Z",
          "iopub.status.busy": "2022-03-14T16:29:39.587267Z",
          "iopub.status.idle": "2022-03-14T16:29:48.921548Z",
          "shell.execute_reply": "2022-03-14T16:29:48.92036Z",
          "shell.execute_reply.started": "2022-03-14T16:29:39.587756Z"
        },
        "id": "QXbpKApuEX8W",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "33daa680-d1c5-4be3-e6d1-a91bc2c726a7",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step: 0 \tTraining loss: 52.5991 \tValidation loss: 11.1866 \tAccuracy: 19.23%\n",
            "New minumum loss found! = 11.1866\tSaving model...\n",
            "Step: 1 \tTraining loss: 52.0676 \tValidation loss: 11.0467 \tAccuracy: 23.08%\n",
            "New minumum loss found! = 11.0467\tSaving model...\n",
            "Step: 2 \tTraining loss: 51.5682 \tValidation loss: 10.9403 \tAccuracy: 24.04%\n",
            "New minumum loss found! = 10.9403\tSaving model...\n",
            "Step: 3 \tTraining loss: 51.3615 \tValidation loss: 11.0087 \tAccuracy: 23.08%\n",
            "Step: 4 \tTraining loss: 51.0128 \tValidation loss: 10.9905 \tAccuracy: 24.04%\n",
            "Step: 5 \tTraining loss: 50.5236 \tValidation loss: 10.8132 \tAccuracy: 23.08%\n",
            "New minumum loss found! = 10.8132\tSaving model...\n",
            "Step: 6 \tTraining loss: 50.4258 \tValidation loss: 10.8142 \tAccuracy: 26.92%\n",
            "Step: 7 \tTraining loss: 50.0904 \tValidation loss: 10.7325 \tAccuracy: 30.77%\n",
            "New minumum loss found! = 10.7325\tSaving model...\n",
            "Step: 8 \tTraining loss: 50.0430 \tValidation loss: 10.6826 \tAccuracy: 33.65%\n",
            "New minumum loss found! = 10.6826\tSaving model...\n",
            "Step: 9 \tTraining loss: 49.6718 \tValidation loss: 10.6526 \tAccuracy: 30.77%\n",
            "New minumum loss found! = 10.6526\tSaving model...\n",
            "Step: 10 \tTraining loss: 49.4147 \tValidation loss: 10.6455 \tAccuracy: 35.58%\n",
            "New minumum loss found! = 10.6455\tSaving model...\n",
            "Step: 11 \tTraining loss: 49.1774 \tValidation loss: 10.5632 \tAccuracy: 33.65%\n",
            "New minumum loss found! = 10.5632\tSaving model...\n",
            "Step: 12 \tTraining loss: 48.9922 \tValidation loss: 10.5605 \tAccuracy: 39.42%\n",
            "New minumum loss found! = 10.5605\tSaving model...\n",
            "Step: 13 \tTraining loss: 48.4251 \tValidation loss: 10.4538 \tAccuracy: 34.62%\n",
            "New minumum loss found! = 10.4538\tSaving model...\n",
            "Step: 14 \tTraining loss: 48.3065 \tValidation loss: 10.5246 \tAccuracy: 37.50%\n",
            "Step: 15 \tTraining loss: 47.8282 \tValidation loss: 10.4609 \tAccuracy: 40.38%\n",
            "Step: 16 \tTraining loss: 47.6092 \tValidation loss: 10.4209 \tAccuracy: 39.42%\n",
            "New minumum loss found! = 10.4209\tSaving model...\n",
            "Step: 17 \tTraining loss: 47.6498 \tValidation loss: 10.4091 \tAccuracy: 40.38%\n",
            "New minumum loss found! = 10.4091\tSaving model...\n",
            "Step: 18 \tTraining loss: 47.1031 \tValidation loss: 10.1646 \tAccuracy: 41.35%\n",
            "New minumum loss found! = 10.1646\tSaving model...\n",
            "Step: 19 \tTraining loss: 46.9132 \tValidation loss: 10.2492 \tAccuracy: 41.35%\n",
            "Step: 20 \tTraining loss: 46.6145 \tValidation loss: 10.1002 \tAccuracy: 49.04%\n",
            "New minumum loss found! = 10.1002\tSaving model...\n",
            "Step: 21 \tTraining loss: 46.2962 \tValidation loss: 10.1900 \tAccuracy: 46.15%\n",
            "Step: 22 \tTraining loss: 45.5970 \tValidation loss: 10.0529 \tAccuracy: 44.23%\n",
            "New minumum loss found! = 10.0529\tSaving model...\n",
            "Step: 23 \tTraining loss: 45.6977 \tValidation loss: 10.1017 \tAccuracy: 50.00%\n",
            "Step: 24 \tTraining loss: 45.8881 \tValidation loss: 9.9260 \tAccuracy: 46.15%\n",
            "New minumum loss found! = 9.9260\tSaving model...\n",
            "Step: 25 \tTraining loss: 45.3283 \tValidation loss: 10.0050 \tAccuracy: 51.92%\n",
            "Step: 26 \tTraining loss: 45.1128 \tValidation loss: 9.8046 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.8046\tSaving model...\n",
            "Step: 27 \tTraining loss: 44.4795 \tValidation loss: 9.7845 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.7845\tSaving model...\n",
            "Step: 28 \tTraining loss: 44.3956 \tValidation loss: 9.7843 \tAccuracy: 52.88%\n",
            "New minumum loss found! = 9.7843\tSaving model...\n",
            "Step: 29 \tTraining loss: 44.0264 \tValidation loss: 9.7751 \tAccuracy: 55.77%\n",
            "New minumum loss found! = 9.7751\tSaving model...\n",
            "Step: 30 \tTraining loss: 44.0840 \tValidation loss: 9.7928 \tAccuracy: 48.08%\n",
            "Step: 31 \tTraining loss: 43.8021 \tValidation loss: 9.6741 \tAccuracy: 55.77%\n",
            "New minumum loss found! = 9.6741\tSaving model...\n",
            "Step: 32 \tTraining loss: 43.3347 \tValidation loss: 9.4852 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.4852\tSaving model...\n",
            "Step: 33 \tTraining loss: 42.7415 \tValidation loss: 9.3649 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.3649\tSaving model...\n",
            "Step: 34 \tTraining loss: 42.9762 \tValidation loss: 9.4923 \tAccuracy: 54.81%\n",
            "Step: 35 \tTraining loss: 42.3717 \tValidation loss: 9.4160 \tAccuracy: 56.73%\n",
            "Step: 36 \tTraining loss: 41.8444 \tValidation loss: 9.3751 \tAccuracy: 59.62%\n",
            "Step: 37 \tTraining loss: 41.7260 \tValidation loss: 9.4366 \tAccuracy: 50.96%\n",
            "Step: 38 \tTraining loss: 41.8472 \tValidation loss: 9.3115 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 9.3115\tSaving model...\n",
            "Step: 39 \tTraining loss: 41.3333 \tValidation loss: 9.3717 \tAccuracy: 52.88%\n",
            "Step: 40 \tTraining loss: 41.1596 \tValidation loss: 9.2649 \tAccuracy: 51.92%\n",
            "New minumum loss found! = 9.2649\tSaving model...\n",
            "Step: 41 \tTraining loss: 40.7539 \tValidation loss: 9.1197 \tAccuracy: 50.96%\n",
            "New minumum loss found! = 9.1197\tSaving model...\n",
            "Step: 42 \tTraining loss: 40.2026 \tValidation loss: 9.0209 \tAccuracy: 58.65%\n",
            "New minumum loss found! = 9.0209\tSaving model...\n",
            "Step: 43 \tTraining loss: 40.1832 \tValidation loss: 9.1366 \tAccuracy: 52.88%\n",
            "Step: 44 \tTraining loss: 39.8085 \tValidation loss: 9.0666 \tAccuracy: 54.81%\n",
            "Step: 45 \tTraining loss: 39.4757 \tValidation loss: 9.0408 \tAccuracy: 59.62%\n",
            "Step: 46 \tTraining loss: 39.2347 \tValidation loss: 8.9293 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.9293\tSaving model...\n",
            "Step: 47 \tTraining loss: 39.1563 \tValidation loss: 8.7611 \tAccuracy: 56.73%\n",
            "New minumum loss found! = 8.7611\tSaving model...\n",
            "Step: 48 \tTraining loss: 38.6258 \tValidation loss: 9.1302 \tAccuracy: 57.69%\n",
            "Step: 49 \tTraining loss: 38.7502 \tValidation loss: 8.6896 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.6896\tSaving model...\n",
            "Step: 50 \tTraining loss: 38.4608 \tValidation loss: 8.8416 \tAccuracy: 56.73%\n",
            "Step: 51 \tTraining loss: 37.8564 \tValidation loss: 9.1362 \tAccuracy: 57.69%\n",
            "Step: 52 \tTraining loss: 37.9259 \tValidation loss: 8.6381 \tAccuracy: 53.85%\n",
            "New minumum loss found! = 8.6381\tSaving model...\n",
            "Step: 53 \tTraining loss: 37.0479 \tValidation loss: 8.5727 \tAccuracy: 58.65%\n",
            "New minumum loss found! = 8.5727\tSaving model...\n",
            "Step: 54 \tTraining loss: 37.6856 \tValidation loss: 8.7726 \tAccuracy: 51.92%\n",
            "Step: 55 \tTraining loss: 37.0523 \tValidation loss: 8.7236 \tAccuracy: 58.65%\n",
            "Step: 56 \tTraining loss: 36.9225 \tValidation loss: 8.4729 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.4729\tSaving model...\n",
            "Step: 57 \tTraining loss: 36.1185 \tValidation loss: 8.2569 \tAccuracy: 60.58%\n",
            "New minumum loss found! = 8.2569\tSaving model...\n",
            "Step: 58 \tTraining loss: 37.0555 \tValidation loss: 8.2410 \tAccuracy: 62.50%\n",
            "New minumum loss found! = 8.2410\tSaving model...\n",
            "Step: 59 \tTraining loss: 36.1872 \tValidation loss: 8.2618 \tAccuracy: 60.58%\n",
            "Step: 60 \tTraining loss: 35.2695 \tValidation loss: 8.3383 \tAccuracy: 59.62%\n",
            "Step: 61 \tTraining loss: 35.5450 \tValidation loss: 8.5062 \tAccuracy: 51.92%\n",
            "Step: 62 \tTraining loss: 35.2219 \tValidation loss: 8.3266 \tAccuracy: 59.62%\n",
            "Step: 63 \tTraining loss: 35.4683 \tValidation loss: 8.1720 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.1720\tSaving model...\n",
            "Step: 64 \tTraining loss: 35.0937 \tValidation loss: 8.0965 \tAccuracy: 59.62%\n",
            "New minumum loss found! = 8.0965\tSaving model...\n",
            "Step: 65 \tTraining loss: 35.0091 \tValidation loss: 8.3946 \tAccuracy: 60.58%\n",
            "Step: 66 \tTraining loss: 34.2874 \tValidation loss: 8.1204 \tAccuracy: 61.54%\n",
            "Step: 67 \tTraining loss: 34.5223 \tValidation loss: 8.1259 \tAccuracy: 58.65%\n",
            "Step: 68 \tTraining loss: 34.3045 \tValidation loss: 8.1135 \tAccuracy: 62.50%\n",
            "Step: 69 \tTraining loss: 33.5903 \tValidation loss: 7.5438 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 7.5438\tSaving model...\n",
            "Step: 70 \tTraining loss: 33.2729 \tValidation loss: 8.1467 \tAccuracy: 63.46%\n",
            "Step: 71 \tTraining loss: 34.2840 \tValidation loss: 8.2335 \tAccuracy: 59.62%\n",
            "Step: 72 \tTraining loss: 33.0637 \tValidation loss: 8.1306 \tAccuracy: 60.58%\n",
            "Step: 73 \tTraining loss: 32.6399 \tValidation loss: 7.8608 \tAccuracy: 60.58%\n",
            "Step: 74 \tTraining loss: 33.2786 \tValidation loss: 8.0927 \tAccuracy: 53.85%\n",
            "Step: 75 \tTraining loss: 32.0788 \tValidation loss: 7.7872 \tAccuracy: 61.54%\n",
            "Step: 76 \tTraining loss: 32.9177 \tValidation loss: 7.7935 \tAccuracy: 64.42%\n",
            "Step: 77 \tTraining loss: 31.7253 \tValidation loss: 7.7864 \tAccuracy: 54.81%\n",
            "Step: 78 \tTraining loss: 31.9380 \tValidation loss: 7.9716 \tAccuracy: 61.54%\n",
            "Step: 79 \tTraining loss: 31.8901 \tValidation loss: 7.7532 \tAccuracy: 61.54%\n",
            "Step: 80 \tTraining loss: 30.6829 \tValidation loss: 7.8062 \tAccuracy: 61.54%\n",
            "Step: 81 \tTraining loss: 32.1526 \tValidation loss: 7.6969 \tAccuracy: 62.50%\n",
            "Step: 82 \tTraining loss: 30.9184 \tValidation loss: 7.5611 \tAccuracy: 60.58%\n",
            "Step: 83 \tTraining loss: 31.1558 \tValidation loss: 7.4389 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 7.4389\tSaving model...\n",
            "Step: 84 \tTraining loss: 30.9566 \tValidation loss: 7.8846 \tAccuracy: 56.73%\n",
            "Step: 85 \tTraining loss: 30.7312 \tValidation loss: 7.3764 \tAccuracy: 61.54%\n",
            "New minumum loss found! = 7.3764\tSaving model...\n",
            "Step: 86 \tTraining loss: 30.4453 \tValidation loss: 7.1924 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 7.1924\tSaving model...\n",
            "Step: 87 \tTraining loss: 30.6058 \tValidation loss: 7.6602 \tAccuracy: 56.73%\n",
            "Step: 88 \tTraining loss: 30.2667 \tValidation loss: 7.3040 \tAccuracy: 59.62%\n",
            "Step: 89 \tTraining loss: 30.3125 \tValidation loss: 7.5349 \tAccuracy: 62.50%\n",
            "Step: 90 \tTraining loss: 30.5207 \tValidation loss: 7.4473 \tAccuracy: 62.50%\n",
            "Step: 91 \tTraining loss: 30.1158 \tValidation loss: 7.6044 \tAccuracy: 56.73%\n",
            "Step: 92 \tTraining loss: 30.0818 \tValidation loss: 7.4366 \tAccuracy: 63.46%\n",
            "Step: 93 \tTraining loss: 29.3016 \tValidation loss: 7.4945 \tAccuracy: 57.69%\n",
            "Step: 94 \tTraining loss: 28.9778 \tValidation loss: 7.8343 \tAccuracy: 60.58%\n",
            "Step: 95 \tTraining loss: 28.8212 \tValidation loss: 7.6412 \tAccuracy: 57.69%\n",
            "Step: 96 \tTraining loss: 28.8608 \tValidation loss: 7.3603 \tAccuracy: 61.54%\n",
            "Step: 97 \tTraining loss: 27.8929 \tValidation loss: 7.2808 \tAccuracy: 65.38%\n",
            "Step: 98 \tTraining loss: 28.5459 \tValidation loss: 6.8073 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.8073\tSaving model...\n",
            "Step: 99 \tTraining loss: 28.5000 \tValidation loss: 7.3569 \tAccuracy: 59.62%\n",
            "Step: 100 \tTraining loss: 29.2340 \tValidation loss: 7.2785 \tAccuracy: 66.35%\n",
            "Step: 101 \tTraining loss: 28.0712 \tValidation loss: 7.4633 \tAccuracy: 55.77%\n",
            "Step: 102 \tTraining loss: 27.9715 \tValidation loss: 7.1656 \tAccuracy: 56.73%\n",
            "Step: 103 \tTraining loss: 27.6648 \tValidation loss: 7.1196 \tAccuracy: 62.50%\n",
            "Step: 104 \tTraining loss: 28.4753 \tValidation loss: 7.5008 \tAccuracy: 61.54%\n",
            "Step: 105 \tTraining loss: 27.8787 \tValidation loss: 7.1354 \tAccuracy: 62.50%\n",
            "Step: 106 \tTraining loss: 27.6722 \tValidation loss: 7.1331 \tAccuracy: 68.27%\n",
            "Step: 107 \tTraining loss: 26.8911 \tValidation loss: 6.6467 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 6.6467\tSaving model...\n",
            "Step: 108 \tTraining loss: 27.9749 \tValidation loss: 7.0439 \tAccuracy: 62.50%\n",
            "Step: 109 \tTraining loss: 27.7526 \tValidation loss: 7.3107 \tAccuracy: 66.35%\n",
            "Step: 110 \tTraining loss: 27.2972 \tValidation loss: 6.9586 \tAccuracy: 59.62%\n",
            "Step: 111 \tTraining loss: 26.6418 \tValidation loss: 7.0882 \tAccuracy: 62.50%\n",
            "Step: 112 \tTraining loss: 27.5590 \tValidation loss: 6.5459 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.5459\tSaving model...\n",
            "Step: 113 \tTraining loss: 26.8400 \tValidation loss: 7.2287 \tAccuracy: 55.77%\n",
            "Step: 114 \tTraining loss: 26.7706 \tValidation loss: 6.8493 \tAccuracy: 58.65%\n",
            "Step: 115 \tTraining loss: 26.5400 \tValidation loss: 6.7344 \tAccuracy: 68.27%\n",
            "Step: 116 \tTraining loss: 26.7867 \tValidation loss: 6.6368 \tAccuracy: 65.38%\n",
            "Step: 117 \tTraining loss: 26.5454 \tValidation loss: 7.2154 \tAccuracy: 60.58%\n",
            "Step: 118 \tTraining loss: 26.2878 \tValidation loss: 7.0085 \tAccuracy: 58.65%\n",
            "Step: 119 \tTraining loss: 25.2550 \tValidation loss: 6.9326 \tAccuracy: 63.46%\n",
            "Step: 120 \tTraining loss: 25.1723 \tValidation loss: 6.9002 \tAccuracy: 60.58%\n",
            "Step: 121 \tTraining loss: 25.1298 \tValidation loss: 7.2259 \tAccuracy: 61.54%\n",
            "Step: 122 \tTraining loss: 25.9963 \tValidation loss: 6.7753 \tAccuracy: 61.54%\n",
            "Step: 123 \tTraining loss: 25.4132 \tValidation loss: 6.7011 \tAccuracy: 66.35%\n",
            "Step: 124 \tTraining loss: 25.8240 \tValidation loss: 7.0693 \tAccuracy: 60.58%\n",
            "Step: 125 \tTraining loss: 25.0822 \tValidation loss: 6.9605 \tAccuracy: 62.50%\n",
            "Step: 126 \tTraining loss: 25.5908 \tValidation loss: 6.9876 \tAccuracy: 64.42%\n",
            "Step: 127 \tTraining loss: 25.8303 \tValidation loss: 6.6582 \tAccuracy: 63.46%\n",
            "Step: 128 \tTraining loss: 25.8644 \tValidation loss: 6.7056 \tAccuracy: 66.35%\n",
            "Step: 129 \tTraining loss: 24.6861 \tValidation loss: 7.0517 \tAccuracy: 55.77%\n",
            "Step: 130 \tTraining loss: 24.3970 \tValidation loss: 6.6435 \tAccuracy: 62.50%\n",
            "Step: 131 \tTraining loss: 24.7874 \tValidation loss: 6.3372 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.3372\tSaving model...\n",
            "Step: 132 \tTraining loss: 24.8988 \tValidation loss: 6.8781 \tAccuracy: 58.65%\n",
            "Step: 133 \tTraining loss: 24.6578 \tValidation loss: 6.9026 \tAccuracy: 65.38%\n",
            "Step: 134 \tTraining loss: 25.9561 \tValidation loss: 6.5364 \tAccuracy: 64.42%\n",
            "Step: 135 \tTraining loss: 24.5596 \tValidation loss: 6.7633 \tAccuracy: 58.65%\n",
            "Step: 136 \tTraining loss: 24.5156 \tValidation loss: 6.2888 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.2888\tSaving model...\n",
            "Step: 137 \tTraining loss: 23.8718 \tValidation loss: 6.7294 \tAccuracy: 63.46%\n",
            "Step: 138 \tTraining loss: 24.6960 \tValidation loss: 7.0993 \tAccuracy: 61.54%\n",
            "Step: 139 \tTraining loss: 24.4926 \tValidation loss: 6.8994 \tAccuracy: 58.65%\n",
            "Step: 140 \tTraining loss: 23.7279 \tValidation loss: 6.3603 \tAccuracy: 68.27%\n",
            "Step: 141 \tTraining loss: 24.9253 \tValidation loss: 6.6534 \tAccuracy: 61.54%\n",
            "Step: 142 \tTraining loss: 24.7270 \tValidation loss: 6.6425 \tAccuracy: 62.50%\n",
            "Step: 143 \tTraining loss: 23.5710 \tValidation loss: 6.4272 \tAccuracy: 64.42%\n",
            "Step: 144 \tTraining loss: 24.0679 \tValidation loss: 6.1754 \tAccuracy: 66.35%\n",
            "New minumum loss found! = 6.1754\tSaving model...\n",
            "Step: 145 \tTraining loss: 23.5520 \tValidation loss: 6.9511 \tAccuracy: 62.50%\n",
            "Step: 146 \tTraining loss: 23.3087 \tValidation loss: 6.7328 \tAccuracy: 63.46%\n",
            "Step: 147 \tTraining loss: 23.8358 \tValidation loss: 6.2304 \tAccuracy: 64.42%\n",
            "Step: 148 \tTraining loss: 24.6708 \tValidation loss: 6.5486 \tAccuracy: 69.23%\n",
            "Step: 149 \tTraining loss: 23.8848 \tValidation loss: 6.7716 \tAccuracy: 58.65%\n",
            "Step: 150 \tTraining loss: 22.7480 \tValidation loss: 6.6829 \tAccuracy: 66.35%\n",
            "Step: 151 \tTraining loss: 23.1454 \tValidation loss: 7.0069 \tAccuracy: 61.54%\n",
            "Step: 152 \tTraining loss: 24.4213 \tValidation loss: 6.8490 \tAccuracy: 58.65%\n",
            "Step: 153 \tTraining loss: 22.8205 \tValidation loss: 6.7403 \tAccuracy: 64.42%\n",
            "Step: 154 \tTraining loss: 22.7997 \tValidation loss: 6.8014 \tAccuracy: 60.58%\n",
            "Step: 155 \tTraining loss: 22.3203 \tValidation loss: 6.0107 \tAccuracy: 65.38%\n",
            "New minumum loss found! = 6.0107\tSaving model...\n",
            "Step: 156 \tTraining loss: 22.5092 \tValidation loss: 6.4970 \tAccuracy: 62.50%\n",
            "Step: 157 \tTraining loss: 22.3366 \tValidation loss: 6.9660 \tAccuracy: 57.69%\n",
            "Step: 158 \tTraining loss: 24.2384 \tValidation loss: 6.6770 \tAccuracy: 57.69%\n",
            "Step: 159 \tTraining loss: 23.0698 \tValidation loss: 6.7664 \tAccuracy: 63.46%\n",
            "Step: 160 \tTraining loss: 22.2441 \tValidation loss: 6.9394 \tAccuracy: 60.58%\n",
            "Step: 161 \tTraining loss: 23.0574 \tValidation loss: 6.0820 \tAccuracy: 67.31%\n",
            "Step: 162 \tTraining loss: 22.7763 \tValidation loss: 6.0503 \tAccuracy: 64.42%\n",
            "Step: 163 \tTraining loss: 21.5364 \tValidation loss: 6.5436 \tAccuracy: 66.35%\n",
            "Step: 164 \tTraining loss: 22.5297 \tValidation loss: 6.3723 \tAccuracy: 61.54%\n",
            "Step: 165 \tTraining loss: 22.9449 \tValidation loss: 6.1879 \tAccuracy: 67.31%\n",
            "Step: 166 \tTraining loss: 22.8832 \tValidation loss: 6.1841 \tAccuracy: 64.42%\n",
            "Step: 167 \tTraining loss: 22.1595 \tValidation loss: 6.4657 \tAccuracy: 61.54%\n",
            "Step: 168 \tTraining loss: 22.1527 \tValidation loss: 7.0875 \tAccuracy: 57.69%\n",
            "Step: 169 \tTraining loss: 22.6103 \tValidation loss: 6.5623 \tAccuracy: 67.31%\n",
            "Step: 170 \tTraining loss: 22.5480 \tValidation loss: 6.1340 \tAccuracy: 66.35%\n",
            "Step: 171 \tTraining loss: 20.3296 \tValidation loss: 6.9484 \tAccuracy: 61.54%\n",
            "Step: 172 \tTraining loss: 21.6362 \tValidation loss: 6.7202 \tAccuracy: 62.50%\n",
            "Step: 173 \tTraining loss: 21.6923 \tValidation loss: 6.4830 \tAccuracy: 70.19%\n",
            "Step: 174 \tTraining loss: 21.6964 \tValidation loss: 6.2595 \tAccuracy: 65.38%\n",
            "Step: 175 \tTraining loss: 21.6110 \tValidation loss: 5.7732 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 5.7732\tSaving model...\n",
            "Step: 176 \tTraining loss: 21.3992 \tValidation loss: 6.5094 \tAccuracy: 63.46%\n",
            "Step: 177 \tTraining loss: 20.6099 \tValidation loss: 6.0911 \tAccuracy: 65.38%\n",
            "Step: 178 \tTraining loss: 21.2664 \tValidation loss: 5.8487 \tAccuracy: 67.31%\n",
            "Step: 179 \tTraining loss: 21.9883 \tValidation loss: 6.4759 \tAccuracy: 60.58%\n",
            "Step: 180 \tTraining loss: 21.9220 \tValidation loss: 6.4761 \tAccuracy: 62.50%\n",
            "Step: 181 \tTraining loss: 21.2158 \tValidation loss: 6.8444 \tAccuracy: 60.58%\n",
            "Step: 182 \tTraining loss: 19.7739 \tValidation loss: 6.1564 \tAccuracy: 66.35%\n",
            "Step: 183 \tTraining loss: 20.5253 \tValidation loss: 6.8139 \tAccuracy: 60.58%\n",
            "Step: 184 \tTraining loss: 21.2265 \tValidation loss: 6.3922 \tAccuracy: 65.38%\n",
            "Step: 185 \tTraining loss: 22.0942 \tValidation loss: 5.9082 \tAccuracy: 68.27%\n",
            "Step: 186 \tTraining loss: 22.1114 \tValidation loss: 6.2147 \tAccuracy: 65.38%\n",
            "Step: 187 \tTraining loss: 20.3717 \tValidation loss: 5.8426 \tAccuracy: 66.35%\n",
            "Step: 188 \tTraining loss: 21.6382 \tValidation loss: 5.9900 \tAccuracy: 65.38%\n",
            "Step: 189 \tTraining loss: 20.1414 \tValidation loss: 6.1114 \tAccuracy: 66.35%\n",
            "Step: 190 \tTraining loss: 21.8786 \tValidation loss: 5.8501 \tAccuracy: 69.23%\n",
            "Step: 191 \tTraining loss: 20.8548 \tValidation loss: 5.8862 \tAccuracy: 68.27%\n",
            "Step: 192 \tTraining loss: 20.9515 \tValidation loss: 6.4102 \tAccuracy: 66.35%\n",
            "Step: 193 \tTraining loss: 19.8175 \tValidation loss: 6.0604 \tAccuracy: 62.50%\n",
            "Step: 194 \tTraining loss: 20.6397 \tValidation loss: 5.9300 \tAccuracy: 63.46%\n",
            "Step: 195 \tTraining loss: 21.6693 \tValidation loss: 6.6223 \tAccuracy: 65.38%\n",
            "Step: 196 \tTraining loss: 19.9015 \tValidation loss: 6.5496 \tAccuracy: 64.42%\n",
            "Step: 197 \tTraining loss: 21.6241 \tValidation loss: 5.8695 \tAccuracy: 66.35%\n",
            "Step: 198 \tTraining loss: 19.7842 \tValidation loss: 6.6390 \tAccuracy: 63.46%\n",
            "Step: 199 \tTraining loss: 20.7016 \tValidation loss: 6.1399 \tAccuracy: 68.27%\n",
            "Step: 200 \tTraining loss: 19.4250 \tValidation loss: 6.0519 \tAccuracy: 68.27%\n",
            "Step: 201 \tTraining loss: 20.7546 \tValidation loss: 5.9509 \tAccuracy: 65.38%\n",
            "Step: 202 \tTraining loss: 19.5340 \tValidation loss: 6.2937 \tAccuracy: 64.42%\n",
            "Step: 203 \tTraining loss: 20.0412 \tValidation loss: 6.3779 \tAccuracy: 65.38%\n",
            "Step: 204 \tTraining loss: 19.6465 \tValidation loss: 6.0508 \tAccuracy: 62.50%\n",
            "Step: 205 \tTraining loss: 19.3248 \tValidation loss: 6.1312 \tAccuracy: 67.31%\n",
            "Step: 206 \tTraining loss: 20.8100 \tValidation loss: 6.0976 \tAccuracy: 67.31%\n",
            "Step: 207 \tTraining loss: 19.4915 \tValidation loss: 6.4424 \tAccuracy: 65.38%\n",
            "Step: 208 \tTraining loss: 20.4420 \tValidation loss: 6.5292 \tAccuracy: 64.42%\n",
            "Step: 209 \tTraining loss: 19.4907 \tValidation loss: 6.5267 \tAccuracy: 66.35%\n",
            "Step: 210 \tTraining loss: 18.5375 \tValidation loss: 6.3972 \tAccuracy: 64.42%\n",
            "Step: 211 \tTraining loss: 20.5128 \tValidation loss: 5.9302 \tAccuracy: 68.27%\n",
            "Step: 212 \tTraining loss: 20.2942 \tValidation loss: 5.9337 \tAccuracy: 62.50%\n",
            "Step: 213 \tTraining loss: 19.5934 \tValidation loss: 6.5564 \tAccuracy: 59.62%\n",
            "Step: 214 \tTraining loss: 20.1703 \tValidation loss: 6.2770 \tAccuracy: 65.38%\n",
            "Step: 215 \tTraining loss: 19.5200 \tValidation loss: 6.2516 \tAccuracy: 64.42%\n",
            "Step: 216 \tTraining loss: 20.4215 \tValidation loss: 5.8037 \tAccuracy: 67.31%\n",
            "Step: 217 \tTraining loss: 19.5838 \tValidation loss: 6.3404 \tAccuracy: 63.46%\n",
            "Step: 218 \tTraining loss: 19.0968 \tValidation loss: 6.3928 \tAccuracy: 65.38%\n",
            "Step: 219 \tTraining loss: 19.4548 \tValidation loss: 6.3041 \tAccuracy: 63.46%\n",
            "Step: 220 \tTraining loss: 19.6589 \tValidation loss: 5.9812 \tAccuracy: 65.38%\n",
            "Step: 221 \tTraining loss: 19.2982 \tValidation loss: 6.4144 \tAccuracy: 66.35%\n",
            "Step: 222 \tTraining loss: 20.9302 \tValidation loss: 5.7400 \tAccuracy: 72.12%\n",
            "New minumum loss found! = 5.7400\tSaving model...\n",
            "Step: 223 \tTraining loss: 18.9358 \tValidation loss: 6.2603 \tAccuracy: 64.42%\n",
            "Step: 224 \tTraining loss: 19.5891 \tValidation loss: 5.9467 \tAccuracy: 62.50%\n",
            "Step: 225 \tTraining loss: 19.5948 \tValidation loss: 6.3375 \tAccuracy: 63.46%\n",
            "Step: 226 \tTraining loss: 18.7808 \tValidation loss: 5.2446 \tAccuracy: 74.04%\n",
            "New minumum loss found! = 5.2446\tSaving model...\n",
            "Step: 227 \tTraining loss: 19.7662 \tValidation loss: 6.3103 \tAccuracy: 68.27%\n",
            "Step: 228 \tTraining loss: 19.2367 \tValidation loss: 5.7649 \tAccuracy: 66.35%\n",
            "Step: 229 \tTraining loss: 18.7522 \tValidation loss: 6.0732 \tAccuracy: 70.19%\n",
            "Step: 230 \tTraining loss: 19.2569 \tValidation loss: 6.7883 \tAccuracy: 61.54%\n",
            "Step: 231 \tTraining loss: 18.6262 \tValidation loss: 5.8928 \tAccuracy: 65.38%\n",
            "Step: 232 \tTraining loss: 19.4097 \tValidation loss: 5.9408 \tAccuracy: 63.46%\n",
            "Step: 233 \tTraining loss: 20.6748 \tValidation loss: 6.1615 \tAccuracy: 66.35%\n",
            "Step: 234 \tTraining loss: 19.0169 \tValidation loss: 5.9804 \tAccuracy: 66.35%\n",
            "Step: 235 \tTraining loss: 18.7026 \tValidation loss: 6.4024 \tAccuracy: 64.42%\n",
            "Step: 236 \tTraining loss: 18.2789 \tValidation loss: 6.6618 \tAccuracy: 59.62%\n",
            "Step: 237 \tTraining loss: 20.0526 \tValidation loss: 6.2530 \tAccuracy: 68.27%\n",
            "Step: 238 \tTraining loss: 18.7606 \tValidation loss: 6.5749 \tAccuracy: 63.46%\n",
            "Step: 239 \tTraining loss: 19.2734 \tValidation loss: 6.7041 \tAccuracy: 68.27%\n",
            "Step: 240 \tTraining loss: 19.6255 \tValidation loss: 6.4957 \tAccuracy: 64.42%\n",
            "Step: 241 \tTraining loss: 19.2447 \tValidation loss: 5.8192 \tAccuracy: 69.23%\n",
            "Step: 242 \tTraining loss: 19.3965 \tValidation loss: 6.0073 \tAccuracy: 68.27%\n",
            "Step: 243 \tTraining loss: 17.5602 \tValidation loss: 5.8137 \tAccuracy: 68.27%\n",
            "Step: 244 \tTraining loss: 18.9945 \tValidation loss: 6.5122 \tAccuracy: 66.35%\n",
            "Step: 245 \tTraining loss: 18.3282 \tValidation loss: 6.4542 \tAccuracy: 64.42%\n",
            "Step: 246 \tTraining loss: 18.8242 \tValidation loss: 5.4519 \tAccuracy: 72.12%\n",
            "Step: 247 \tTraining loss: 17.7483 \tValidation loss: 5.8936 \tAccuracy: 68.27%\n",
            "Step: 248 \tTraining loss: 18.4956 \tValidation loss: 6.0083 \tAccuracy: 64.42%\n",
            "Step: 249 \tTraining loss: 18.6679 \tValidation loss: 6.0946 \tAccuracy: 66.35%\n",
            "Step: 250 \tTraining loss: 18.5184 \tValidation loss: 5.7992 \tAccuracy: 65.38%\n",
            "Step: 251 \tTraining loss: 18.4590 \tValidation loss: 5.8522 \tAccuracy: 66.35%\n",
            "Step: 252 \tTraining loss: 17.9796 \tValidation loss: 5.8915 \tAccuracy: 67.31%\n",
            "Step: 253 \tTraining loss: 17.2912 \tValidation loss: 6.2045 \tAccuracy: 68.27%\n",
            "Step: 254 \tTraining loss: 17.9011 \tValidation loss: 5.8654 \tAccuracy: 63.46%\n",
            "Step: 255 \tTraining loss: 19.0574 \tValidation loss: 5.9433 \tAccuracy: 67.31%\n",
            "Step: 256 \tTraining loss: 17.8506 \tValidation loss: 6.4164 \tAccuracy: 65.38%\n",
            "Step: 257 \tTraining loss: 18.0356 \tValidation loss: 5.9744 \tAccuracy: 67.31%\n",
            "Step: 258 \tTraining loss: 18.2001 \tValidation loss: 5.6118 \tAccuracy: 66.35%\n",
            "Step: 259 \tTraining loss: 17.5492 \tValidation loss: 5.9324 \tAccuracy: 67.31%\n",
            "Step: 260 \tTraining loss: 17.4059 \tValidation loss: 6.0026 \tAccuracy: 66.35%\n",
            "Step: 261 \tTraining loss: 18.8581 \tValidation loss: 6.2402 \tAccuracy: 66.35%\n",
            "Step: 262 \tTraining loss: 17.2705 \tValidation loss: 5.7319 \tAccuracy: 68.27%\n",
            "Step: 263 \tTraining loss: 17.0890 \tValidation loss: 5.9722 \tAccuracy: 69.23%\n",
            "Step: 264 \tTraining loss: 15.8426 \tValidation loss: 6.3561 \tAccuracy: 69.23%\n",
            "Step: 265 \tTraining loss: 18.1803 \tValidation loss: 5.9836 \tAccuracy: 68.27%\n",
            "Step: 266 \tTraining loss: 17.4099 \tValidation loss: 6.0331 \tAccuracy: 65.38%\n",
            "Step: 267 \tTraining loss: 17.4641 \tValidation loss: 6.4134 \tAccuracy: 63.46%\n",
            "Step: 268 \tTraining loss: 18.7435 \tValidation loss: 6.0334 \tAccuracy: 66.35%\n",
            "Step: 269 \tTraining loss: 18.3412 \tValidation loss: 6.0627 \tAccuracy: 69.23%\n",
            "Step: 270 \tTraining loss: 17.3466 \tValidation loss: 5.5635 \tAccuracy: 70.19%\n",
            "Step: 271 \tTraining loss: 16.6685 \tValidation loss: 5.8903 \tAccuracy: 65.38%\n",
            "Step: 272 \tTraining loss: 18.1734 \tValidation loss: 6.2667 \tAccuracy: 61.54%\n",
            "Step: 273 \tTraining loss: 18.3103 \tValidation loss: 6.1715 \tAccuracy: 63.46%\n",
            "Step: 274 \tTraining loss: 17.0616 \tValidation loss: 5.8677 \tAccuracy: 65.38%\n",
            "Step: 275 \tTraining loss: 17.2066 \tValidation loss: 6.3201 \tAccuracy: 65.38%\n",
            "Step: 276 \tTraining loss: 18.3136 \tValidation loss: 5.8187 \tAccuracy: 72.12%\n",
            "Step: 277 \tTraining loss: 18.1596 \tValidation loss: 6.4829 \tAccuracy: 62.50%\n",
            "Step: 278 \tTraining loss: 17.7979 \tValidation loss: 6.6198 \tAccuracy: 66.35%\n",
            "Step: 279 \tTraining loss: 17.0858 \tValidation loss: 5.7645 \tAccuracy: 68.27%\n",
            "Step: 280 \tTraining loss: 17.9447 \tValidation loss: 6.9663 \tAccuracy: 63.46%\n",
            "Step: 281 \tTraining loss: 16.8029 \tValidation loss: 6.6406 \tAccuracy: 65.38%\n",
            "Step: 282 \tTraining loss: 18.0827 \tValidation loss: 6.7903 \tAccuracy: 65.38%\n",
            "Step: 283 \tTraining loss: 17.8062 \tValidation loss: 6.3030 \tAccuracy: 66.35%\n",
            "Step: 284 \tTraining loss: 16.1556 \tValidation loss: 5.5794 \tAccuracy: 67.31%\n",
            "Step: 285 \tTraining loss: 17.6603 \tValidation loss: 5.4455 \tAccuracy: 69.23%\n",
            "Step: 286 \tTraining loss: 17.1149 \tValidation loss: 6.8227 \tAccuracy: 59.62%\n",
            "Step: 287 \tTraining loss: 17.8231 \tValidation loss: 6.1822 \tAccuracy: 62.50%\n",
            "Step: 288 \tTraining loss: 16.7697 \tValidation loss: 5.6949 \tAccuracy: 72.12%\n",
            "Step: 289 \tTraining loss: 17.0445 \tValidation loss: 5.8212 \tAccuracy: 67.31%\n",
            "Step: 290 \tTraining loss: 15.9531 \tValidation loss: 6.3357 \tAccuracy: 60.58%\n",
            "Step: 291 \tTraining loss: 16.9082 \tValidation loss: 5.8991 \tAccuracy: 68.27%\n",
            "Step: 292 \tTraining loss: 16.4403 \tValidation loss: 6.6116 \tAccuracy: 59.62%\n",
            "Step: 293 \tTraining loss: 18.2584 \tValidation loss: 6.2964 \tAccuracy: 65.38%\n",
            "Step: 294 \tTraining loss: 16.5324 \tValidation loss: 7.0033 \tAccuracy: 62.50%\n",
            "Step: 295 \tTraining loss: 16.7613 \tValidation loss: 5.7511 \tAccuracy: 66.35%\n",
            "Step: 296 \tTraining loss: 17.1838 \tValidation loss: 5.7467 \tAccuracy: 67.31%\n",
            "Step: 297 \tTraining loss: 17.1074 \tValidation loss: 5.9495 \tAccuracy: 66.35%\n",
            "Step: 298 \tTraining loss: 16.8789 \tValidation loss: 5.6331 \tAccuracy: 69.23%\n",
            "Step: 299 \tTraining loss: 17.5506 \tValidation loss: 6.7969 \tAccuracy: 59.62%\n",
            "Step: 300 \tTraining loss: 16.8546 \tValidation loss: 6.0675 \tAccuracy: 68.27%\n",
            "Step: 301 \tTraining loss: 15.3696 \tValidation loss: 6.5835 \tAccuracy: 61.54%\n",
            "Step: 302 \tTraining loss: 16.7296 \tValidation loss: 6.1946 \tAccuracy: 69.23%\n",
            "Step: 303 \tTraining loss: 18.4573 \tValidation loss: 5.0605 \tAccuracy: 72.12%\n",
            "New minumum loss found! = 5.0605\tSaving model...\n",
            "Step: 304 \tTraining loss: 15.8065 \tValidation loss: 5.8822 \tAccuracy: 71.15%\n",
            "Step: 305 \tTraining loss: 17.2544 \tValidation loss: 5.8519 \tAccuracy: 67.31%\n",
            "Step: 306 \tTraining loss: 15.6800 \tValidation loss: 6.8673 \tAccuracy: 60.58%\n",
            "Step: 307 \tTraining loss: 16.2724 \tValidation loss: 6.7493 \tAccuracy: 63.46%\n",
            "Step: 308 \tTraining loss: 17.2696 \tValidation loss: 6.0035 \tAccuracy: 69.23%\n",
            "Step: 309 \tTraining loss: 16.3094 \tValidation loss: 6.4037 \tAccuracy: 66.35%\n",
            "Step: 310 \tTraining loss: 16.5594 \tValidation loss: 5.4867 \tAccuracy: 69.23%\n",
            "Step: 311 \tTraining loss: 16.2765 \tValidation loss: 6.5757 \tAccuracy: 67.31%\n",
            "Step: 312 \tTraining loss: 15.5121 \tValidation loss: 5.9615 \tAccuracy: 72.12%\n",
            "Step: 313 \tTraining loss: 16.1633 \tValidation loss: 5.2913 \tAccuracy: 69.23%\n",
            "Step: 314 \tTraining loss: 16.5539 \tValidation loss: 5.6901 \tAccuracy: 67.31%\n",
            "Step: 315 \tTraining loss: 16.0828 \tValidation loss: 5.9191 \tAccuracy: 63.46%\n",
            "Step: 316 \tTraining loss: 16.6901 \tValidation loss: 6.0357 \tAccuracy: 67.31%\n",
            "Step: 317 \tTraining loss: 15.7921 \tValidation loss: 5.6921 \tAccuracy: 66.35%\n",
            "Step: 318 \tTraining loss: 16.8236 \tValidation loss: 5.4787 \tAccuracy: 72.12%\n",
            "Step: 319 \tTraining loss: 17.9447 \tValidation loss: 5.7053 \tAccuracy: 70.19%\n",
            "Step: 320 \tTraining loss: 17.6682 \tValidation loss: 6.0628 \tAccuracy: 68.27%\n",
            "Step: 321 \tTraining loss: 17.5656 \tValidation loss: 6.0533 \tAccuracy: 69.23%\n",
            "Step: 322 \tTraining loss: 17.1263 \tValidation loss: 5.9399 \tAccuracy: 69.23%\n",
            "Step: 323 \tTraining loss: 15.8426 \tValidation loss: 5.8360 \tAccuracy: 67.31%\n",
            "Step: 324 \tTraining loss: 16.9513 \tValidation loss: 6.2312 \tAccuracy: 65.38%\n",
            "Step: 325 \tTraining loss: 16.4452 \tValidation loss: 6.3824 \tAccuracy: 65.38%\n",
            "Step: 326 \tTraining loss: 16.6166 \tValidation loss: 5.8896 \tAccuracy: 69.23%\n",
            "Step: 327 \tTraining loss: 15.2849 \tValidation loss: 6.1652 \tAccuracy: 70.19%\n",
            "Step: 328 \tTraining loss: 15.6551 \tValidation loss: 6.7464 \tAccuracy: 65.38%\n",
            "Step: 329 \tTraining loss: 17.1626 \tValidation loss: 7.3049 \tAccuracy: 61.54%\n",
            "Step: 330 \tTraining loss: 15.6469 \tValidation loss: 5.7456 \tAccuracy: 67.31%\n",
            "Step: 331 \tTraining loss: 16.2067 \tValidation loss: 5.9870 \tAccuracy: 65.38%\n",
            "Step: 332 \tTraining loss: 17.0443 \tValidation loss: 5.3576 \tAccuracy: 74.04%\n",
            "Step: 333 \tTraining loss: 15.9682 \tValidation loss: 6.2796 \tAccuracy: 63.46%\n",
            "Step: 334 \tTraining loss: 16.8662 \tValidation loss: 6.5043 \tAccuracy: 64.42%\n",
            "Step: 335 \tTraining loss: 15.5723 \tValidation loss: 6.5844 \tAccuracy: 62.50%\n",
            "Step: 336 \tTraining loss: 15.8198 \tValidation loss: 5.3716 \tAccuracy: 66.35%\n",
            "Step: 337 \tTraining loss: 16.0463 \tValidation loss: 6.0457 \tAccuracy: 70.19%\n",
            "Step: 338 \tTraining loss: 16.7264 \tValidation loss: 5.9268 \tAccuracy: 64.42%\n",
            "Step: 339 \tTraining loss: 15.9415 \tValidation loss: 6.4150 \tAccuracy: 71.15%\n",
            "Step: 340 \tTraining loss: 15.8605 \tValidation loss: 5.8527 \tAccuracy: 68.27%\n",
            "Step: 341 \tTraining loss: 15.5344 \tValidation loss: 5.8561 \tAccuracy: 69.23%\n",
            "Step: 342 \tTraining loss: 16.1696 \tValidation loss: 5.6340 \tAccuracy: 67.31%\n",
            "Step: 343 \tTraining loss: 16.7569 \tValidation loss: 5.7346 \tAccuracy: 65.38%\n",
            "Step: 344 \tTraining loss: 15.3957 \tValidation loss: 6.0728 \tAccuracy: 66.35%\n",
            "Step: 345 \tTraining loss: 15.9443 \tValidation loss: 6.9542 \tAccuracy: 61.54%\n",
            "Step: 346 \tTraining loss: 17.0690 \tValidation loss: 5.0601 \tAccuracy: 67.31%\n",
            "New minumum loss found! = 5.0601\tSaving model...\n",
            "Step: 347 \tTraining loss: 15.3187 \tValidation loss: 6.3018 \tAccuracy: 71.15%\n",
            "Step: 348 \tTraining loss: 15.1761 \tValidation loss: 6.6604 \tAccuracy: 61.54%\n",
            "Step: 349 \tTraining loss: 16.1718 \tValidation loss: 5.7534 \tAccuracy: 67.31%\n",
            "Step: 350 \tTraining loss: 14.0176 \tValidation loss: 6.3215 \tAccuracy: 69.23%\n",
            "Step: 351 \tTraining loss: 15.8845 \tValidation loss: 5.9624 \tAccuracy: 64.42%\n",
            "Step: 352 \tTraining loss: 16.3358 \tValidation loss: 6.0887 \tAccuracy: 65.38%\n",
            "Step: 353 \tTraining loss: 16.5013 \tValidation loss: 5.7827 \tAccuracy: 67.31%\n",
            "Step: 354 \tTraining loss: 14.8226 \tValidation loss: 5.4334 \tAccuracy: 71.15%\n",
            "Step: 355 \tTraining loss: 16.7156 \tValidation loss: 6.2743 \tAccuracy: 62.50%\n",
            "Step: 356 \tTraining loss: 16.1529 \tValidation loss: 5.6636 \tAccuracy: 72.12%\n",
            "Step: 357 \tTraining loss: 15.5296 \tValidation loss: 4.7589 \tAccuracy: 74.04%\n",
            "New minumum loss found! = 4.7589\tSaving model...\n",
            "Step: 358 \tTraining loss: 13.9401 \tValidation loss: 5.5232 \tAccuracy: 66.35%\n",
            "Step: 359 \tTraining loss: 15.3671 \tValidation loss: 5.7195 \tAccuracy: 66.35%\n",
            "Step: 360 \tTraining loss: 15.5186 \tValidation loss: 5.9594 \tAccuracy: 69.23%\n",
            "Step: 361 \tTraining loss: 15.3834 \tValidation loss: 5.9647 \tAccuracy: 66.35%\n",
            "Step: 362 \tTraining loss: 15.6251 \tValidation loss: 6.3725 \tAccuracy: 66.35%\n",
            "Step: 363 \tTraining loss: 16.2810 \tValidation loss: 5.2577 \tAccuracy: 68.27%\n",
            "Step: 364 \tTraining loss: 16.0699 \tValidation loss: 5.9253 \tAccuracy: 66.35%\n",
            "Step: 365 \tTraining loss: 16.6199 \tValidation loss: 5.5860 \tAccuracy: 66.35%\n",
            "Step: 366 \tTraining loss: 14.7786 \tValidation loss: 6.2875 \tAccuracy: 66.35%\n",
            "Step: 367 \tTraining loss: 15.9392 \tValidation loss: 6.8235 \tAccuracy: 63.46%\n",
            "Step: 368 \tTraining loss: 17.3167 \tValidation loss: 6.4860 \tAccuracy: 67.31%\n",
            "Step: 369 \tTraining loss: 15.4588 \tValidation loss: 6.1184 \tAccuracy: 70.19%\n",
            "Step: 370 \tTraining loss: 14.8414 \tValidation loss: 5.7192 \tAccuracy: 67.31%\n",
            "Step: 371 \tTraining loss: 15.5053 \tValidation loss: 5.9325 \tAccuracy: 68.27%\n",
            "Step: 372 \tTraining loss: 16.0260 \tValidation loss: 6.0674 \tAccuracy: 69.23%\n",
            "Step: 373 \tTraining loss: 15.2773 \tValidation loss: 5.8999 \tAccuracy: 69.23%\n",
            "Step: 374 \tTraining loss: 14.8461 \tValidation loss: 5.4744 \tAccuracy: 70.19%\n",
            "Step: 375 \tTraining loss: 14.4948 \tValidation loss: 6.7623 \tAccuracy: 66.35%\n",
            "Step: 376 \tTraining loss: 15.7124 \tValidation loss: 6.0443 \tAccuracy: 63.46%\n",
            "Step: 377 \tTraining loss: 15.1161 \tValidation loss: 6.1620 \tAccuracy: 66.35%\n",
            "Step: 378 \tTraining loss: 15.3758 \tValidation loss: 5.6271 \tAccuracy: 66.35%\n",
            "Step: 379 \tTraining loss: 15.1847 \tValidation loss: 5.9502 \tAccuracy: 71.15%\n",
            "Step: 380 \tTraining loss: 13.9747 \tValidation loss: 5.7393 \tAccuracy: 71.15%\n",
            "Step: 381 \tTraining loss: 15.3114 \tValidation loss: 5.3109 \tAccuracy: 66.35%\n",
            "Step: 382 \tTraining loss: 15.1674 \tValidation loss: 5.8631 \tAccuracy: 68.27%\n",
            "Step: 383 \tTraining loss: 15.0485 \tValidation loss: 5.9115 \tAccuracy: 63.46%\n",
            "Step: 384 \tTraining loss: 15.7866 \tValidation loss: 5.7878 \tAccuracy: 70.19%\n",
            "Step: 385 \tTraining loss: 14.8830 \tValidation loss: 5.6056 \tAccuracy: 69.23%\n",
            "Step: 386 \tTraining loss: 14.4776 \tValidation loss: 5.4346 \tAccuracy: 68.27%\n",
            "Step: 387 \tTraining loss: 14.2152 \tValidation loss: 7.5482 \tAccuracy: 58.65%\n",
            "Step: 388 \tTraining loss: 17.3403 \tValidation loss: 6.1200 \tAccuracy: 61.54%\n",
            "Step: 389 \tTraining loss: 16.0641 \tValidation loss: 5.6186 \tAccuracy: 72.12%\n",
            "Step: 390 \tTraining loss: 13.9263 \tValidation loss: 6.3288 \tAccuracy: 68.27%\n",
            "Step: 391 \tTraining loss: 16.7266 \tValidation loss: 6.1620 \tAccuracy: 66.35%\n",
            "Step: 392 \tTraining loss: 15.2334 \tValidation loss: 6.1244 \tAccuracy: 68.27%\n",
            "Step: 393 \tTraining loss: 15.9673 \tValidation loss: 6.0832 \tAccuracy: 65.38%\n",
            "Step: 394 \tTraining loss: 15.0058 \tValidation loss: 5.2490 \tAccuracy: 69.23%\n",
            "Step: 395 \tTraining loss: 14.0214 \tValidation loss: 6.2147 \tAccuracy: 62.50%\n",
            "Step: 396 \tTraining loss: 14.4264 \tValidation loss: 5.3615 \tAccuracy: 68.27%\n",
            "Step: 397 \tTraining loss: 14.5739 \tValidation loss: 6.5602 \tAccuracy: 63.46%\n",
            "Step: 398 \tTraining loss: 13.6593 \tValidation loss: 5.6683 \tAccuracy: 68.27%\n",
            "Step: 399 \tTraining loss: 15.3002 \tValidation loss: 6.4638 \tAccuracy: 61.54%\n",
            "Step: 400 \tTraining loss: 13.7799 \tValidation loss: 6.8532 \tAccuracy: 69.23%\n",
            "Step: 401 \tTraining loss: 14.4899 \tValidation loss: 5.4919 \tAccuracy: 64.42%\n",
            "Step: 402 \tTraining loss: 13.7015 \tValidation loss: 5.9519 \tAccuracy: 64.42%\n",
            "Step: 403 \tTraining loss: 13.5797 \tValidation loss: 5.9671 \tAccuracy: 67.31%\n",
            "Step: 404 \tTraining loss: 14.0277 \tValidation loss: 5.2886 \tAccuracy: 70.19%\n",
            "Step: 405 \tTraining loss: 13.6640 \tValidation loss: 6.7936 \tAccuracy: 69.23%\n",
            "Step: 406 \tTraining loss: 15.0093 \tValidation loss: 5.7865 \tAccuracy: 68.27%\n",
            "Step: 407 \tTraining loss: 14.8194 \tValidation loss: 6.1334 \tAccuracy: 71.15%\n",
            "Step: 408 \tTraining loss: 15.2821 \tValidation loss: 6.5259 \tAccuracy: 65.38%\n",
            "Step: 409 \tTraining loss: 15.6360 \tValidation loss: 6.0372 \tAccuracy: 74.04%\n",
            "Step: 410 \tTraining loss: 14.5127 \tValidation loss: 6.8654 \tAccuracy: 69.23%\n",
            "Step: 411 \tTraining loss: 14.7736 \tValidation loss: 5.2449 \tAccuracy: 69.23%\n",
            "Step: 412 \tTraining loss: 14.6731 \tValidation loss: 5.7769 \tAccuracy: 67.31%\n",
            "Step: 413 \tTraining loss: 14.7193 \tValidation loss: 6.1042 \tAccuracy: 68.27%\n",
            "Step: 414 \tTraining loss: 15.0937 \tValidation loss: 5.7492 \tAccuracy: 72.12%\n",
            "Step: 415 \tTraining loss: 14.8725 \tValidation loss: 5.9233 \tAccuracy: 70.19%\n",
            "Step: 416 \tTraining loss: 14.9544 \tValidation loss: 5.9671 \tAccuracy: 66.35%\n",
            "Step: 417 \tTraining loss: 14.0616 \tValidation loss: 6.4449 \tAccuracy: 68.27%\n",
            "Step: 418 \tTraining loss: 14.6921 \tValidation loss: 6.4773 \tAccuracy: 64.42%\n",
            "Step: 419 \tTraining loss: 15.3762 \tValidation loss: 6.3897 \tAccuracy: 69.23%\n",
            "Step: 420 \tTraining loss: 14.5874 \tValidation loss: 6.0309 \tAccuracy: 66.35%\n",
            "Step: 421 \tTraining loss: 15.0333 \tValidation loss: 5.6008 \tAccuracy: 68.27%\n",
            "Step: 422 \tTraining loss: 13.6544 \tValidation loss: 5.8954 \tAccuracy: 74.04%\n",
            "Step: 423 \tTraining loss: 14.3865 \tValidation loss: 5.9194 \tAccuracy: 69.23%\n",
            "Step: 424 \tTraining loss: 13.9782 \tValidation loss: 5.8787 \tAccuracy: 64.42%\n",
            "Step: 425 \tTraining loss: 15.3112 \tValidation loss: 6.5601 \tAccuracy: 66.35%\n",
            "Step: 426 \tTraining loss: 13.8454 \tValidation loss: 5.5228 \tAccuracy: 67.31%\n",
            "Step: 427 \tTraining loss: 14.3740 \tValidation loss: 6.2047 \tAccuracy: 66.35%\n",
            "Step: 428 \tTraining loss: 14.4410 \tValidation loss: 5.6614 \tAccuracy: 71.15%\n",
            "Step: 429 \tTraining loss: 13.8633 \tValidation loss: 5.8746 \tAccuracy: 72.12%\n",
            "Step: 430 \tTraining loss: 15.3875 \tValidation loss: 5.3364 \tAccuracy: 72.12%\n",
            "Step: 431 \tTraining loss: 13.1613 \tValidation loss: 6.1663 \tAccuracy: 70.19%\n",
            "Step: 432 \tTraining loss: 14.1445 \tValidation loss: 6.7319 \tAccuracy: 63.46%\n",
            "Step: 433 \tTraining loss: 14.7063 \tValidation loss: 5.6001 \tAccuracy: 69.23%\n",
            "Step: 434 \tTraining loss: 13.2639 \tValidation loss: 6.2757 \tAccuracy: 66.35%\n",
            "Step: 435 \tTraining loss: 14.7677 \tValidation loss: 5.6694 \tAccuracy: 65.38%\n",
            "Step: 436 \tTraining loss: 14.6198 \tValidation loss: 5.4192 \tAccuracy: 70.19%\n",
            "Step: 437 \tTraining loss: 13.2098 \tValidation loss: 5.6336 \tAccuracy: 65.38%\n",
            "Step: 438 \tTraining loss: 14.4295 \tValidation loss: 5.8751 \tAccuracy: 66.35%\n",
            "Step: 439 \tTraining loss: 14.2172 \tValidation loss: 6.9131 \tAccuracy: 63.46%\n",
            "Step: 440 \tTraining loss: 12.9976 \tValidation loss: 5.5948 \tAccuracy: 71.15%\n",
            "Step: 441 \tTraining loss: 14.7216 \tValidation loss: 6.0669 \tAccuracy: 67.31%\n",
            "Step: 442 \tTraining loss: 13.4396 \tValidation loss: 6.0510 \tAccuracy: 67.31%\n",
            "Step: 443 \tTraining loss: 14.8411 \tValidation loss: 5.7527 \tAccuracy: 69.23%\n",
            "Step: 444 \tTraining loss: 14.3682 \tValidation loss: 5.9482 \tAccuracy: 66.35%\n",
            "Step: 445 \tTraining loss: 14.2227 \tValidation loss: 6.4622 \tAccuracy: 66.35%\n",
            "Step: 446 \tTraining loss: 14.7167 \tValidation loss: 5.9315 \tAccuracy: 67.31%\n",
            "Step: 447 \tTraining loss: 13.3271 \tValidation loss: 5.7511 \tAccuracy: 69.23%\n",
            "Step: 448 \tTraining loss: 14.2046 \tValidation loss: 7.1569 \tAccuracy: 62.50%\n",
            "Step: 449 \tTraining loss: 14.0776 \tValidation loss: 6.6375 \tAccuracy: 60.58%\n",
            "Step: 450 \tTraining loss: 13.5138 \tValidation loss: 5.8782 \tAccuracy: 67.31%\n",
            "Step: 451 \tTraining loss: 15.7159 \tValidation loss: 7.5262 \tAccuracy: 62.50%\n",
            "Step: 452 \tTraining loss: 14.7842 \tValidation loss: 6.1509 \tAccuracy: 69.23%\n",
            "Step: 453 \tTraining loss: 13.9251 \tValidation loss: 6.4639 \tAccuracy: 61.54%\n",
            "Step: 454 \tTraining loss: 14.6088 \tValidation loss: 6.7470 \tAccuracy: 67.31%\n",
            "Step: 455 \tTraining loss: 14.6132 \tValidation loss: 6.3085 \tAccuracy: 67.31%\n",
            "Step: 456 \tTraining loss: 13.3377 \tValidation loss: 5.3568 \tAccuracy: 70.19%\n",
            "Step: 457 \tTraining loss: 13.2773 \tValidation loss: 6.1257 \tAccuracy: 63.46%\n",
            "Step: 458 \tTraining loss: 13.8150 \tValidation loss: 6.4214 \tAccuracy: 65.38%\n",
            "Step: 459 \tTraining loss: 14.5171 \tValidation loss: 5.7522 \tAccuracy: 71.15%\n",
            "Step: 460 \tTraining loss: 13.9883 \tValidation loss: 6.2828 \tAccuracy: 64.42%\n",
            "Step: 461 \tTraining loss: 13.0318 \tValidation loss: 6.7331 \tAccuracy: 63.46%\n",
            "Step: 462 \tTraining loss: 14.1320 \tValidation loss: 5.5066 \tAccuracy: 70.19%\n",
            "Step: 463 \tTraining loss: 14.6401 \tValidation loss: 6.3206 \tAccuracy: 70.19%\n",
            "Step: 464 \tTraining loss: 14.8112 \tValidation loss: 6.0543 \tAccuracy: 70.19%\n",
            "Step: 465 \tTraining loss: 13.7966 \tValidation loss: 6.0070 \tAccuracy: 64.42%\n",
            "Step: 466 \tTraining loss: 13.9145 \tValidation loss: 4.9915 \tAccuracy: 72.12%\n",
            "Step: 467 \tTraining loss: 14.4583 \tValidation loss: 6.2960 \tAccuracy: 69.23%\n",
            "Step: 468 \tTraining loss: 12.4578 \tValidation loss: 6.3600 \tAccuracy: 64.42%\n",
            "Step: 469 \tTraining loss: 14.3989 \tValidation loss: 5.6752 \tAccuracy: 64.42%\n",
            "Step: 470 \tTraining loss: 14.4782 \tValidation loss: 6.2214 \tAccuracy: 68.27%\n",
            "Step: 471 \tTraining loss: 15.0164 \tValidation loss: 5.8517 \tAccuracy: 67.31%\n",
            "Step: 472 \tTraining loss: 14.3881 \tValidation loss: 5.4682 \tAccuracy: 69.23%\n",
            "Step: 473 \tTraining loss: 13.0447 \tValidation loss: 6.0243 \tAccuracy: 64.42%\n",
            "Step: 474 \tTraining loss: 14.3361 \tValidation loss: 5.9155 \tAccuracy: 71.15%\n",
            "Step: 475 \tTraining loss: 13.3525 \tValidation loss: 6.5497 \tAccuracy: 66.35%\n",
            "Step: 476 \tTraining loss: 14.1116 \tValidation loss: 6.2214 \tAccuracy: 63.46%\n",
            "Step: 477 \tTraining loss: 13.7718 \tValidation loss: 6.1334 \tAccuracy: 69.23%\n",
            "Step: 478 \tTraining loss: 14.1457 \tValidation loss: 5.8272 \tAccuracy: 67.31%\n",
            "Step: 479 \tTraining loss: 14.5549 \tValidation loss: 5.7541 \tAccuracy: 68.27%\n",
            "Step: 480 \tTraining loss: 14.0360 \tValidation loss: 6.4927 \tAccuracy: 66.35%\n",
            "Step: 481 \tTraining loss: 13.6293 \tValidation loss: 5.5723 \tAccuracy: 66.35%\n",
            "Step: 482 \tTraining loss: 13.5128 \tValidation loss: 6.1968 \tAccuracy: 66.35%\n",
            "Step: 483 \tTraining loss: 13.6693 \tValidation loss: 6.0755 \tAccuracy: 68.27%\n",
            "Step: 484 \tTraining loss: 14.9461 \tValidation loss: 6.1338 \tAccuracy: 69.23%\n",
            "Step: 485 \tTraining loss: 12.9358 \tValidation loss: 6.4383 \tAccuracy: 70.19%\n",
            "Step: 486 \tTraining loss: 13.3199 \tValidation loss: 6.4212 \tAccuracy: 67.31%\n",
            "Step: 487 \tTraining loss: 12.1954 \tValidation loss: 6.3147 \tAccuracy: 64.42%\n",
            "Step: 488 \tTraining loss: 13.3055 \tValidation loss: 5.6937 \tAccuracy: 69.23%\n",
            "Step: 489 \tTraining loss: 13.3865 \tValidation loss: 6.2480 \tAccuracy: 65.38%\n",
            "Step: 490 \tTraining loss: 13.6940 \tValidation loss: 5.2576 \tAccuracy: 71.15%\n",
            "Step: 491 \tTraining loss: 13.6484 \tValidation loss: 6.0021 \tAccuracy: 69.23%\n",
            "Step: 492 \tTraining loss: 13.9260 \tValidation loss: 6.1813 \tAccuracy: 64.42%\n",
            "Step: 493 \tTraining loss: 13.1838 \tValidation loss: 5.9816 \tAccuracy: 64.42%\n",
            "Step: 494 \tTraining loss: 13.5105 \tValidation loss: 6.7630 \tAccuracy: 63.46%\n",
            "Step: 495 \tTraining loss: 12.7147 \tValidation loss: 6.0275 \tAccuracy: 68.27%\n",
            "Step: 496 \tTraining loss: 13.6252 \tValidation loss: 6.5690 \tAccuracy: 70.19%\n",
            "Step: 497 \tTraining loss: 13.9254 \tValidation loss: 6.0499 \tAccuracy: 68.27%\n",
            "Step: 498 \tTraining loss: 13.8524 \tValidation loss: 5.9053 \tAccuracy: 71.15%\n",
            "Step: 499 \tTraining loss: 13.3685 \tValidation loss: 6.3409 \tAccuracy: 67.31%\n",
            "Step: 500 \tTraining loss: 13.6885 \tValidation loss: 6.5846 \tAccuracy: 64.42%\n",
            "Step: 501 \tTraining loss: 13.6828 \tValidation loss: 5.5871 \tAccuracy: 65.38%\n",
            "Step: 502 \tTraining loss: 12.1839 \tValidation loss: 6.3268 \tAccuracy: 66.35%\n",
            "Step: 503 \tTraining loss: 13.4183 \tValidation loss: 6.3927 \tAccuracy: 65.38%\n",
            "Step: 504 \tTraining loss: 13.6543 \tValidation loss: 6.3012 \tAccuracy: 68.27%\n",
            "Step: 505 \tTraining loss: 14.7371 \tValidation loss: 6.6019 \tAccuracy: 66.35%\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ef1f9e7907dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_its\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-947fefb80bb8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, max_its, min_loss)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mtraining_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         \u001b[0mangle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, angle, interpolation, expand, center, fill, resample)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     \u001b[0;31m# we need to set -angle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_inverse_affine_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mangle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(img, matrix, interpolation, expand, fill)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_output_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexpand\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;31m# grid will be generated on the same device as theta and img\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gen_affine_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#train(model, max_its, min_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Results\n",
        "In the cells below we evaluate the models, (one with the Adam optimizer and one with the SGD optimizer) with the testing data set. As you can see from the printout of the results, both models perform very similarly, so for this project, the SGD and Adam optimizer are comparable. \n",
        "\n",
        "The final accuracy of the trained models tops out at just under 80%. This is decent performance considering the dataset and the training time. Better performance most likely could be acheived with a larger more comprehensive dataset and longer training time to allow the loss to decrease even further. The training time and computational requirements were definitely a limitation on this project, since to achieve these results, training took at least 1 hour running on Google Colab's provided GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "_cell_guid": "de154d7e-1447-455b-b4a7-28bd514bf366",
        "_uuid": "d11e3af8-2c8f-46d5-8b0f-269c38121410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-03-14T16:31:02.333657Z",
          "iopub.status.busy": "2022-03-14T16:31:02.333404Z",
          "iopub.status.idle": "2022-03-14T16:31:03.894833Z",
          "shell.execute_reply": "2022-03-14T16:31:03.894065Z",
          "shell.execute_reply.started": "2022-03-14T16:31:02.333627Z"
        },
        "id": "18b2mMlcEX8X",
        "jupyter": {
          "outputs_hidden": false
        },
        "outputId": "60a3aac5-98de-4946-b57f-7bb500d7f3f8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===========================\n",
            "Results with SGD optimizer:\n",
            "===========================\n",
            "Prediction: Rook-resize\t Confidence: 43.09%\t Actual label: pawn_resized\n",
            "Prediction: knight-resize\t Confidence: 99.70%\t Actual label: knight-resize\n",
            "Prediction: Rook-resize\t Confidence: 86.18%\t Actual label: Rook-resize\n",
            "Prediction: Queen-Resized\t Confidence: 80.27%\t Actual label: Queen-Resized\n",
            "Prediction: bishop_resized\t Confidence: 92.43%\t Actual label: bishop_resized\n",
            "Prediction: knight-resize\t Confidence: 72.78%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 76.24%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 85.55%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 89.55%\t Actual label: Queen-Resized\n",
            "Prediction: Queen-Resized\t Confidence: 58.92%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 68.47%\t Actual label: Queen-Resized\n",
            "Prediction: bishop_resized\t Confidence: 76.25%\t Actual label: bishop_resized\n",
            "Prediction: knight-resize\t Confidence: 77.08%\t Actual label: knight-resize\n",
            "Prediction: Rook-resize\t Confidence: 99.44%\t Actual label: Rook-resize\n",
            "Prediction: knight-resize\t Confidence: 86.49%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 91.18%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 74.00%\t Actual label: bishop_resized\n",
            "Prediction: bishop_resized\t Confidence: 79.27%\t Actual label: Rook-resize\n",
            "Prediction: Rook-resize\t Confidence: 66.44%\t Actual label: Rook-resize\n",
            "Prediction: Rook-resize\t Confidence: 57.77%\t Actual label: bishop_resized\n",
            "Prediction: pawn_resized\t Confidence: 52.18%\t Actual label: pawn_resized\n",
            "Prediction: Queen-Resized\t Confidence: 95.31%\t Actual label: Queen-Resized\n",
            "Prediction: knight-resize\t Confidence: 81.42%\t Actual label: knight-resize\n",
            "Prediction: pawn_resized\t Confidence: 84.91%\t Actual label: pawn_resized\n",
            "Prediction: Queen-Resized\t Confidence: 58.78%\t Actual label: bishop_resized\n",
            "Prediction: knight-resize\t Confidence: 85.80%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 56.27%\t Actual label: Queen-Resized\n",
            "Accuracy:\n",
            "=========\n",
            "Score 21/27\n",
            "Accuracy: 77.78%\n"
          ]
        }
      ],
      "source": [
        "total_correct = 0\n",
        "count = 0\n",
        "classes = dataset.classes\n",
        "model.load_state_dict(torch.load('./model_SGD.pt',map_location=device))\n",
        "\n",
        "print(\"===========================\")\n",
        "print(\"Results with SGD optimizer:\")\n",
        "print(\"===========================\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        yp = model(images)\n",
        "        yp = nn.Softmax(dim = 1)(yp)\n",
        "        top_p, top_class = yp.topk(1, dim = 1)\n",
        "        eq = top_class == labels.view(-1, 1)\n",
        "        # print(classes[top_class.item()])\n",
        "        total_correct += eq.sum().item()\n",
        "        \n",
        "        if count % 1 == 0:\n",
        "            print(\"Prediction: {}\\t Confidence: {:.2f}%\\t Actual label: {}\".format(classes[top_class.item()], top_p.item() * 100, classes[labels.item()]))\n",
        "        else:\n",
        "            print(f\"count%1 = {count % 1}\")\n",
        "        count += 1\n",
        "\n",
        "print(\"Accuracy:\\n=========\")\n",
        "print(f\"Score {total_correct}/{len(test_data)}\")\n",
        "print(f\"Accuracy: {(total_correct/len(test_data)) * 100:.2f}%\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===========================\n",
            "Results with Adam optimizer:\n",
            "===========================\n",
            "Prediction: knight-resize\t Confidence: 98.64%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 99.38%\t Actual label: knight-resize\n",
            "Prediction: pawn_resized\t Confidence: 41.99%\t Actual label: pawn_resized\n",
            "Prediction: knight-resize\t Confidence: 98.99%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 81.18%\t Actual label: Queen-Resized\n",
            "Prediction: bishop_resized\t Confidence: 47.86%\t Actual label: Rook-resize\n",
            "Prediction: bishop_resized\t Confidence: 76.42%\t Actual label: bishop_resized\n",
            "Prediction: Rook-resize\t Confidence: 75.67%\t Actual label: Rook-resize\n",
            "Prediction: knight-resize\t Confidence: 99.30%\t Actual label: knight-resize\n",
            "Prediction: knight-resize\t Confidence: 95.13%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 96.16%\t Actual label: Queen-Resized\n",
            "Prediction: bishop_resized\t Confidence: 37.09%\t Actual label: bishop_resized\n",
            "Prediction: bishop_resized\t Confidence: 44.53%\t Actual label: Queen-Resized\n",
            "Prediction: pawn_resized\t Confidence: 97.79%\t Actual label: pawn_resized\n",
            "Prediction: knight-resize\t Confidence: 72.79%\t Actual label: knight-resize\n",
            "Prediction: Rook-resize\t Confidence: 86.53%\t Actual label: Rook-resize\n",
            "Prediction: knight-resize\t Confidence: 98.90%\t Actual label: knight-resize\n",
            "Prediction: Queen-Resized\t Confidence: 41.97%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 59.26%\t Actual label: Queen-Resized\n",
            "Prediction: bishop_resized\t Confidence: 59.03%\t Actual label: bishop_resized\n",
            "Prediction: Queen-Resized\t Confidence: 51.27%\t Actual label: Queen-Resized\n",
            "Prediction: Rook-resize\t Confidence: 37.03%\t Actual label: knight-resize\n",
            "Prediction: Rook-resize\t Confidence: 98.09%\t Actual label: Rook-resize\n",
            "Prediction: Rook-resize\t Confidence: 47.88%\t Actual label: pawn_resized\n",
            "Prediction: pawn_resized\t Confidence: 61.92%\t Actual label: knight-resize\n",
            "Prediction: Rook-resize\t Confidence: 62.42%\t Actual label: bishop_resized\n",
            "Prediction: bishop_resized\t Confidence: 90.03%\t Actual label: bishop_resized\n",
            "Accuracy:\n",
            "=========\n",
            "Score: 20/27\n",
            "Accuracy: 74.07%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "total_correct = 0\n",
        "count = 0\n",
        "classes = dataset.classes\n",
        "model.load_state_dict(torch.load('./model_adam.pt',map_location=device))\n",
        "\n",
        "print(\"===========================\")\n",
        "print(\"Results with Adam optimizer:\")\n",
        "print(\"===========================\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        yp = model(images)\n",
        "        yp = nn.Softmax(dim = 1)(yp)\n",
        "        top_p, top_class = yp.topk(1, dim = 1)\n",
        "        eq = top_class == labels.view(-1, 1)\n",
        "        # print(classes[top_class.item()])\n",
        "        total_correct += eq.sum().item()\n",
        "        \n",
        "        if count % 1 == 0:\n",
        "            print(\"Prediction: {}\\t Confidence: {:.2f}%\\t Actual label: {}\".format(classes[top_class.item()], top_p.item() * 100, classes[labels.item()]))\n",
        "        else:\n",
        "            print(f\"count%1 = {count % 1}\")\n",
        "        count += 1\n",
        "\n",
        "print(\"Accuracy:\\n=========\")\n",
        "print(f\"Score: {total_correct}/{len(test_data)}\")\n",
        "print(f\"Accuracy: {(total_correct/len(test_data)) * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
