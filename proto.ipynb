{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66240b07-f98d-4443-aa2b-855c9ab2f5a9",
        "_uuid": "bb0e65ca-ab55-4d15-a6e0-bc6a040fa868",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.079316Z",
          "iopub.status.busy": "2022-03-14T16:24:57.078588Z",
          "iopub.status.idle": "2022-03-14T16:24:57.084741Z",
          "shell.execute_reply": "2022-03-14T16:24:57.083768Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.079255Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "augyEluuEX8E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66dafa92-4c17-4e67-abda-cfbedcf6b794",
        "_uuid": "fc94861b-96c3-4083-a1cd-b8d84c1e1c0a",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.087033Z",
          "iopub.status.busy": "2022-03-14T16:24:57.08675Z",
          "iopub.status.idle": "2022-03-14T16:24:57.106857Z",
          "shell.execute_reply": "2022-03-14T16:24:57.106144Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.086997Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp3BxLB2EX8K",
        "outputId": "68d8b09a-03b7-431a-8542-7cab11077b37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup torch device, using GPU if its available \n",
        "# Training with the CPU on my laptop is very very slow, so using a GPU with Google colab is preferred\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    warnings.warn(\"It is recommended to use train on a GPU, perhaps through Google colab, for performance\")\n",
        "    device = torch.device(\"cpu\")\n",
        "print(f\"Using {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2LSvAUvEX8N"
      },
      "outputs": [],
      "source": [
        "# Define transformations for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p = 0.4),\n",
        "    transforms.RandomRotation(30),\n",
        "    #transforms.Normalize((0.5, 0.5 ,0.5), (0.5, 0.5 ,0.5))    \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aH9UzJ0EX8P"
      },
      "outputs": [],
      "source": [
        "# Load in the dataset\n",
        "dataset_path = \"./chess_pieces\"\n",
        "dataset = ImageFolder(dataset_path, transform=train_transform)\n",
        "\n",
        "train_data, val_data = torch.utils.data.random_split(\n",
        "    dataset,\n",
        "    [int(len(dataset)*0.8), len(dataset) - int(len(dataset)*0.8)]\n",
        ")\n",
        "\n",
        "val_data, test_data = torch.utils.data.random_split(\n",
        "    val_data,\n",
        "    [int(len(val_data)*0.8), len(val_data) - int(len(val_data)*0.8)]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size = 16, shuffle = True)\n",
        "val_loader = DataLoader(val_data, batch_size = 16, shuffle = True)\n",
        "test_loader = DataLoader(test_data, batch_size = 1, shuffle = True)\n",
        "test_loader_ordered = DataLoader(test_data, batch_size = 1, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4db1772a-4fc5-48c2-97cc-b00f0e418c20",
        "_uuid": "a6644ddf-144b-4d36-a0e2-8e9a87bd93b4",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:24:57.108527Z",
          "iopub.status.busy": "2022-03-14T16:24:57.108271Z",
          "iopub.status.idle": "2022-03-14T16:24:57.115135Z",
          "shell.execute_reply": "2022-03-14T16:24:57.11424Z",
          "shell.execute_reply.started": "2022-03-14T16:24:57.108493Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "UGBXb8MYEX8Q"
      },
      "outputs": [],
      "source": [
        "# Define a neural network as a class that inherits from the torch.nn.Module class \n",
        "class ChessNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessNet, self).__init__()\n",
        "\n",
        "        # use ResNet, a deep neural network model, which is particularly good for image classification\n",
        "        self.model = torchvision.models.resnet50(pretrained = True)\n",
        "\n",
        "        for parameter in self.model.parameters():\n",
        "            parameter.requires_grad = False\n",
        "\n",
        "        # Define the model of each layer TODO: is this correct?\n",
        "        self.model.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1000),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1000, 5)\n",
        "        )\n",
        "\n",
        "    # forward propogation step TODO: is this correct? \n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d1600f55-ba5f-431f-b183-db612f9dac68",
        "_uuid": "66e06d27-17d7-4244-9e28-8979c52c791a",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:59.750758Z",
          "iopub.status.busy": "2022-03-14T16:29:59.750106Z",
          "iopub.status.idle": "2022-03-14T16:30:00.282854Z",
          "shell.execute_reply": "2022-03-14T16:30:00.28215Z",
          "shell.execute_reply.started": "2022-03-14T16:29:59.750683Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egaO9oxAEX8S",
        "outputId": "9b3cb3e9-386b-4bc2-ddb7-7992fb6a5905"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChessNet(\n",
              "  (model): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=1000, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "model = ChessNet() # instantiate the neural net class\n",
        "learning_rate = 0.00001 # define the learning rate\n",
        "# learning_rate = 0.001\n",
        "epochs = 1000 # define the epochs\n",
        "\n",
        "# use the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 0.001)\n",
        "criterion = nn.CrossEntropyLoss() # use cross entropy loss function\n",
        "min_loss = np.inf\n",
        "#file = torch.load('/kaggle/working/chess.pt')\n",
        "#model.load_state_dict(file)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:38.203117Z",
          "iopub.status.busy": "2022-03-14T16:29:38.202861Z",
          "iopub.status.idle": "2022-03-14T16:29:38.259661Z",
          "shell.execute_reply": "2022-03-14T16:29:38.258917Z",
          "shell.execute_reply.started": "2022-03-14T16:29:38.203087Z"
        },
        "trusted": true,
        "id": "fDs5K6_CEX8T"
      },
      "outputs": [],
      "source": [
        "# x, y = next(iter(train_loader))\n",
        "# x,y = x.to(device), y.to(device)\n",
        "\n",
        "# yhat = model(x)\n",
        "\n",
        "# print(yhat.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7e11bfe7-4a3a-449f-b9a5-6daa591956f1",
        "_uuid": "d2af0b73-a6f0-48a9-a844-d3b454eb6985",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:38.98681Z",
          "iopub.status.busy": "2022-03-14T16:29:38.986272Z",
          "iopub.status.idle": "2022-03-14T16:29:38.99915Z",
          "shell.execute_reply": "2022-03-14T16:29:38.998375Z",
          "shell.execute_reply.started": "2022-03-14T16:29:38.986771Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "8pWcNsNGEX8U"
      },
      "outputs": [],
      "source": [
        "def train(model, epochs, min_loss):\n",
        "    for epoch in range(epochs):\n",
        "        training_loss = 0\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            yhat = model(images)\n",
        "            loss = criterion(yhat, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            training_loss += loss.item()\n",
        "            \n",
        "            del images, labels\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "\n",
        "        valid_loss = 0\n",
        "        valid_accuracy = 0\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                yhat = model(images)\n",
        "                loss = criterion(yhat, labels)\n",
        "                valid_loss += loss.item()\n",
        "                yhat = nn.Softmax(dim = 1)(yhat)\n",
        "                top_p, top_class = yhat.topk(1, dim = 1)\n",
        "                num_correct = top_class == labels.view(-1,1)\n",
        "                valid_accuracy += num_correct.sum().item()\n",
        "\n",
        "                del images, labels\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        print(\"Epochs: {}.. \\tTraining_loss: {:.6f}.. \\tValid_loss: {:.6f}.. \\tAccuracy: {:.2f}%\".format(epoch, training_loss, valid_loss, (valid_accuracy/len(val_data))*100))\n",
        "\n",
        "        if valid_loss <= min_loss:\n",
        "            print(\"Saving Model {:.6f} ---> {:.6f}\".format(min_loss, valid_loss))\n",
        "            torch.save(model.state_dict(), \"chess.pt\")\n",
        "            min_loss = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "390812cb-c782-49ea-a31f-9e02f66b696f",
        "_uuid": "0a81eef0-af1a-4588-bd0c-5adadc3e6d02",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:29:39.587801Z",
          "iopub.status.busy": "2022-03-14T16:29:39.587267Z",
          "iopub.status.idle": "2022-03-14T16:29:48.921548Z",
          "shell.execute_reply": "2022-03-14T16:29:48.92036Z",
          "shell.execute_reply.started": "2022-03-14T16:29:39.587756Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXbpKApuEX8W",
        "outputId": "3430400e-336b-47a3-c980-c6d49a1c6b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0.. \tTraining_loss: 52.375653.. \tValid_loss: 10.991291.. \tAccuracy: 25.96%\n",
            "Saving Model inf ---> 10.991291\n",
            "Epochs: 1.. \tTraining_loss: 51.030317.. \tValid_loss: 10.877337.. \tAccuracy: 29.81%\n",
            "Saving Model 10.991291 ---> 10.877337\n",
            "Epochs: 2.. \tTraining_loss: 50.317967.. \tValid_loss: 10.666012.. \tAccuracy: 29.81%\n",
            "Saving Model 10.877337 ---> 10.666012\n",
            "Epochs: 3.. \tTraining_loss: 49.293747.. \tValid_loss: 10.582915.. \tAccuracy: 33.65%\n",
            "Saving Model 10.666012 ---> 10.582915\n",
            "Epochs: 4.. \tTraining_loss: 48.619225.. \tValid_loss: 10.328755.. \tAccuracy: 37.50%\n",
            "Saving Model 10.582915 ---> 10.328755\n",
            "Epochs: 5.. \tTraining_loss: 47.625570.. \tValid_loss: 10.219845.. \tAccuracy: 43.27%\n",
            "Saving Model 10.328755 ---> 10.219845\n",
            "Epochs: 6.. \tTraining_loss: 46.849006.. \tValid_loss: 9.976274.. \tAccuracy: 50.00%\n",
            "Saving Model 10.219845 ---> 9.976274\n",
            "Epochs: 7.. \tTraining_loss: 46.085024.. \tValid_loss: 9.915017.. \tAccuracy: 48.08%\n",
            "Saving Model 9.976274 ---> 9.915017\n",
            "Epochs: 8.. \tTraining_loss: 45.150654.. \tValid_loss: 9.703788.. \tAccuracy: 50.00%\n",
            "Saving Model 9.915017 ---> 9.703788\n",
            "Epochs: 9.. \tTraining_loss: 44.194473.. \tValid_loss: 9.655357.. \tAccuracy: 50.00%\n",
            "Saving Model 9.703788 ---> 9.655357\n",
            "Epochs: 10.. \tTraining_loss: 43.542859.. \tValid_loss: 9.254686.. \tAccuracy: 50.96%\n",
            "Saving Model 9.655357 ---> 9.254686\n",
            "Epochs: 11.. \tTraining_loss: 42.901099.. \tValid_loss: 9.292315.. \tAccuracy: 56.73%\n",
            "Epochs: 12.. \tTraining_loss: 42.032967.. \tValid_loss: 9.307468.. \tAccuracy: 57.69%\n",
            "Epochs: 13.. \tTraining_loss: 41.487732.. \tValid_loss: 9.116317.. \tAccuracy: 55.77%\n",
            "Saving Model 9.254686 ---> 9.116317\n",
            "Epochs: 14.. \tTraining_loss: 40.574964.. \tValid_loss: 8.984684.. \tAccuracy: 61.54%\n",
            "Saving Model 9.116317 ---> 8.984684\n",
            "Epochs: 15.. \tTraining_loss: 39.918631.. \tValid_loss: 8.795062.. \tAccuracy: 60.58%\n",
            "Saving Model 8.984684 ---> 8.795062\n",
            "Epochs: 16.. \tTraining_loss: 39.328807.. \tValid_loss: 8.543654.. \tAccuracy: 66.35%\n",
            "Saving Model 8.795062 ---> 8.543654\n",
            "Epochs: 17.. \tTraining_loss: 39.208090.. \tValid_loss: 8.379236.. \tAccuracy: 64.42%\n",
            "Saving Model 8.543654 ---> 8.379236\n",
            "Epochs: 18.. \tTraining_loss: 38.432931.. \tValid_loss: 8.398755.. \tAccuracy: 63.46%\n",
            "Epochs: 19.. \tTraining_loss: 37.861799.. \tValid_loss: 8.291615.. \tAccuracy: 60.58%\n",
            "Saving Model 8.379236 ---> 8.291615\n",
            "Epochs: 20.. \tTraining_loss: 37.523891.. \tValid_loss: 8.210603.. \tAccuracy: 66.35%\n",
            "Saving Model 8.291615 ---> 8.210603\n",
            "Epochs: 21.. \tTraining_loss: 36.484815.. \tValid_loss: 8.243706.. \tAccuracy: 61.54%\n",
            "Epochs: 22.. \tTraining_loss: 35.943375.. \tValid_loss: 8.185858.. \tAccuracy: 63.46%\n",
            "Saving Model 8.210603 ---> 8.185858\n",
            "Epochs: 23.. \tTraining_loss: 35.867112.. \tValid_loss: 8.009833.. \tAccuracy: 58.65%\n",
            "Saving Model 8.185858 ---> 8.009833\n",
            "Epochs: 24.. \tTraining_loss: 35.669788.. \tValid_loss: 7.746428.. \tAccuracy: 66.35%\n",
            "Saving Model 8.009833 ---> 7.746428\n",
            "Epochs: 25.. \tTraining_loss: 35.374926.. \tValid_loss: 7.736825.. \tAccuracy: 70.19%\n",
            "Saving Model 7.746428 ---> 7.736825\n",
            "Epochs: 26.. \tTraining_loss: 33.971855.. \tValid_loss: 7.664376.. \tAccuracy: 67.31%\n",
            "Saving Model 7.736825 ---> 7.664376\n",
            "Epochs: 27.. \tTraining_loss: 33.767460.. \tValid_loss: 7.765758.. \tAccuracy: 60.58%\n",
            "Epochs: 28.. \tTraining_loss: 33.824720.. \tValid_loss: 7.609221.. \tAccuracy: 64.42%\n",
            "Saving Model 7.664376 ---> 7.609221\n",
            "Epochs: 29.. \tTraining_loss: 33.416549.. \tValid_loss: 7.791710.. \tAccuracy: 61.54%\n",
            "Epochs: 30.. \tTraining_loss: 33.469987.. \tValid_loss: 7.619541.. \tAccuracy: 68.27%\n",
            "Epochs: 31.. \tTraining_loss: 32.528625.. \tValid_loss: 7.639563.. \tAccuracy: 60.58%\n",
            "Epochs: 32.. \tTraining_loss: 33.202976.. \tValid_loss: 7.249098.. \tAccuracy: 70.19%\n",
            "Saving Model 7.609221 ---> 7.249098\n",
            "Epochs: 33.. \tTraining_loss: 31.895615.. \tValid_loss: 7.650225.. \tAccuracy: 63.46%\n",
            "Epochs: 34.. \tTraining_loss: 31.913241.. \tValid_loss: 7.549247.. \tAccuracy: 66.35%\n",
            "Epochs: 35.. \tTraining_loss: 31.434517.. \tValid_loss: 7.385684.. \tAccuracy: 62.50%\n",
            "Epochs: 36.. \tTraining_loss: 31.252492.. \tValid_loss: 7.410570.. \tAccuracy: 65.38%\n",
            "Epochs: 37.. \tTraining_loss: 30.513010.. \tValid_loss: 7.328337.. \tAccuracy: 62.50%\n",
            "Epochs: 38.. \tTraining_loss: 30.218366.. \tValid_loss: 7.346436.. \tAccuracy: 62.50%\n",
            "Epochs: 39.. \tTraining_loss: 31.047308.. \tValid_loss: 7.260890.. \tAccuracy: 60.58%\n",
            "Epochs: 40.. \tTraining_loss: 30.229690.. \tValid_loss: 7.182548.. \tAccuracy: 69.23%\n",
            "Saving Model 7.249098 ---> 7.182548\n",
            "Epochs: 41.. \tTraining_loss: 29.560909.. \tValid_loss: 7.142970.. \tAccuracy: 64.42%\n",
            "Saving Model 7.182548 ---> 7.142970\n",
            "Epochs: 42.. \tTraining_loss: 28.769921.. \tValid_loss: 6.920467.. \tAccuracy: 64.42%\n",
            "Saving Model 7.142970 ---> 6.920467\n",
            "Epochs: 43.. \tTraining_loss: 29.593082.. \tValid_loss: 7.108744.. \tAccuracy: 67.31%\n",
            "Epochs: 44.. \tTraining_loss: 29.769050.. \tValid_loss: 6.878437.. \tAccuracy: 68.27%\n",
            "Saving Model 6.920467 ---> 6.878437\n",
            "Epochs: 45.. \tTraining_loss: 29.168285.. \tValid_loss: 6.897864.. \tAccuracy: 68.27%\n",
            "Epochs: 46.. \tTraining_loss: 28.948138.. \tValid_loss: 6.165913.. \tAccuracy: 71.15%\n",
            "Saving Model 6.878437 ---> 6.165913\n",
            "Epochs: 47.. \tTraining_loss: 28.703896.. \tValid_loss: 6.789903.. \tAccuracy: 66.35%\n",
            "Epochs: 48.. \tTraining_loss: 29.537848.. \tValid_loss: 6.681548.. \tAccuracy: 67.31%\n",
            "Epochs: 49.. \tTraining_loss: 28.997775.. \tValid_loss: 6.516649.. \tAccuracy: 70.19%\n",
            "Epochs: 50.. \tTraining_loss: 27.861315.. \tValid_loss: 6.312209.. \tAccuracy: 72.12%\n",
            "Epochs: 51.. \tTraining_loss: 28.034472.. \tValid_loss: 6.645105.. \tAccuracy: 65.38%\n",
            "Epochs: 52.. \tTraining_loss: 27.367948.. \tValid_loss: 6.384884.. \tAccuracy: 71.15%\n",
            "Epochs: 53.. \tTraining_loss: 27.162618.. \tValid_loss: 6.336733.. \tAccuracy: 64.42%\n",
            "Epochs: 54.. \tTraining_loss: 27.582678.. \tValid_loss: 6.924323.. \tAccuracy: 63.46%\n",
            "Epochs: 55.. \tTraining_loss: 26.636976.. \tValid_loss: 5.886545.. \tAccuracy: 73.08%\n",
            "Saving Model 6.165913 ---> 5.886545\n",
            "Epochs: 56.. \tTraining_loss: 26.817850.. \tValid_loss: 6.945225.. \tAccuracy: 66.35%\n",
            "Epochs: 57.. \tTraining_loss: 26.531984.. \tValid_loss: 6.727395.. \tAccuracy: 65.38%\n",
            "Epochs: 58.. \tTraining_loss: 26.949583.. \tValid_loss: 6.014295.. \tAccuracy: 70.19%\n",
            "Epochs: 59.. \tTraining_loss: 26.603819.. \tValid_loss: 6.374302.. \tAccuracy: 70.19%\n",
            "Epochs: 60.. \tTraining_loss: 25.079833.. \tValid_loss: 5.877831.. \tAccuracy: 73.08%\n",
            "Saving Model 5.886545 ---> 5.877831\n",
            "Epochs: 61.. \tTraining_loss: 27.010333.. \tValid_loss: 5.981396.. \tAccuracy: 71.15%\n",
            "Epochs: 62.. \tTraining_loss: 25.826928.. \tValid_loss: 6.437438.. \tAccuracy: 64.42%\n",
            "Epochs: 63.. \tTraining_loss: 25.602357.. \tValid_loss: 6.889278.. \tAccuracy: 60.58%\n",
            "Epochs: 64.. \tTraining_loss: 23.830410.. \tValid_loss: 6.119264.. \tAccuracy: 70.19%\n",
            "Epochs: 65.. \tTraining_loss: 26.479214.. \tValid_loss: 6.244264.. \tAccuracy: 72.12%\n",
            "Epochs: 66.. \tTraining_loss: 24.546775.. \tValid_loss: 6.402975.. \tAccuracy: 64.42%\n",
            "Epochs: 67.. \tTraining_loss: 25.072725.. \tValid_loss: 5.946978.. \tAccuracy: 72.12%\n",
            "Epochs: 68.. \tTraining_loss: 24.796372.. \tValid_loss: 5.759725.. \tAccuracy: 75.00%\n",
            "Saving Model 5.877831 ---> 5.759725\n",
            "Epochs: 69.. \tTraining_loss: 25.010720.. \tValid_loss: 6.427754.. \tAccuracy: 64.42%\n",
            "Epochs: 70.. \tTraining_loss: 25.148756.. \tValid_loss: 5.688254.. \tAccuracy: 69.23%\n",
            "Saving Model 5.759725 ---> 5.688254\n",
            "Epochs: 71.. \tTraining_loss: 24.996081.. \tValid_loss: 6.290539.. \tAccuracy: 63.46%\n",
            "Epochs: 72.. \tTraining_loss: 24.969563.. \tValid_loss: 6.171366.. \tAccuracy: 68.27%\n",
            "Epochs: 73.. \tTraining_loss: 25.161091.. \tValid_loss: 6.305452.. \tAccuracy: 64.42%\n",
            "Epochs: 74.. \tTraining_loss: 23.614777.. \tValid_loss: 5.791978.. \tAccuracy: 69.23%\n",
            "Epochs: 75.. \tTraining_loss: 24.256634.. \tValid_loss: 6.356832.. \tAccuracy: 62.50%\n",
            "Epochs: 76.. \tTraining_loss: 24.285172.. \tValid_loss: 5.910253.. \tAccuracy: 67.31%\n",
            "Epochs: 77.. \tTraining_loss: 24.593798.. \tValid_loss: 6.294550.. \tAccuracy: 66.35%\n",
            "Epochs: 78.. \tTraining_loss: 23.576224.. \tValid_loss: 6.133029.. \tAccuracy: 72.12%\n",
            "Epochs: 79.. \tTraining_loss: 23.605182.. \tValid_loss: 6.461693.. \tAccuracy: 68.27%\n",
            "Epochs: 80.. \tTraining_loss: 22.923015.. \tValid_loss: 6.297630.. \tAccuracy: 67.31%\n",
            "Epochs: 81.. \tTraining_loss: 23.186352.. \tValid_loss: 6.086806.. \tAccuracy: 67.31%\n",
            "Epochs: 82.. \tTraining_loss: 23.218095.. \tValid_loss: 6.429559.. \tAccuracy: 65.38%\n",
            "Epochs: 83.. \tTraining_loss: 23.456365.. \tValid_loss: 6.495752.. \tAccuracy: 68.27%\n",
            "Epochs: 84.. \tTraining_loss: 22.314370.. \tValid_loss: 5.841249.. \tAccuracy: 69.23%\n",
            "Epochs: 85.. \tTraining_loss: 22.784695.. \tValid_loss: 5.819601.. \tAccuracy: 69.23%\n",
            "Epochs: 86.. \tTraining_loss: 22.782510.. \tValid_loss: 5.415745.. \tAccuracy: 75.00%\n",
            "Saving Model 5.688254 ---> 5.415745\n",
            "Epochs: 87.. \tTraining_loss: 22.127714.. \tValid_loss: 5.602029.. \tAccuracy: 71.15%\n",
            "Epochs: 88.. \tTraining_loss: 22.619388.. \tValid_loss: 6.049054.. \tAccuracy: 69.23%\n",
            "Epochs: 89.. \tTraining_loss: 23.244598.. \tValid_loss: 5.845269.. \tAccuracy: 70.19%\n",
            "Epochs: 90.. \tTraining_loss: 21.704680.. \tValid_loss: 5.602152.. \tAccuracy: 73.08%\n",
            "Epochs: 91.. \tTraining_loss: 22.364512.. \tValid_loss: 5.477449.. \tAccuracy: 73.08%\n",
            "Epochs: 92.. \tTraining_loss: 22.023903.. \tValid_loss: 5.793000.. \tAccuracy: 72.12%\n",
            "Epochs: 93.. \tTraining_loss: 22.165772.. \tValid_loss: 5.327195.. \tAccuracy: 75.00%\n",
            "Saving Model 5.415745 ---> 5.327195\n",
            "Epochs: 94.. \tTraining_loss: 22.071156.. \tValid_loss: 5.152509.. \tAccuracy: 75.00%\n",
            "Saving Model 5.327195 ---> 5.152509\n",
            "Epochs: 95.. \tTraining_loss: 21.827371.. \tValid_loss: 5.807952.. \tAccuracy: 69.23%\n",
            "Epochs: 96.. \tTraining_loss: 21.893651.. \tValid_loss: 5.570837.. \tAccuracy: 64.42%\n",
            "Epochs: 97.. \tTraining_loss: 21.704435.. \tValid_loss: 6.455418.. \tAccuracy: 65.38%\n",
            "Epochs: 98.. \tTraining_loss: 22.451618.. \tValid_loss: 5.416792.. \tAccuracy: 69.23%\n",
            "Epochs: 99.. \tTraining_loss: 21.521985.. \tValid_loss: 5.289382.. \tAccuracy: 73.08%\n",
            "Epochs: 100.. \tTraining_loss: 22.932554.. \tValid_loss: 6.145228.. \tAccuracy: 72.12%\n",
            "Epochs: 101.. \tTraining_loss: 21.705268.. \tValid_loss: 5.154990.. \tAccuracy: 72.12%\n",
            "Epochs: 102.. \tTraining_loss: 21.441011.. \tValid_loss: 5.838899.. \tAccuracy: 65.38%\n",
            "Epochs: 103.. \tTraining_loss: 21.979565.. \tValid_loss: 5.485634.. \tAccuracy: 70.19%\n",
            "Epochs: 104.. \tTraining_loss: 21.220106.. \tValid_loss: 5.666470.. \tAccuracy: 68.27%\n",
            "Epochs: 105.. \tTraining_loss: 20.534719.. \tValid_loss: 5.714476.. \tAccuracy: 72.12%\n",
            "Epochs: 106.. \tTraining_loss: 21.226271.. \tValid_loss: 5.624501.. \tAccuracy: 71.15%\n",
            "Epochs: 107.. \tTraining_loss: 20.883217.. \tValid_loss: 5.484049.. \tAccuracy: 71.15%\n",
            "Epochs: 108.. \tTraining_loss: 21.236264.. \tValid_loss: 5.663430.. \tAccuracy: 68.27%\n",
            "Epochs: 109.. \tTraining_loss: 21.442506.. \tValid_loss: 5.796236.. \tAccuracy: 70.19%\n",
            "Epochs: 110.. \tTraining_loss: 21.045921.. \tValid_loss: 5.406071.. \tAccuracy: 70.19%\n",
            "Epochs: 111.. \tTraining_loss: 21.324374.. \tValid_loss: 5.309440.. \tAccuracy: 72.12%\n",
            "Epochs: 112.. \tTraining_loss: 20.847247.. \tValid_loss: 5.939248.. \tAccuracy: 71.15%\n",
            "Epochs: 113.. \tTraining_loss: 20.654707.. \tValid_loss: 5.735200.. \tAccuracy: 66.35%\n",
            "Epochs: 114.. \tTraining_loss: 21.426069.. \tValid_loss: 5.869387.. \tAccuracy: 70.19%\n",
            "Epochs: 115.. \tTraining_loss: 21.259044.. \tValid_loss: 5.755487.. \tAccuracy: 70.19%\n",
            "Epochs: 116.. \tTraining_loss: 22.270627.. \tValid_loss: 5.814576.. \tAccuracy: 66.35%\n",
            "Epochs: 117.. \tTraining_loss: 20.185957.. \tValid_loss: 5.697425.. \tAccuracy: 70.19%\n",
            "Epochs: 118.. \tTraining_loss: 20.179038.. \tValid_loss: 5.664006.. \tAccuracy: 66.35%\n",
            "Epochs: 119.. \tTraining_loss: 21.011022.. \tValid_loss: 5.885941.. \tAccuracy: 72.12%\n",
            "Epochs: 120.. \tTraining_loss: 19.814153.. \tValid_loss: 5.458824.. \tAccuracy: 70.19%\n",
            "Epochs: 121.. \tTraining_loss: 20.539820.. \tValid_loss: 5.481616.. \tAccuracy: 72.12%\n",
            "Epochs: 122.. \tTraining_loss: 21.185925.. \tValid_loss: 6.051792.. \tAccuracy: 65.38%\n",
            "Epochs: 123.. \tTraining_loss: 20.723285.. \tValid_loss: 5.341784.. \tAccuracy: 68.27%\n",
            "Epochs: 124.. \tTraining_loss: 20.616725.. \tValid_loss: 5.431631.. \tAccuracy: 72.12%\n",
            "Epochs: 125.. \tTraining_loss: 19.159992.. \tValid_loss: 5.674741.. \tAccuracy: 67.31%\n",
            "Epochs: 126.. \tTraining_loss: 20.144845.. \tValid_loss: 5.813316.. \tAccuracy: 73.08%\n",
            "Epochs: 127.. \tTraining_loss: 21.074708.. \tValid_loss: 5.507537.. \tAccuracy: 68.27%\n",
            "Epochs: 128.. \tTraining_loss: 19.849576.. \tValid_loss: 5.298408.. \tAccuracy: 75.96%\n",
            "Epochs: 129.. \tTraining_loss: 19.048603.. \tValid_loss: 5.988540.. \tAccuracy: 71.15%\n",
            "Epochs: 130.. \tTraining_loss: 18.839644.. \tValid_loss: 5.748536.. \tAccuracy: 69.23%\n",
            "Epochs: 131.. \tTraining_loss: 19.999032.. \tValid_loss: 5.343042.. \tAccuracy: 73.08%\n",
            "Epochs: 132.. \tTraining_loss: 19.540149.. \tValid_loss: 4.882600.. \tAccuracy: 72.12%\n",
            "Saving Model 5.152509 ---> 4.882600\n",
            "Epochs: 133.. \tTraining_loss: 18.995958.. \tValid_loss: 4.817986.. \tAccuracy: 77.88%\n",
            "Saving Model 4.882600 ---> 4.817986\n",
            "Epochs: 134.. \tTraining_loss: 19.383537.. \tValid_loss: 4.985446.. \tAccuracy: 74.04%\n",
            "Epochs: 135.. \tTraining_loss: 19.347871.. \tValid_loss: 5.955207.. \tAccuracy: 65.38%\n",
            "Epochs: 136.. \tTraining_loss: 18.802473.. \tValid_loss: 4.606550.. \tAccuracy: 78.85%\n",
            "Saving Model 4.817986 ---> 4.606550\n",
            "Epochs: 137.. \tTraining_loss: 19.302824.. \tValid_loss: 5.777187.. \tAccuracy: 67.31%\n",
            "Epochs: 138.. \tTraining_loss: 18.575267.. \tValid_loss: 5.532699.. \tAccuracy: 65.38%\n",
            "Epochs: 139.. \tTraining_loss: 18.699197.. \tValid_loss: 5.227531.. \tAccuracy: 72.12%\n",
            "Epochs: 140.. \tTraining_loss: 19.933196.. \tValid_loss: 5.750201.. \tAccuracy: 72.12%\n",
            "Epochs: 141.. \tTraining_loss: 19.354927.. \tValid_loss: 5.401806.. \tAccuracy: 73.08%\n",
            "Epochs: 142.. \tTraining_loss: 20.042917.. \tValid_loss: 6.192565.. \tAccuracy: 65.38%\n",
            "Epochs: 143.. \tTraining_loss: 19.527618.. \tValid_loss: 5.411745.. \tAccuracy: 67.31%\n",
            "Epochs: 144.. \tTraining_loss: 20.248267.. \tValid_loss: 5.147328.. \tAccuracy: 75.96%\n",
            "Epochs: 145.. \tTraining_loss: 19.374358.. \tValid_loss: 5.023070.. \tAccuracy: 75.96%\n",
            "Epochs: 146.. \tTraining_loss: 19.051362.. \tValid_loss: 5.654916.. \tAccuracy: 75.00%\n",
            "Epochs: 147.. \tTraining_loss: 18.417243.. \tValid_loss: 5.628235.. \tAccuracy: 74.04%\n",
            "Epochs: 148.. \tTraining_loss: 18.202542.. \tValid_loss: 5.398545.. \tAccuracy: 73.08%\n",
            "Epochs: 149.. \tTraining_loss: 19.024772.. \tValid_loss: 5.223600.. \tAccuracy: 71.15%\n",
            "Epochs: 150.. \tTraining_loss: 19.168012.. \tValid_loss: 5.753830.. \tAccuracy: 68.27%\n",
            "Epochs: 151.. \tTraining_loss: 17.780666.. \tValid_loss: 4.778494.. \tAccuracy: 72.12%\n",
            "Epochs: 152.. \tTraining_loss: 18.563739.. \tValid_loss: 4.794644.. \tAccuracy: 73.08%\n",
            "Epochs: 153.. \tTraining_loss: 18.501018.. \tValid_loss: 5.827518.. \tAccuracy: 71.15%\n",
            "Epochs: 154.. \tTraining_loss: 17.912507.. \tValid_loss: 5.659410.. \tAccuracy: 67.31%\n",
            "Epochs: 155.. \tTraining_loss: 20.016802.. \tValid_loss: 5.128927.. \tAccuracy: 74.04%\n",
            "Epochs: 156.. \tTraining_loss: 19.954501.. \tValid_loss: 5.258084.. \tAccuracy: 71.15%\n",
            "Epochs: 157.. \tTraining_loss: 18.765946.. \tValid_loss: 5.833495.. \tAccuracy: 72.12%\n",
            "Epochs: 158.. \tTraining_loss: 18.662586.. \tValid_loss: 5.551928.. \tAccuracy: 69.23%\n",
            "Epochs: 159.. \tTraining_loss: 18.657042.. \tValid_loss: 5.163615.. \tAccuracy: 75.00%\n",
            "Epochs: 160.. \tTraining_loss: 18.374100.. \tValid_loss: 4.959851.. \tAccuracy: 75.00%\n",
            "Epochs: 161.. \tTraining_loss: 18.898624.. \tValid_loss: 5.240113.. \tAccuracy: 74.04%\n",
            "Epochs: 162.. \tTraining_loss: 17.646487.. \tValid_loss: 5.028853.. \tAccuracy: 73.08%\n",
            "Epochs: 163.. \tTraining_loss: 19.426737.. \tValid_loss: 5.150109.. \tAccuracy: 73.08%\n",
            "Epochs: 164.. \tTraining_loss: 18.059470.. \tValid_loss: 5.834841.. \tAccuracy: 70.19%\n",
            "Epochs: 165.. \tTraining_loss: 18.605389.. \tValid_loss: 4.762072.. \tAccuracy: 81.73%\n",
            "Epochs: 166.. \tTraining_loss: 17.375487.. \tValid_loss: 5.305733.. \tAccuracy: 70.19%\n",
            "Epochs: 167.. \tTraining_loss: 18.412631.. \tValid_loss: 5.262618.. \tAccuracy: 77.88%\n",
            "Epochs: 168.. \tTraining_loss: 18.726708.. \tValid_loss: 5.281763.. \tAccuracy: 71.15%\n",
            "Epochs: 169.. \tTraining_loss: 18.144940.. \tValid_loss: 5.105989.. \tAccuracy: 70.19%\n",
            "Epochs: 170.. \tTraining_loss: 17.702479.. \tValid_loss: 5.096361.. \tAccuracy: 74.04%\n",
            "Epochs: 171.. \tTraining_loss: 18.407577.. \tValid_loss: 5.089209.. \tAccuracy: 69.23%\n",
            "Epochs: 172.. \tTraining_loss: 19.014858.. \tValid_loss: 5.300368.. \tAccuracy: 70.19%\n",
            "Epochs: 173.. \tTraining_loss: 18.557530.. \tValid_loss: 5.178752.. \tAccuracy: 72.12%\n",
            "Epochs: 174.. \tTraining_loss: 18.169435.. \tValid_loss: 5.443829.. \tAccuracy: 71.15%\n",
            "Epochs: 175.. \tTraining_loss: 17.627804.. \tValid_loss: 5.551379.. \tAccuracy: 74.04%\n",
            "Epochs: 176.. \tTraining_loss: 17.801035.. \tValid_loss: 5.143639.. \tAccuracy: 74.04%\n",
            "Epochs: 177.. \tTraining_loss: 17.931122.. \tValid_loss: 4.819277.. \tAccuracy: 71.15%\n",
            "Epochs: 178.. \tTraining_loss: 17.568411.. \tValid_loss: 5.145336.. \tAccuracy: 72.12%\n",
            "Epochs: 179.. \tTraining_loss: 17.496507.. \tValid_loss: 4.840401.. \tAccuracy: 77.88%\n",
            "Epochs: 180.. \tTraining_loss: 17.426809.. \tValid_loss: 4.962041.. \tAccuracy: 75.96%\n",
            "Epochs: 181.. \tTraining_loss: 19.509511.. \tValid_loss: 5.277791.. \tAccuracy: 71.15%\n",
            "Epochs: 182.. \tTraining_loss: 16.664557.. \tValid_loss: 5.059423.. \tAccuracy: 72.12%\n",
            "Epochs: 183.. \tTraining_loss: 17.359298.. \tValid_loss: 5.449686.. \tAccuracy: 75.00%\n",
            "Epochs: 184.. \tTraining_loss: 17.948761.. \tValid_loss: 5.611124.. \tAccuracy: 71.15%\n",
            "Epochs: 185.. \tTraining_loss: 18.408105.. \tValid_loss: 5.317512.. \tAccuracy: 71.15%\n",
            "Epochs: 186.. \tTraining_loss: 17.801472.. \tValid_loss: 4.953324.. \tAccuracy: 72.12%\n",
            "Epochs: 187.. \tTraining_loss: 16.489626.. \tValid_loss: 5.219925.. \tAccuracy: 75.00%\n",
            "Epochs: 188.. \tTraining_loss: 17.668004.. \tValid_loss: 5.438125.. \tAccuracy: 70.19%\n",
            "Epochs: 189.. \tTraining_loss: 17.835564.. \tValid_loss: 5.009206.. \tAccuracy: 70.19%\n",
            "Epochs: 190.. \tTraining_loss: 17.109050.. \tValid_loss: 5.202951.. \tAccuracy: 70.19%\n",
            "Epochs: 191.. \tTraining_loss: 17.528257.. \tValid_loss: 4.603429.. \tAccuracy: 75.96%\n",
            "Saving Model 4.606550 ---> 4.603429\n",
            "Epochs: 192.. \tTraining_loss: 17.107414.. \tValid_loss: 5.408160.. \tAccuracy: 71.15%\n",
            "Epochs: 193.. \tTraining_loss: 17.197131.. \tValid_loss: 5.258589.. \tAccuracy: 72.12%\n",
            "Epochs: 194.. \tTraining_loss: 18.235816.. \tValid_loss: 5.124936.. \tAccuracy: 68.27%\n",
            "Epochs: 195.. \tTraining_loss: 17.170591.. \tValid_loss: 5.350045.. \tAccuracy: 74.04%\n",
            "Epochs: 196.. \tTraining_loss: 17.393327.. \tValid_loss: 5.194901.. \tAccuracy: 69.23%\n",
            "Epochs: 197.. \tTraining_loss: 16.985445.. \tValid_loss: 5.101702.. \tAccuracy: 71.15%\n",
            "Epochs: 198.. \tTraining_loss: 17.380577.. \tValid_loss: 5.256617.. \tAccuracy: 71.15%\n",
            "Epochs: 199.. \tTraining_loss: 16.632566.. \tValid_loss: 5.438648.. \tAccuracy: 71.15%\n",
            "Epochs: 200.. \tTraining_loss: 17.816279.. \tValid_loss: 5.176042.. \tAccuracy: 75.96%\n",
            "Epochs: 201.. \tTraining_loss: 16.911590.. \tValid_loss: 5.367324.. \tAccuracy: 68.27%\n",
            "Epochs: 202.. \tTraining_loss: 16.503907.. \tValid_loss: 5.393350.. \tAccuracy: 75.96%\n",
            "Epochs: 203.. \tTraining_loss: 16.430206.. \tValid_loss: 5.273116.. \tAccuracy: 68.27%\n",
            "Epochs: 204.. \tTraining_loss: 15.896907.. \tValid_loss: 5.459333.. \tAccuracy: 69.23%\n",
            "Epochs: 205.. \tTraining_loss: 16.665549.. \tValid_loss: 4.847019.. \tAccuracy: 75.00%\n",
            "Epochs: 206.. \tTraining_loss: 17.597064.. \tValid_loss: 4.764191.. \tAccuracy: 79.81%\n",
            "Epochs: 207.. \tTraining_loss: 17.056647.. \tValid_loss: 5.539267.. \tAccuracy: 70.19%\n",
            "Epochs: 208.. \tTraining_loss: 17.376948.. \tValid_loss: 5.080402.. \tAccuracy: 75.96%\n",
            "Epochs: 209.. \tTraining_loss: 16.436730.. \tValid_loss: 5.687705.. \tAccuracy: 72.12%\n",
            "Epochs: 210.. \tTraining_loss: 16.580234.. \tValid_loss: 5.037981.. \tAccuracy: 73.08%\n",
            "Epochs: 211.. \tTraining_loss: 16.518730.. \tValid_loss: 5.240761.. \tAccuracy: 70.19%\n",
            "Epochs: 212.. \tTraining_loss: 17.419519.. \tValid_loss: 5.019674.. \tAccuracy: 72.12%\n",
            "Epochs: 213.. \tTraining_loss: 15.970288.. \tValid_loss: 5.227259.. \tAccuracy: 66.35%\n",
            "Epochs: 214.. \tTraining_loss: 15.666276.. \tValid_loss: 5.565119.. \tAccuracy: 69.23%\n",
            "Epochs: 215.. \tTraining_loss: 16.651750.. \tValid_loss: 5.191899.. \tAccuracy: 73.08%\n",
            "Epochs: 216.. \tTraining_loss: 16.565858.. \tValid_loss: 4.794831.. \tAccuracy: 73.08%\n",
            "Epochs: 217.. \tTraining_loss: 16.813127.. \tValid_loss: 5.952809.. \tAccuracy: 69.23%\n",
            "Epochs: 218.. \tTraining_loss: 15.722898.. \tValid_loss: 5.159329.. \tAccuracy: 71.15%\n",
            "Epochs: 219.. \tTraining_loss: 18.108510.. \tValid_loss: 5.233561.. \tAccuracy: 69.23%\n",
            "Epochs: 220.. \tTraining_loss: 16.243501.. \tValid_loss: 5.099496.. \tAccuracy: 73.08%\n",
            "Epochs: 221.. \tTraining_loss: 17.406037.. \tValid_loss: 5.583737.. \tAccuracy: 65.38%\n",
            "Epochs: 222.. \tTraining_loss: 17.225423.. \tValid_loss: 5.630031.. \tAccuracy: 69.23%\n",
            "Epochs: 223.. \tTraining_loss: 15.639784.. \tValid_loss: 5.541883.. \tAccuracy: 69.23%\n",
            "Epochs: 224.. \tTraining_loss: 15.937031.. \tValid_loss: 5.087116.. \tAccuracy: 70.19%\n",
            "Epochs: 225.. \tTraining_loss: 16.689837.. \tValid_loss: 4.823225.. \tAccuracy: 75.96%\n",
            "Epochs: 226.. \tTraining_loss: 15.756881.. \tValid_loss: 5.115298.. \tAccuracy: 74.04%\n",
            "Epochs: 227.. \tTraining_loss: 16.397022.. \tValid_loss: 5.340453.. \tAccuracy: 70.19%\n",
            "Epochs: 228.. \tTraining_loss: 15.312257.. \tValid_loss: 5.618402.. \tAccuracy: 74.04%\n",
            "Epochs: 229.. \tTraining_loss: 16.071342.. \tValid_loss: 5.176451.. \tAccuracy: 74.04%\n",
            "Epochs: 230.. \tTraining_loss: 17.015213.. \tValid_loss: 5.289024.. \tAccuracy: 70.19%\n",
            "Epochs: 231.. \tTraining_loss: 16.467478.. \tValid_loss: 5.079987.. \tAccuracy: 70.19%\n",
            "Epochs: 232.. \tTraining_loss: 14.981906.. \tValid_loss: 5.494902.. \tAccuracy: 69.23%\n",
            "Epochs: 233.. \tTraining_loss: 15.592399.. \tValid_loss: 5.260692.. \tAccuracy: 74.04%\n",
            "Epochs: 234.. \tTraining_loss: 15.526553.. \tValid_loss: 4.981046.. \tAccuracy: 74.04%\n",
            "Epochs: 235.. \tTraining_loss: 15.723814.. \tValid_loss: 5.290903.. \tAccuracy: 75.00%\n",
            "Epochs: 236.. \tTraining_loss: 16.250784.. \tValid_loss: 5.757816.. \tAccuracy: 67.31%\n",
            "Epochs: 237.. \tTraining_loss: 15.787382.. \tValid_loss: 4.896121.. \tAccuracy: 71.15%\n",
            "Epochs: 238.. \tTraining_loss: 14.904478.. \tValid_loss: 4.981114.. \tAccuracy: 71.15%\n",
            "Epochs: 239.. \tTraining_loss: 16.819944.. \tValid_loss: 5.050928.. \tAccuracy: 72.12%\n",
            "Epochs: 240.. \tTraining_loss: 15.060700.. \tValid_loss: 5.162573.. \tAccuracy: 71.15%\n",
            "Epochs: 241.. \tTraining_loss: 14.894318.. \tValid_loss: 5.110272.. \tAccuracy: 73.08%\n",
            "Epochs: 242.. \tTraining_loss: 15.795276.. \tValid_loss: 5.194995.. \tAccuracy: 75.00%\n",
            "Epochs: 243.. \tTraining_loss: 15.886877.. \tValid_loss: 5.208977.. \tAccuracy: 73.08%\n",
            "Epochs: 244.. \tTraining_loss: 16.797862.. \tValid_loss: 5.514562.. \tAccuracy: 72.12%\n",
            "Epochs: 245.. \tTraining_loss: 15.940017.. \tValid_loss: 5.037132.. \tAccuracy: 75.96%\n",
            "Epochs: 246.. \tTraining_loss: 14.629604.. \tValid_loss: 5.122721.. \tAccuracy: 72.12%\n",
            "Epochs: 247.. \tTraining_loss: 15.341790.. \tValid_loss: 5.334202.. \tAccuracy: 70.19%\n",
            "Epochs: 248.. \tTraining_loss: 16.524656.. \tValid_loss: 5.037391.. \tAccuracy: 74.04%\n",
            "Epochs: 249.. \tTraining_loss: 15.829418.. \tValid_loss: 5.233555.. \tAccuracy: 73.08%\n",
            "Epochs: 250.. \tTraining_loss: 15.602696.. \tValid_loss: 5.652077.. \tAccuracy: 67.31%\n",
            "Epochs: 251.. \tTraining_loss: 16.337741.. \tValid_loss: 4.928270.. \tAccuracy: 74.04%\n",
            "Epochs: 252.. \tTraining_loss: 16.240971.. \tValid_loss: 5.131039.. \tAccuracy: 71.15%\n",
            "Epochs: 253.. \tTraining_loss: 16.126872.. \tValid_loss: 5.331181.. \tAccuracy: 67.31%\n",
            "Epochs: 254.. \tTraining_loss: 15.699172.. \tValid_loss: 4.531323.. \tAccuracy: 76.92%\n",
            "Saving Model 4.603429 ---> 4.531323\n",
            "Epochs: 255.. \tTraining_loss: 16.172641.. \tValid_loss: 4.746834.. \tAccuracy: 75.00%\n",
            "Epochs: 256.. \tTraining_loss: 15.706006.. \tValid_loss: 4.782381.. \tAccuracy: 72.12%\n",
            "Epochs: 257.. \tTraining_loss: 14.848806.. \tValid_loss: 5.378182.. \tAccuracy: 65.38%\n",
            "Epochs: 258.. \tTraining_loss: 14.912728.. \tValid_loss: 5.077537.. \tAccuracy: 71.15%\n",
            "Epochs: 259.. \tTraining_loss: 14.364106.. \tValid_loss: 5.254230.. \tAccuracy: 72.12%\n",
            "Epochs: 260.. \tTraining_loss: 15.511686.. \tValid_loss: 5.603004.. \tAccuracy: 70.19%\n",
            "Epochs: 261.. \tTraining_loss: 15.742687.. \tValid_loss: 5.108139.. \tAccuracy: 71.15%\n",
            "Epochs: 262.. \tTraining_loss: 15.990907.. \tValid_loss: 4.820629.. \tAccuracy: 72.12%\n",
            "Epochs: 263.. \tTraining_loss: 14.006162.. \tValid_loss: 4.238794.. \tAccuracy: 75.96%\n",
            "Saving Model 4.531323 ---> 4.238794\n",
            "Epochs: 264.. \tTraining_loss: 15.021198.. \tValid_loss: 5.493082.. \tAccuracy: 71.15%\n",
            "Epochs: 265.. \tTraining_loss: 14.298263.. \tValid_loss: 5.133042.. \tAccuracy: 68.27%\n",
            "Epochs: 266.. \tTraining_loss: 14.542105.. \tValid_loss: 4.857498.. \tAccuracy: 75.96%\n",
            "Epochs: 267.. \tTraining_loss: 15.508417.. \tValid_loss: 4.935835.. \tAccuracy: 72.12%\n",
            "Epochs: 268.. \tTraining_loss: 14.291889.. \tValid_loss: 5.259185.. \tAccuracy: 77.88%\n",
            "Epochs: 269.. \tTraining_loss: 14.844674.. \tValid_loss: 4.991008.. \tAccuracy: 75.00%\n",
            "Epochs: 270.. \tTraining_loss: 14.533800.. \tValid_loss: 5.372646.. \tAccuracy: 75.00%\n",
            "Epochs: 271.. \tTraining_loss: 15.276970.. \tValid_loss: 6.302655.. \tAccuracy: 67.31%\n",
            "Epochs: 272.. \tTraining_loss: 14.575641.. \tValid_loss: 5.268787.. \tAccuracy: 71.15%\n",
            "Epochs: 273.. \tTraining_loss: 14.661712.. \tValid_loss: 5.561879.. \tAccuracy: 70.19%\n",
            "Epochs: 274.. \tTraining_loss: 15.733452.. \tValid_loss: 5.433672.. \tAccuracy: 67.31%\n",
            "Epochs: 275.. \tTraining_loss: 14.013311.. \tValid_loss: 5.793264.. \tAccuracy: 75.00%\n",
            "Epochs: 276.. \tTraining_loss: 14.868756.. \tValid_loss: 5.431144.. \tAccuracy: 71.15%\n",
            "Epochs: 277.. \tTraining_loss: 14.993797.. \tValid_loss: 5.200779.. \tAccuracy: 71.15%\n",
            "Epochs: 278.. \tTraining_loss: 16.499613.. \tValid_loss: 5.314236.. \tAccuracy: 76.92%\n",
            "Epochs: 279.. \tTraining_loss: 13.811582.. \tValid_loss: 5.403739.. \tAccuracy: 72.12%\n",
            "Epochs: 280.. \tTraining_loss: 13.866615.. \tValid_loss: 4.766128.. \tAccuracy: 76.92%\n",
            "Epochs: 281.. \tTraining_loss: 14.918618.. \tValid_loss: 5.164192.. \tAccuracy: 68.27%\n",
            "Epochs: 282.. \tTraining_loss: 14.815395.. \tValid_loss: 4.918121.. \tAccuracy: 75.96%\n",
            "Epochs: 283.. \tTraining_loss: 16.040293.. \tValid_loss: 5.453468.. \tAccuracy: 71.15%\n",
            "Epochs: 284.. \tTraining_loss: 15.497173.. \tValid_loss: 4.465421.. \tAccuracy: 75.96%\n",
            "Epochs: 285.. \tTraining_loss: 13.432927.. \tValid_loss: 4.743423.. \tAccuracy: 73.08%\n",
            "Epochs: 286.. \tTraining_loss: 16.411485.. \tValid_loss: 5.505906.. \tAccuracy: 68.27%\n",
            "Epochs: 287.. \tTraining_loss: 15.841534.. \tValid_loss: 5.095978.. \tAccuracy: 75.00%\n",
            "Epochs: 288.. \tTraining_loss: 14.965848.. \tValid_loss: 5.087465.. \tAccuracy: 71.15%\n",
            "Epochs: 289.. \tTraining_loss: 14.507587.. \tValid_loss: 5.827983.. \tAccuracy: 71.15%\n",
            "Epochs: 290.. \tTraining_loss: 16.654116.. \tValid_loss: 5.939130.. \tAccuracy: 67.31%\n",
            "Epochs: 291.. \tTraining_loss: 15.374449.. \tValid_loss: 4.697761.. \tAccuracy: 76.92%\n",
            "Epochs: 292.. \tTraining_loss: 15.479854.. \tValid_loss: 5.419189.. \tAccuracy: 70.19%\n",
            "Epochs: 293.. \tTraining_loss: 14.525728.. \tValid_loss: 5.418828.. \tAccuracy: 70.19%\n",
            "Epochs: 294.. \tTraining_loss: 15.115894.. \tValid_loss: 5.365475.. \tAccuracy: 66.35%\n",
            "Epochs: 295.. \tTraining_loss: 14.187113.. \tValid_loss: 5.555360.. \tAccuracy: 70.19%\n",
            "Epochs: 296.. \tTraining_loss: 14.466414.. \tValid_loss: 5.608037.. \tAccuracy: 75.96%\n",
            "Epochs: 297.. \tTraining_loss: 14.855059.. \tValid_loss: 5.312742.. \tAccuracy: 70.19%\n",
            "Epochs: 298.. \tTraining_loss: 14.827333.. \tValid_loss: 5.943648.. \tAccuracy: 67.31%\n",
            "Epochs: 299.. \tTraining_loss: 13.990292.. \tValid_loss: 4.975194.. \tAccuracy: 73.08%\n",
            "Epochs: 300.. \tTraining_loss: 15.961934.. \tValid_loss: 5.592387.. \tAccuracy: 69.23%\n",
            "Epochs: 301.. \tTraining_loss: 16.081316.. \tValid_loss: 5.408810.. \tAccuracy: 73.08%\n",
            "Epochs: 302.. \tTraining_loss: 15.315604.. \tValid_loss: 4.890166.. \tAccuracy: 71.15%\n",
            "Epochs: 303.. \tTraining_loss: 13.725404.. \tValid_loss: 5.172019.. \tAccuracy: 79.81%\n",
            "Epochs: 304.. \tTraining_loss: 15.316912.. \tValid_loss: 5.312421.. \tAccuracy: 71.15%\n",
            "Epochs: 305.. \tTraining_loss: 14.537575.. \tValid_loss: 5.067230.. \tAccuracy: 66.35%\n",
            "Epochs: 306.. \tTraining_loss: 13.896128.. \tValid_loss: 5.738838.. \tAccuracy: 66.35%\n",
            "Epochs: 307.. \tTraining_loss: 15.885224.. \tValid_loss: 4.942143.. \tAccuracy: 68.27%\n",
            "Epochs: 308.. \tTraining_loss: 14.122723.. \tValid_loss: 4.729637.. \tAccuracy: 77.88%\n",
            "Epochs: 309.. \tTraining_loss: 13.964904.. \tValid_loss: 5.153818.. \tAccuracy: 76.92%\n",
            "Epochs: 310.. \tTraining_loss: 14.092964.. \tValid_loss: 5.141467.. \tAccuracy: 68.27%\n",
            "Epochs: 311.. \tTraining_loss: 14.842104.. \tValid_loss: 5.573720.. \tAccuracy: 68.27%\n",
            "Epochs: 312.. \tTraining_loss: 15.326149.. \tValid_loss: 5.444536.. \tAccuracy: 70.19%\n",
            "Epochs: 313.. \tTraining_loss: 13.353234.. \tValid_loss: 5.030194.. \tAccuracy: 80.77%\n",
            "Epochs: 314.. \tTraining_loss: 13.401280.. \tValid_loss: 5.491462.. \tAccuracy: 76.92%\n",
            "Epochs: 315.. \tTraining_loss: 14.862049.. \tValid_loss: 5.240747.. \tAccuracy: 74.04%\n",
            "Epochs: 316.. \tTraining_loss: 14.583424.. \tValid_loss: 5.435971.. \tAccuracy: 71.15%\n",
            "Epochs: 317.. \tTraining_loss: 14.703071.. \tValid_loss: 5.566386.. \tAccuracy: 71.15%\n",
            "Epochs: 318.. \tTraining_loss: 14.799199.. \tValid_loss: 4.598098.. \tAccuracy: 75.00%\n",
            "Epochs: 319.. \tTraining_loss: 13.747638.. \tValid_loss: 6.062526.. \tAccuracy: 71.15%\n",
            "Epochs: 320.. \tTraining_loss: 13.800443.. \tValid_loss: 5.387961.. \tAccuracy: 69.23%\n",
            "Epochs: 321.. \tTraining_loss: 14.287137.. \tValid_loss: 5.993416.. \tAccuracy: 67.31%\n",
            "Epochs: 322.. \tTraining_loss: 15.437810.. \tValid_loss: 5.582703.. \tAccuracy: 77.88%\n",
            "Epochs: 323.. \tTraining_loss: 15.073840.. \tValid_loss: 5.053250.. \tAccuracy: 74.04%\n",
            "Epochs: 324.. \tTraining_loss: 14.531144.. \tValid_loss: 4.651720.. \tAccuracy: 73.08%\n",
            "Epochs: 325.. \tTraining_loss: 14.977236.. \tValid_loss: 5.897738.. \tAccuracy: 73.08%\n",
            "Epochs: 326.. \tTraining_loss: 14.996964.. \tValid_loss: 5.820065.. \tAccuracy: 66.35%\n",
            "Epochs: 327.. \tTraining_loss: 13.551156.. \tValid_loss: 4.767518.. \tAccuracy: 75.96%\n",
            "Epochs: 328.. \tTraining_loss: 14.328564.. \tValid_loss: 5.219030.. \tAccuracy: 74.04%\n",
            "Epochs: 329.. \tTraining_loss: 12.729140.. \tValid_loss: 5.369977.. \tAccuracy: 69.23%\n",
            "Epochs: 330.. \tTraining_loss: 13.442620.. \tValid_loss: 5.600609.. \tAccuracy: 73.08%\n",
            "Epochs: 331.. \tTraining_loss: 13.229287.. \tValid_loss: 5.541326.. \tAccuracy: 75.00%\n",
            "Epochs: 332.. \tTraining_loss: 13.257688.. \tValid_loss: 4.763116.. \tAccuracy: 77.88%\n",
            "Epochs: 333.. \tTraining_loss: 13.641679.. \tValid_loss: 5.793490.. \tAccuracy: 70.19%\n",
            "Epochs: 334.. \tTraining_loss: 13.900306.. \tValid_loss: 5.400050.. \tAccuracy: 74.04%\n",
            "Epochs: 335.. \tTraining_loss: 14.947094.. \tValid_loss: 5.036193.. \tAccuracy: 74.04%\n",
            "Epochs: 336.. \tTraining_loss: 15.452267.. \tValid_loss: 4.937845.. \tAccuracy: 72.12%\n",
            "Epochs: 337.. \tTraining_loss: 12.650478.. \tValid_loss: 5.131432.. \tAccuracy: 73.08%\n",
            "Epochs: 338.. \tTraining_loss: 14.777007.. \tValid_loss: 5.411680.. \tAccuracy: 73.08%\n",
            "Epochs: 339.. \tTraining_loss: 14.744765.. \tValid_loss: 4.641856.. \tAccuracy: 74.04%\n",
            "Epochs: 340.. \tTraining_loss: 13.668611.. \tValid_loss: 5.584559.. \tAccuracy: 74.04%\n",
            "Epochs: 341.. \tTraining_loss: 13.962314.. \tValid_loss: 5.295286.. \tAccuracy: 73.08%\n",
            "Epochs: 342.. \tTraining_loss: 15.263543.. \tValid_loss: 5.053511.. \tAccuracy: 70.19%\n",
            "Epochs: 343.. \tTraining_loss: 13.062548.. \tValid_loss: 5.479773.. \tAccuracy: 75.00%\n",
            "Epochs: 344.. \tTraining_loss: 13.872808.. \tValid_loss: 6.062089.. \tAccuracy: 71.15%\n",
            "Epochs: 345.. \tTraining_loss: 11.528554.. \tValid_loss: 5.506631.. \tAccuracy: 71.15%\n",
            "Epochs: 346.. \tTraining_loss: 13.132722.. \tValid_loss: 6.046554.. \tAccuracy: 74.04%\n",
            "Epochs: 347.. \tTraining_loss: 14.502488.. \tValid_loss: 5.189306.. \tAccuracy: 72.12%\n",
            "Epochs: 348.. \tTraining_loss: 14.089916.. \tValid_loss: 5.907688.. \tAccuracy: 72.12%\n",
            "Epochs: 349.. \tTraining_loss: 13.367816.. \tValid_loss: 4.438339.. \tAccuracy: 73.08%\n",
            "Epochs: 350.. \tTraining_loss: 14.073214.. \tValid_loss: 5.354941.. \tAccuracy: 74.04%\n",
            "Epochs: 351.. \tTraining_loss: 13.843483.. \tValid_loss: 5.094271.. \tAccuracy: 75.00%\n",
            "Epochs: 352.. \tTraining_loss: 14.263937.. \tValid_loss: 5.740027.. \tAccuracy: 70.19%\n",
            "Epochs: 353.. \tTraining_loss: 13.861120.. \tValid_loss: 5.624775.. \tAccuracy: 67.31%\n",
            "Epochs: 354.. \tTraining_loss: 12.892607.. \tValid_loss: 4.750850.. \tAccuracy: 73.08%\n",
            "Epochs: 355.. \tTraining_loss: 14.775938.. \tValid_loss: 5.269225.. \tAccuracy: 74.04%\n",
            "Epochs: 356.. \tTraining_loss: 13.284218.. \tValid_loss: 5.717953.. \tAccuracy: 69.23%\n",
            "Epochs: 357.. \tTraining_loss: 14.495883.. \tValid_loss: 4.668964.. \tAccuracy: 76.92%\n",
            "Epochs: 358.. \tTraining_loss: 12.298527.. \tValid_loss: 4.840284.. \tAccuracy: 73.08%\n",
            "Epochs: 359.. \tTraining_loss: 12.910370.. \tValid_loss: 5.806153.. \tAccuracy: 73.08%\n",
            "Epochs: 360.. \tTraining_loss: 15.392745.. \tValid_loss: 5.709970.. \tAccuracy: 74.04%\n",
            "Epochs: 361.. \tTraining_loss: 14.051135.. \tValid_loss: 5.129079.. \tAccuracy: 72.12%\n",
            "Epochs: 362.. \tTraining_loss: 14.228114.. \tValid_loss: 5.065280.. \tAccuracy: 74.04%\n",
            "Epochs: 363.. \tTraining_loss: 12.016978.. \tValid_loss: 5.291175.. \tAccuracy: 73.08%\n",
            "Epochs: 364.. \tTraining_loss: 13.503591.. \tValid_loss: 5.234433.. \tAccuracy: 78.85%\n",
            "Epochs: 365.. \tTraining_loss: 13.809956.. \tValid_loss: 5.304295.. \tAccuracy: 75.00%\n",
            "Epochs: 366.. \tTraining_loss: 12.600741.. \tValid_loss: 5.278902.. \tAccuracy: 73.08%\n",
            "Epochs: 367.. \tTraining_loss: 13.781671.. \tValid_loss: 5.290018.. \tAccuracy: 72.12%\n",
            "Epochs: 368.. \tTraining_loss: 13.703412.. \tValid_loss: 4.871781.. \tAccuracy: 74.04%\n",
            "Epochs: 369.. \tTraining_loss: 13.263266.. \tValid_loss: 5.302349.. \tAccuracy: 67.31%\n",
            "Epochs: 370.. \tTraining_loss: 13.949305.. \tValid_loss: 5.227039.. \tAccuracy: 74.04%\n",
            "Epochs: 371.. \tTraining_loss: 13.151376.. \tValid_loss: 5.756766.. \tAccuracy: 75.96%\n",
            "Epochs: 372.. \tTraining_loss: 13.362218.. \tValid_loss: 5.774232.. \tAccuracy: 72.12%\n",
            "Epochs: 373.. \tTraining_loss: 14.098386.. \tValid_loss: 5.563760.. \tAccuracy: 74.04%\n",
            "Epochs: 374.. \tTraining_loss: 12.893945.. \tValid_loss: 4.953383.. \tAccuracy: 74.04%\n",
            "Epochs: 375.. \tTraining_loss: 15.001980.. \tValid_loss: 5.314936.. \tAccuracy: 73.08%\n",
            "Epochs: 376.. \tTraining_loss: 15.248022.. \tValid_loss: 5.025474.. \tAccuracy: 75.00%\n",
            "Epochs: 377.. \tTraining_loss: 12.919570.. \tValid_loss: 5.393325.. \tAccuracy: 71.15%\n",
            "Epochs: 378.. \tTraining_loss: 13.933900.. \tValid_loss: 5.773510.. \tAccuracy: 70.19%\n",
            "Epochs: 379.. \tTraining_loss: 14.612200.. \tValid_loss: 5.019248.. \tAccuracy: 75.96%\n",
            "Epochs: 380.. \tTraining_loss: 14.798743.. \tValid_loss: 5.528684.. \tAccuracy: 68.27%\n",
            "Epochs: 381.. \tTraining_loss: 12.617079.. \tValid_loss: 5.637992.. \tAccuracy: 68.27%\n",
            "Epochs: 382.. \tTraining_loss: 12.050568.. \tValid_loss: 5.289136.. \tAccuracy: 74.04%\n",
            "Epochs: 383.. \tTraining_loss: 13.328355.. \tValid_loss: 4.986537.. \tAccuracy: 76.92%\n",
            "Epochs: 384.. \tTraining_loss: 13.505939.. \tValid_loss: 5.672329.. \tAccuracy: 71.15%\n",
            "Epochs: 385.. \tTraining_loss: 12.558615.. \tValid_loss: 5.916666.. \tAccuracy: 68.27%\n",
            "Epochs: 386.. \tTraining_loss: 11.988614.. \tValid_loss: 5.323419.. \tAccuracy: 70.19%\n",
            "Epochs: 387.. \tTraining_loss: 12.294966.. \tValid_loss: 5.731450.. \tAccuracy: 74.04%\n",
            "Epochs: 388.. \tTraining_loss: 12.921040.. \tValid_loss: 4.421680.. \tAccuracy: 79.81%\n",
            "Epochs: 389.. \tTraining_loss: 14.410824.. \tValid_loss: 5.822639.. \tAccuracy: 72.12%\n",
            "Epochs: 390.. \tTraining_loss: 14.501679.. \tValid_loss: 4.630816.. \tAccuracy: 74.04%\n",
            "Epochs: 391.. \tTraining_loss: 14.548866.. \tValid_loss: 5.542565.. \tAccuracy: 75.00%\n",
            "Epochs: 392.. \tTraining_loss: 13.309649.. \tValid_loss: 5.977149.. \tAccuracy: 69.23%\n",
            "Epochs: 393.. \tTraining_loss: 12.985254.. \tValid_loss: 5.296477.. \tAccuracy: 76.92%\n",
            "Epochs: 394.. \tTraining_loss: 14.521132.. \tValid_loss: 4.860831.. \tAccuracy: 74.04%\n",
            "Epochs: 395.. \tTraining_loss: 11.962562.. \tValid_loss: 5.897456.. \tAccuracy: 76.92%\n",
            "Epochs: 396.. \tTraining_loss: 12.334724.. \tValid_loss: 5.216041.. \tAccuracy: 74.04%\n",
            "Epochs: 397.. \tTraining_loss: 13.544044.. \tValid_loss: 6.438888.. \tAccuracy: 71.15%\n",
            "Epochs: 398.. \tTraining_loss: 13.031837.. \tValid_loss: 5.399208.. \tAccuracy: 72.12%\n",
            "Epochs: 399.. \tTraining_loss: 12.407534.. \tValid_loss: 5.546295.. \tAccuracy: 70.19%\n",
            "Epochs: 400.. \tTraining_loss: 13.276406.. \tValid_loss: 6.620272.. \tAccuracy: 74.04%\n",
            "Epochs: 401.. \tTraining_loss: 12.450063.. \tValid_loss: 4.779832.. \tAccuracy: 72.12%\n",
            "Epochs: 402.. \tTraining_loss: 12.430362.. \tValid_loss: 4.964684.. \tAccuracy: 77.88%\n",
            "Epochs: 403.. \tTraining_loss: 13.168734.. \tValid_loss: 5.655480.. \tAccuracy: 72.12%\n",
            "Epochs: 404.. \tTraining_loss: 13.184142.. \tValid_loss: 6.003877.. \tAccuracy: 65.38%\n",
            "Epochs: 405.. \tTraining_loss: 13.197122.. \tValid_loss: 5.454529.. \tAccuracy: 70.19%\n",
            "Epochs: 406.. \tTraining_loss: 12.236811.. \tValid_loss: 5.145153.. \tAccuracy: 75.00%\n",
            "Epochs: 407.. \tTraining_loss: 12.974595.. \tValid_loss: 5.611819.. \tAccuracy: 71.15%\n",
            "Epochs: 408.. \tTraining_loss: 13.200674.. \tValid_loss: 5.050446.. \tAccuracy: 72.12%\n",
            "Epochs: 409.. \tTraining_loss: 13.214366.. \tValid_loss: 4.632338.. \tAccuracy: 75.00%\n",
            "Epochs: 410.. \tTraining_loss: 13.493365.. \tValid_loss: 5.354030.. \tAccuracy: 79.81%\n",
            "Epochs: 411.. \tTraining_loss: 12.320128.. \tValid_loss: 6.132995.. \tAccuracy: 66.35%\n",
            "Epochs: 412.. \tTraining_loss: 12.878729.. \tValid_loss: 5.314359.. \tAccuracy: 70.19%\n",
            "Epochs: 413.. \tTraining_loss: 12.779330.. \tValid_loss: 5.684179.. \tAccuracy: 66.35%\n",
            "Epochs: 414.. \tTraining_loss: 11.694278.. \tValid_loss: 5.435455.. \tAccuracy: 71.15%\n",
            "Epochs: 415.. \tTraining_loss: 13.579220.. \tValid_loss: 5.391656.. \tAccuracy: 71.15%\n",
            "Epochs: 416.. \tTraining_loss: 11.167657.. \tValid_loss: 5.949500.. \tAccuracy: 74.04%\n",
            "Epochs: 417.. \tTraining_loss: 14.356948.. \tValid_loss: 5.201162.. \tAccuracy: 73.08%\n",
            "Epochs: 418.. \tTraining_loss: 11.669474.. \tValid_loss: 5.275310.. \tAccuracy: 72.12%\n",
            "Epochs: 419.. \tTraining_loss: 12.221172.. \tValid_loss: 5.627668.. \tAccuracy: 74.04%\n",
            "Epochs: 420.. \tTraining_loss: 12.767525.. \tValid_loss: 5.165234.. \tAccuracy: 73.08%\n",
            "Epochs: 421.. \tTraining_loss: 14.386429.. \tValid_loss: 5.840942.. \tAccuracy: 69.23%\n",
            "Epochs: 422.. \tTraining_loss: 11.716720.. \tValid_loss: 5.661417.. \tAccuracy: 74.04%\n",
            "Epochs: 423.. \tTraining_loss: 12.285308.. \tValid_loss: 5.470003.. \tAccuracy: 69.23%\n",
            "Epochs: 424.. \tTraining_loss: 13.097155.. \tValid_loss: 5.724244.. \tAccuracy: 68.27%\n",
            "Epochs: 425.. \tTraining_loss: 12.747720.. \tValid_loss: 5.290308.. \tAccuracy: 76.92%\n",
            "Epochs: 426.. \tTraining_loss: 12.140265.. \tValid_loss: 5.957309.. \tAccuracy: 66.35%\n",
            "Epochs: 427.. \tTraining_loss: 12.807836.. \tValid_loss: 4.867510.. \tAccuracy: 75.96%\n",
            "Epochs: 428.. \tTraining_loss: 13.221114.. \tValid_loss: 5.486482.. \tAccuracy: 72.12%\n",
            "Epochs: 429.. \tTraining_loss: 13.446774.. \tValid_loss: 4.672512.. \tAccuracy: 74.04%\n",
            "Epochs: 430.. \tTraining_loss: 13.184307.. \tValid_loss: 5.447907.. \tAccuracy: 73.08%\n",
            "Epochs: 431.. \tTraining_loss: 13.323502.. \tValid_loss: 5.630506.. \tAccuracy: 74.04%\n",
            "Epochs: 432.. \tTraining_loss: 12.567470.. \tValid_loss: 5.046836.. \tAccuracy: 73.08%\n",
            "Epochs: 433.. \tTraining_loss: 12.820066.. \tValid_loss: 5.192678.. \tAccuracy: 75.00%\n",
            "Epochs: 434.. \tTraining_loss: 12.776861.. \tValid_loss: 4.761517.. \tAccuracy: 70.19%\n",
            "Epochs: 435.. \tTraining_loss: 12.862593.. \tValid_loss: 5.712368.. \tAccuracy: 75.00%\n",
            "Epochs: 436.. \tTraining_loss: 13.332428.. \tValid_loss: 5.825560.. \tAccuracy: 66.35%\n",
            "Epochs: 437.. \tTraining_loss: 11.905598.. \tValid_loss: 5.145327.. \tAccuracy: 70.19%\n",
            "Epochs: 438.. \tTraining_loss: 12.538979.. \tValid_loss: 5.356460.. \tAccuracy: 70.19%\n",
            "Epochs: 439.. \tTraining_loss: 12.314054.. \tValid_loss: 4.468830.. \tAccuracy: 72.12%\n",
            "Epochs: 440.. \tTraining_loss: 12.191309.. \tValid_loss: 5.118039.. \tAccuracy: 76.92%\n",
            "Epochs: 441.. \tTraining_loss: 11.089893.. \tValid_loss: 5.276478.. \tAccuracy: 73.08%\n",
            "Epochs: 442.. \tTraining_loss: 11.920720.. \tValid_loss: 5.548383.. \tAccuracy: 71.15%\n",
            "Epochs: 443.. \tTraining_loss: 13.223404.. \tValid_loss: 5.813039.. \tAccuracy: 72.12%\n",
            "Epochs: 444.. \tTraining_loss: 13.028931.. \tValid_loss: 4.874241.. \tAccuracy: 71.15%\n",
            "Epochs: 445.. \tTraining_loss: 12.619945.. \tValid_loss: 4.929747.. \tAccuracy: 73.08%\n",
            "Epochs: 446.. \tTraining_loss: 12.099251.. \tValid_loss: 5.687081.. \tAccuracy: 71.15%\n",
            "Epochs: 447.. \tTraining_loss: 11.541841.. \tValid_loss: 5.979455.. \tAccuracy: 71.15%\n",
            "Epochs: 448.. \tTraining_loss: 12.415603.. \tValid_loss: 5.243519.. \tAccuracy: 72.12%\n",
            "Epochs: 449.. \tTraining_loss: 11.015671.. \tValid_loss: 5.221659.. \tAccuracy: 76.92%\n",
            "Epochs: 450.. \tTraining_loss: 11.541454.. \tValid_loss: 5.200047.. \tAccuracy: 70.19%\n",
            "Epochs: 451.. \tTraining_loss: 12.292125.. \tValid_loss: 5.992138.. \tAccuracy: 73.08%\n",
            "Epochs: 452.. \tTraining_loss: 12.155285.. \tValid_loss: 5.034321.. \tAccuracy: 72.12%\n",
            "Epochs: 453.. \tTraining_loss: 12.341276.. \tValid_loss: 4.043045.. \tAccuracy: 78.85%\n",
            "Saving Model 4.238794 ---> 4.043045\n",
            "Epochs: 454.. \tTraining_loss: 12.296438.. \tValid_loss: 5.344890.. \tAccuracy: 76.92%\n",
            "Epochs: 455.. \tTraining_loss: 10.631190.. \tValid_loss: 6.219511.. \tAccuracy: 66.35%\n",
            "Epochs: 456.. \tTraining_loss: 11.270635.. \tValid_loss: 5.475905.. \tAccuracy: 73.08%\n",
            "Epochs: 457.. \tTraining_loss: 12.905391.. \tValid_loss: 6.085267.. \tAccuracy: 72.12%\n",
            "Epochs: 458.. \tTraining_loss: 13.033307.. \tValid_loss: 4.932160.. \tAccuracy: 71.15%\n",
            "Epochs: 459.. \tTraining_loss: 13.820770.. \tValid_loss: 5.789652.. \tAccuracy: 69.23%\n",
            "Epochs: 460.. \tTraining_loss: 11.392060.. \tValid_loss: 4.703894.. \tAccuracy: 76.92%\n",
            "Epochs: 461.. \tTraining_loss: 11.544357.. \tValid_loss: 5.345351.. \tAccuracy: 69.23%\n",
            "Epochs: 462.. \tTraining_loss: 12.370132.. \tValid_loss: 5.316208.. \tAccuracy: 72.12%\n",
            "Epochs: 463.. \tTraining_loss: 11.510961.. \tValid_loss: 4.855159.. \tAccuracy: 77.88%\n",
            "Epochs: 464.. \tTraining_loss: 11.746988.. \tValid_loss: 5.431709.. \tAccuracy: 69.23%\n",
            "Epochs: 465.. \tTraining_loss: 12.624429.. \tValid_loss: 4.610433.. \tAccuracy: 72.12%\n",
            "Epochs: 466.. \tTraining_loss: 13.505576.. \tValid_loss: 5.032058.. \tAccuracy: 77.88%\n",
            "Epochs: 467.. \tTraining_loss: 11.267300.. \tValid_loss: 5.840372.. \tAccuracy: 72.12%\n",
            "Epochs: 468.. \tTraining_loss: 10.594264.. \tValid_loss: 4.555105.. \tAccuracy: 72.12%\n",
            "Epochs: 469.. \tTraining_loss: 11.953200.. \tValid_loss: 7.084645.. \tAccuracy: 63.46%\n",
            "Epochs: 470.. \tTraining_loss: 12.197514.. \tValid_loss: 4.892235.. \tAccuracy: 71.15%\n",
            "Epochs: 471.. \tTraining_loss: 11.878359.. \tValid_loss: 5.632832.. \tAccuracy: 76.92%\n",
            "Epochs: 472.. \tTraining_loss: 11.515591.. \tValid_loss: 4.852517.. \tAccuracy: 74.04%\n",
            "Epochs: 473.. \tTraining_loss: 12.255733.. \tValid_loss: 5.647292.. \tAccuracy: 70.19%\n",
            "Epochs: 474.. \tTraining_loss: 10.598355.. \tValid_loss: 4.554614.. \tAccuracy: 71.15%\n",
            "Epochs: 475.. \tTraining_loss: 12.682309.. \tValid_loss: 5.189402.. \tAccuracy: 73.08%\n",
            "Epochs: 476.. \tTraining_loss: 12.835301.. \tValid_loss: 5.959828.. \tAccuracy: 69.23%\n",
            "Epochs: 477.. \tTraining_loss: 11.089553.. \tValid_loss: 5.566255.. \tAccuracy: 75.00%\n",
            "Epochs: 478.. \tTraining_loss: 11.634621.. \tValid_loss: 5.802016.. \tAccuracy: 69.23%\n",
            "Epochs: 479.. \tTraining_loss: 12.025455.. \tValid_loss: 5.044138.. \tAccuracy: 74.04%\n",
            "Epochs: 480.. \tTraining_loss: 13.111815.. \tValid_loss: 5.398907.. \tAccuracy: 72.12%\n",
            "Epochs: 481.. \tTraining_loss: 11.166538.. \tValid_loss: 5.317210.. \tAccuracy: 74.04%\n",
            "Epochs: 482.. \tTraining_loss: 11.910592.. \tValid_loss: 5.019991.. \tAccuracy: 75.96%\n",
            "Epochs: 483.. \tTraining_loss: 11.809902.. \tValid_loss: 5.911330.. \tAccuracy: 70.19%\n",
            "Epochs: 484.. \tTraining_loss: 11.409495.. \tValid_loss: 5.477361.. \tAccuracy: 68.27%\n",
            "Epochs: 485.. \tTraining_loss: 11.216477.. \tValid_loss: 4.576881.. \tAccuracy: 79.81%\n",
            "Epochs: 486.. \tTraining_loss: 11.727107.. \tValid_loss: 5.088052.. \tAccuracy: 75.96%\n",
            "Epochs: 487.. \tTraining_loss: 11.773143.. \tValid_loss: 5.559510.. \tAccuracy: 72.12%\n",
            "Epochs: 488.. \tTraining_loss: 11.469759.. \tValid_loss: 5.470263.. \tAccuracy: 70.19%\n",
            "Epochs: 489.. \tTraining_loss: 11.776577.. \tValid_loss: 5.571031.. \tAccuracy: 76.92%\n",
            "Epochs: 490.. \tTraining_loss: 12.560562.. \tValid_loss: 5.325292.. \tAccuracy: 68.27%\n",
            "Epochs: 491.. \tTraining_loss: 10.992436.. \tValid_loss: 6.326694.. \tAccuracy: 66.35%\n",
            "Epochs: 492.. \tTraining_loss: 11.721252.. \tValid_loss: 5.224225.. \tAccuracy: 73.08%\n",
            "Epochs: 493.. \tTraining_loss: 11.537229.. \tValid_loss: 5.927434.. \tAccuracy: 75.00%\n",
            "Epochs: 494.. \tTraining_loss: 12.183622.. \tValid_loss: 5.222744.. \tAccuracy: 75.96%\n",
            "Epochs: 495.. \tTraining_loss: 11.911316.. \tValid_loss: 5.453025.. \tAccuracy: 74.04%\n",
            "Epochs: 496.. \tTraining_loss: 11.290212.. \tValid_loss: 5.150678.. \tAccuracy: 73.08%\n",
            "Epochs: 497.. \tTraining_loss: 11.089246.. \tValid_loss: 4.804065.. \tAccuracy: 75.96%\n",
            "Epochs: 498.. \tTraining_loss: 12.669856.. \tValid_loss: 5.158806.. \tAccuracy: 75.96%\n",
            "Epochs: 499.. \tTraining_loss: 12.643268.. \tValid_loss: 5.729386.. \tAccuracy: 70.19%\n",
            "Epochs: 500.. \tTraining_loss: 12.239269.. \tValid_loss: 6.423966.. \tAccuracy: 72.12%\n",
            "Epochs: 501.. \tTraining_loss: 12.644568.. \tValid_loss: 5.401797.. \tAccuracy: 69.23%\n",
            "Epochs: 502.. \tTraining_loss: 11.530516.. \tValid_loss: 5.395087.. \tAccuracy: 70.19%\n",
            "Epochs: 503.. \tTraining_loss: 11.522557.. \tValid_loss: 4.398265.. \tAccuracy: 75.96%\n",
            "Epochs: 504.. \tTraining_loss: 11.262642.. \tValid_loss: 4.964290.. \tAccuracy: 74.04%\n",
            "Epochs: 505.. \tTraining_loss: 11.623764.. \tValid_loss: 5.361672.. \tAccuracy: 76.92%\n",
            "Epochs: 506.. \tTraining_loss: 11.064333.. \tValid_loss: 5.568198.. \tAccuracy: 70.19%\n",
            "Epochs: 507.. \tTraining_loss: 11.891918.. \tValid_loss: 5.124295.. \tAccuracy: 74.04%\n",
            "Epochs: 508.. \tTraining_loss: 10.945355.. \tValid_loss: 5.081577.. \tAccuracy: 73.08%\n",
            "Epochs: 509.. \tTraining_loss: 12.223107.. \tValid_loss: 5.424840.. \tAccuracy: 74.04%\n",
            "Epochs: 510.. \tTraining_loss: 11.659747.. \tValid_loss: 5.409798.. \tAccuracy: 73.08%\n",
            "Epochs: 511.. \tTraining_loss: 12.196497.. \tValid_loss: 5.746015.. \tAccuracy: 69.23%\n",
            "Epochs: 512.. \tTraining_loss: 12.923988.. \tValid_loss: 5.681355.. \tAccuracy: 71.15%\n",
            "Epochs: 513.. \tTraining_loss: 11.685482.. \tValid_loss: 6.147141.. \tAccuracy: 71.15%\n",
            "Epochs: 514.. \tTraining_loss: 12.293169.. \tValid_loss: 5.034188.. \tAccuracy: 69.23%\n",
            "Epochs: 515.. \tTraining_loss: 11.595833.. \tValid_loss: 6.089662.. \tAccuracy: 68.27%\n",
            "Epochs: 516.. \tTraining_loss: 12.340669.. \tValid_loss: 5.531799.. \tAccuracy: 69.23%\n",
            "Epochs: 517.. \tTraining_loss: 12.016033.. \tValid_loss: 5.999367.. \tAccuracy: 75.00%\n",
            "Epochs: 518.. \tTraining_loss: 11.966717.. \tValid_loss: 6.098488.. \tAccuracy: 71.15%\n",
            "Epochs: 519.. \tTraining_loss: 9.934745.. \tValid_loss: 5.192288.. \tAccuracy: 72.12%\n",
            "Epochs: 520.. \tTraining_loss: 12.705337.. \tValid_loss: 6.336208.. \tAccuracy: 65.38%\n",
            "Epochs: 521.. \tTraining_loss: 10.471824.. \tValid_loss: 5.315319.. \tAccuracy: 75.96%\n",
            "Epochs: 522.. \tTraining_loss: 11.401010.. \tValid_loss: 5.896301.. \tAccuracy: 73.08%\n",
            "Epochs: 523.. \tTraining_loss: 11.584268.. \tValid_loss: 5.805631.. \tAccuracy: 73.08%\n",
            "Epochs: 524.. \tTraining_loss: 12.164733.. \tValid_loss: 5.943665.. \tAccuracy: 72.12%\n",
            "Epochs: 525.. \tTraining_loss: 11.765025.. \tValid_loss: 5.235951.. \tAccuracy: 75.00%\n",
            "Epochs: 526.. \tTraining_loss: 10.434671.. \tValid_loss: 6.122994.. \tAccuracy: 71.15%\n",
            "Epochs: 527.. \tTraining_loss: 11.711375.. \tValid_loss: 5.421876.. \tAccuracy: 74.04%\n",
            "Epochs: 528.. \tTraining_loss: 11.648909.. \tValid_loss: 5.223360.. \tAccuracy: 75.00%\n",
            "Epochs: 529.. \tTraining_loss: 10.389483.. \tValid_loss: 5.655599.. \tAccuracy: 69.23%\n",
            "Epochs: 530.. \tTraining_loss: 11.089076.. \tValid_loss: 5.978759.. \tAccuracy: 70.19%\n",
            "Epochs: 531.. \tTraining_loss: 12.206184.. \tValid_loss: 5.711391.. \tAccuracy: 73.08%\n",
            "Epochs: 532.. \tTraining_loss: 11.452599.. \tValid_loss: 5.338487.. \tAccuracy: 75.00%\n",
            "Epochs: 533.. \tTraining_loss: 10.978468.. \tValid_loss: 5.909863.. \tAccuracy: 69.23%\n",
            "Epochs: 534.. \tTraining_loss: 10.904328.. \tValid_loss: 4.948884.. \tAccuracy: 75.96%\n",
            "Epochs: 535.. \tTraining_loss: 11.616077.. \tValid_loss: 5.634780.. \tAccuracy: 71.15%\n",
            "Epochs: 536.. \tTraining_loss: 11.798440.. \tValid_loss: 5.732659.. \tAccuracy: 67.31%\n",
            "Epochs: 537.. \tTraining_loss: 11.069065.. \tValid_loss: 6.241748.. \tAccuracy: 67.31%\n",
            "Epochs: 538.. \tTraining_loss: 12.192840.. \tValid_loss: 6.030302.. \tAccuracy: 72.12%\n",
            "Epochs: 539.. \tTraining_loss: 10.529579.. \tValid_loss: 5.414974.. \tAccuracy: 74.04%\n",
            "Epochs: 540.. \tTraining_loss: 12.027264.. \tValid_loss: 5.587389.. \tAccuracy: 77.88%\n",
            "Epochs: 541.. \tTraining_loss: 11.986683.. \tValid_loss: 6.262029.. \tAccuracy: 72.12%\n",
            "Epochs: 542.. \tTraining_loss: 12.046415.. \tValid_loss: 6.610191.. \tAccuracy: 70.19%\n",
            "Epochs: 543.. \tTraining_loss: 11.301788.. \tValid_loss: 5.974160.. \tAccuracy: 71.15%\n",
            "Epochs: 544.. \tTraining_loss: 11.311005.. \tValid_loss: 5.740511.. \tAccuracy: 72.12%\n",
            "Epochs: 545.. \tTraining_loss: 11.290098.. \tValid_loss: 6.302248.. \tAccuracy: 69.23%\n",
            "Epochs: 546.. \tTraining_loss: 11.733328.. \tValid_loss: 5.377989.. \tAccuracy: 73.08%\n",
            "Epochs: 547.. \tTraining_loss: 10.920666.. \tValid_loss: 5.982355.. \tAccuracy: 75.00%\n",
            "Epochs: 548.. \tTraining_loss: 10.545949.. \tValid_loss: 5.961454.. \tAccuracy: 69.23%\n",
            "Epochs: 549.. \tTraining_loss: 12.298646.. \tValid_loss: 6.452184.. \tAccuracy: 66.35%\n",
            "Epochs: 550.. \tTraining_loss: 10.780778.. \tValid_loss: 6.264723.. \tAccuracy: 69.23%\n",
            "Epochs: 551.. \tTraining_loss: 10.200376.. \tValid_loss: 4.555434.. \tAccuracy: 76.92%\n",
            "Epochs: 552.. \tTraining_loss: 11.078351.. \tValid_loss: 5.871687.. \tAccuracy: 73.08%\n",
            "Epochs: 553.. \tTraining_loss: 10.411831.. \tValid_loss: 5.394499.. \tAccuracy: 70.19%\n",
            "Epochs: 554.. \tTraining_loss: 11.596219.. \tValid_loss: 6.402370.. \tAccuracy: 70.19%\n",
            "Epochs: 555.. \tTraining_loss: 12.923052.. \tValid_loss: 5.530451.. \tAccuracy: 75.00%\n",
            "Epochs: 556.. \tTraining_loss: 10.487269.. \tValid_loss: 4.591861.. \tAccuracy: 74.04%\n",
            "Epochs: 557.. \tTraining_loss: 12.279372.. \tValid_loss: 5.469810.. \tAccuracy: 73.08%\n",
            "Epochs: 558.. \tTraining_loss: 10.800803.. \tValid_loss: 6.017689.. \tAccuracy: 67.31%\n",
            "Epochs: 559.. \tTraining_loss: 11.691176.. \tValid_loss: 4.718677.. \tAccuracy: 73.08%\n",
            "Epochs: 560.. \tTraining_loss: 12.184259.. \tValid_loss: 6.372791.. \tAccuracy: 68.27%\n",
            "Epochs: 561.. \tTraining_loss: 12.685729.. \tValid_loss: 6.345467.. \tAccuracy: 71.15%\n",
            "Epochs: 562.. \tTraining_loss: 10.676462.. \tValid_loss: 5.985608.. \tAccuracy: 75.00%\n",
            "Epochs: 563.. \tTraining_loss: 10.037393.. \tValid_loss: 5.620693.. \tAccuracy: 75.96%\n",
            "Epochs: 564.. \tTraining_loss: 11.435928.. \tValid_loss: 6.176382.. \tAccuracy: 69.23%\n",
            "Epochs: 565.. \tTraining_loss: 11.596609.. \tValid_loss: 5.148295.. \tAccuracy: 73.08%\n",
            "Epochs: 566.. \tTraining_loss: 11.007719.. \tValid_loss: 5.649428.. \tAccuracy: 73.08%\n",
            "Epochs: 567.. \tTraining_loss: 10.210288.. \tValid_loss: 5.414057.. \tAccuracy: 72.12%\n",
            "Epochs: 568.. \tTraining_loss: 11.333440.. \tValid_loss: 6.323917.. \tAccuracy: 74.04%\n",
            "Epochs: 569.. \tTraining_loss: 10.620525.. \tValid_loss: 5.978738.. \tAccuracy: 64.42%\n",
            "Epochs: 570.. \tTraining_loss: 10.933484.. \tValid_loss: 5.769881.. \tAccuracy: 75.00%\n",
            "Epochs: 571.. \tTraining_loss: 11.145306.. \tValid_loss: 5.897482.. \tAccuracy: 73.08%\n",
            "Epochs: 572.. \tTraining_loss: 11.462454.. \tValid_loss: 5.606941.. \tAccuracy: 75.00%\n",
            "Epochs: 573.. \tTraining_loss: 12.023587.. \tValid_loss: 5.325877.. \tAccuracy: 74.04%\n",
            "Epochs: 574.. \tTraining_loss: 11.739115.. \tValid_loss: 5.645049.. \tAccuracy: 73.08%\n",
            "Epochs: 575.. \tTraining_loss: 10.919451.. \tValid_loss: 5.641322.. \tAccuracy: 75.96%\n",
            "Epochs: 576.. \tTraining_loss: 10.826310.. \tValid_loss: 4.825465.. \tAccuracy: 78.85%\n",
            "Epochs: 577.. \tTraining_loss: 11.262921.. \tValid_loss: 5.188571.. \tAccuracy: 70.19%\n",
            "Epochs: 578.. \tTraining_loss: 12.228357.. \tValid_loss: 5.620526.. \tAccuracy: 71.15%\n",
            "Epochs: 579.. \tTraining_loss: 10.878126.. \tValid_loss: 6.189010.. \tAccuracy: 70.19%\n",
            "Epochs: 580.. \tTraining_loss: 11.730268.. \tValid_loss: 5.663392.. \tAccuracy: 71.15%\n",
            "Epochs: 581.. \tTraining_loss: 10.757196.. \tValid_loss: 6.206991.. \tAccuracy: 65.38%\n",
            "Epochs: 582.. \tTraining_loss: 10.808440.. \tValid_loss: 6.234125.. \tAccuracy: 73.08%\n",
            "Epochs: 583.. \tTraining_loss: 10.006001.. \tValid_loss: 5.137365.. \tAccuracy: 75.96%\n",
            "Epochs: 584.. \tTraining_loss: 10.603559.. \tValid_loss: 5.722502.. \tAccuracy: 72.12%\n",
            "Epochs: 585.. \tTraining_loss: 10.263678.. \tValid_loss: 5.536567.. \tAccuracy: 72.12%\n",
            "Epochs: 586.. \tTraining_loss: 10.117932.. \tValid_loss: 4.554531.. \tAccuracy: 72.12%\n",
            "Epochs: 587.. \tTraining_loss: 11.444933.. \tValid_loss: 5.239548.. \tAccuracy: 74.04%\n",
            "Epochs: 588.. \tTraining_loss: 10.710069.. \tValid_loss: 5.568811.. \tAccuracy: 67.31%\n",
            "Epochs: 589.. \tTraining_loss: 11.271494.. \tValid_loss: 5.032759.. \tAccuracy: 74.04%\n",
            "Epochs: 590.. \tTraining_loss: 10.767129.. \tValid_loss: 5.656632.. \tAccuracy: 70.19%\n",
            "Epochs: 591.. \tTraining_loss: 9.424217.. \tValid_loss: 5.429888.. \tAccuracy: 68.27%\n",
            "Epochs: 592.. \tTraining_loss: 9.986190.. \tValid_loss: 4.917621.. \tAccuracy: 72.12%\n",
            "Epochs: 593.. \tTraining_loss: 12.084194.. \tValid_loss: 6.488282.. \tAccuracy: 68.27%\n",
            "Epochs: 594.. \tTraining_loss: 9.863318.. \tValid_loss: 6.081797.. \tAccuracy: 65.38%\n",
            "Epochs: 595.. \tTraining_loss: 11.423510.. \tValid_loss: 5.423296.. \tAccuracy: 74.04%\n",
            "Epochs: 596.. \tTraining_loss: 11.498813.. \tValid_loss: 5.456401.. \tAccuracy: 70.19%\n",
            "Epochs: 597.. \tTraining_loss: 11.356691.. \tValid_loss: 5.428622.. \tAccuracy: 73.08%\n",
            "Epochs: 598.. \tTraining_loss: 10.660599.. \tValid_loss: 6.301626.. \tAccuracy: 71.15%\n",
            "Epochs: 599.. \tTraining_loss: 11.502694.. \tValid_loss: 5.470397.. \tAccuracy: 74.04%\n",
            "Epochs: 600.. \tTraining_loss: 11.347333.. \tValid_loss: 5.516068.. \tAccuracy: 70.19%\n",
            "Epochs: 601.. \tTraining_loss: 11.378161.. \tValid_loss: 5.768082.. \tAccuracy: 74.04%\n",
            "Epochs: 602.. \tTraining_loss: 10.649469.. \tValid_loss: 6.140213.. \tAccuracy: 75.96%\n",
            "Epochs: 603.. \tTraining_loss: 11.792253.. \tValid_loss: 5.612416.. \tAccuracy: 71.15%\n",
            "Epochs: 604.. \tTraining_loss: 11.058033.. \tValid_loss: 4.967139.. \tAccuracy: 75.96%\n",
            "Epochs: 605.. \tTraining_loss: 12.186812.. \tValid_loss: 5.579295.. \tAccuracy: 78.85%\n",
            "Epochs: 606.. \tTraining_loss: 10.968507.. \tValid_loss: 6.403050.. \tAccuracy: 66.35%\n",
            "Epochs: 607.. \tTraining_loss: 9.933588.. \tValid_loss: 6.323361.. \tAccuracy: 68.27%\n",
            "Epochs: 608.. \tTraining_loss: 10.820007.. \tValid_loss: 6.081304.. \tAccuracy: 67.31%\n",
            "Epochs: 609.. \tTraining_loss: 10.905243.. \tValid_loss: 5.632538.. \tAccuracy: 75.96%\n",
            "Epochs: 610.. \tTraining_loss: 11.604003.. \tValid_loss: 4.813123.. \tAccuracy: 75.00%\n",
            "Epochs: 611.. \tTraining_loss: 9.914091.. \tValid_loss: 5.752788.. \tAccuracy: 72.12%\n",
            "Epochs: 612.. \tTraining_loss: 11.622029.. \tValid_loss: 5.748966.. \tAccuracy: 71.15%\n",
            "Epochs: 613.. \tTraining_loss: 10.466457.. \tValid_loss: 5.418972.. \tAccuracy: 75.96%\n",
            "Epochs: 614.. \tTraining_loss: 10.535987.. \tValid_loss: 5.570558.. \tAccuracy: 73.08%\n",
            "Epochs: 615.. \tTraining_loss: 10.100152.. \tValid_loss: 5.439799.. \tAccuracy: 75.96%\n",
            "Epochs: 616.. \tTraining_loss: 10.439239.. \tValid_loss: 5.328630.. \tAccuracy: 78.85%\n",
            "Epochs: 617.. \tTraining_loss: 9.263623.. \tValid_loss: 5.500584.. \tAccuracy: 71.15%\n",
            "Epochs: 618.. \tTraining_loss: 10.756945.. \tValid_loss: 4.819523.. \tAccuracy: 75.96%\n",
            "Epochs: 619.. \tTraining_loss: 11.335032.. \tValid_loss: 5.835120.. \tAccuracy: 72.12%\n",
            "Epochs: 620.. \tTraining_loss: 10.978475.. \tValid_loss: 6.071027.. \tAccuracy: 75.00%\n",
            "Epochs: 621.. \tTraining_loss: 10.818906.. \tValid_loss: 5.342864.. \tAccuracy: 76.92%\n",
            "Epochs: 622.. \tTraining_loss: 11.424161.. \tValid_loss: 4.379486.. \tAccuracy: 73.08%\n",
            "Epochs: 623.. \tTraining_loss: 10.992803.. \tValid_loss: 6.490962.. \tAccuracy: 73.08%\n",
            "Epochs: 624.. \tTraining_loss: 11.439020.. \tValid_loss: 5.504389.. \tAccuracy: 75.96%\n",
            "Epochs: 625.. \tTraining_loss: 10.220604.. \tValid_loss: 5.472434.. \tAccuracy: 74.04%\n",
            "Epochs: 626.. \tTraining_loss: 10.604537.. \tValid_loss: 6.423403.. \tAccuracy: 70.19%\n",
            "Epochs: 627.. \tTraining_loss: 11.502939.. \tValid_loss: 6.138395.. \tAccuracy: 67.31%\n",
            "Epochs: 628.. \tTraining_loss: 10.177809.. \tValid_loss: 5.581617.. \tAccuracy: 71.15%\n",
            "Epochs: 629.. \tTraining_loss: 11.505779.. \tValid_loss: 5.424378.. \tAccuracy: 75.00%\n",
            "Epochs: 630.. \tTraining_loss: 11.085545.. \tValid_loss: 5.652479.. \tAccuracy: 71.15%\n",
            "Epochs: 631.. \tTraining_loss: 10.555715.. \tValid_loss: 5.317870.. \tAccuracy: 76.92%\n",
            "Epochs: 632.. \tTraining_loss: 11.046703.. \tValid_loss: 5.805302.. \tAccuracy: 71.15%\n",
            "Epochs: 633.. \tTraining_loss: 10.180034.. \tValid_loss: 5.306253.. \tAccuracy: 75.00%\n",
            "Epochs: 634.. \tTraining_loss: 11.657587.. \tValid_loss: 6.236875.. \tAccuracy: 70.19%\n",
            "Epochs: 635.. \tTraining_loss: 10.012079.. \tValid_loss: 6.005919.. \tAccuracy: 72.12%\n",
            "Epochs: 636.. \tTraining_loss: 10.888851.. \tValid_loss: 6.081711.. \tAccuracy: 73.08%\n",
            "Epochs: 637.. \tTraining_loss: 12.187035.. \tValid_loss: 5.907657.. \tAccuracy: 66.35%\n",
            "Epochs: 638.. \tTraining_loss: 10.915323.. \tValid_loss: 5.835271.. \tAccuracy: 73.08%\n",
            "Epochs: 639.. \tTraining_loss: 11.842371.. \tValid_loss: 5.316339.. \tAccuracy: 72.12%\n",
            "Epochs: 640.. \tTraining_loss: 9.671324.. \tValid_loss: 5.686353.. \tAccuracy: 73.08%\n",
            "Epochs: 641.. \tTraining_loss: 11.045992.. \tValid_loss: 5.894549.. \tAccuracy: 68.27%\n",
            "Epochs: 642.. \tTraining_loss: 10.879847.. \tValid_loss: 6.395709.. \tAccuracy: 72.12%\n",
            "Epochs: 643.. \tTraining_loss: 11.152909.. \tValid_loss: 6.065839.. \tAccuracy: 67.31%\n",
            "Epochs: 644.. \tTraining_loss: 12.265740.. \tValid_loss: 7.258212.. \tAccuracy: 68.27%\n",
            "Epochs: 645.. \tTraining_loss: 10.000376.. \tValid_loss: 6.024174.. \tAccuracy: 72.12%\n",
            "Epochs: 646.. \tTraining_loss: 9.715663.. \tValid_loss: 5.161981.. \tAccuracy: 75.96%\n",
            "Epochs: 647.. \tTraining_loss: 11.114753.. \tValid_loss: 5.837277.. \tAccuracy: 75.00%\n",
            "Epochs: 648.. \tTraining_loss: 9.466217.. \tValid_loss: 5.473651.. \tAccuracy: 74.04%\n",
            "Epochs: 649.. \tTraining_loss: 9.428255.. \tValid_loss: 5.556139.. \tAccuracy: 75.96%\n",
            "Epochs: 650.. \tTraining_loss: 10.396748.. \tValid_loss: 5.329954.. \tAccuracy: 69.23%\n",
            "Epochs: 651.. \tTraining_loss: 10.407456.. \tValid_loss: 6.702993.. \tAccuracy: 68.27%\n",
            "Epochs: 652.. \tTraining_loss: 11.139546.. \tValid_loss: 5.000172.. \tAccuracy: 76.92%\n",
            "Epochs: 653.. \tTraining_loss: 11.536001.. \tValid_loss: 6.133325.. \tAccuracy: 65.38%\n",
            "Epochs: 654.. \tTraining_loss: 10.900626.. \tValid_loss: 4.934034.. \tAccuracy: 77.88%\n",
            "Epochs: 655.. \tTraining_loss: 11.482371.. \tValid_loss: 5.302212.. \tAccuracy: 70.19%\n",
            "Epochs: 656.. \tTraining_loss: 10.634586.. \tValid_loss: 5.139495.. \tAccuracy: 76.92%\n",
            "Epochs: 657.. \tTraining_loss: 11.085130.. \tValid_loss: 4.676892.. \tAccuracy: 77.88%\n",
            "Epochs: 658.. \tTraining_loss: 9.247542.. \tValid_loss: 5.581196.. \tAccuracy: 75.00%\n",
            "Epochs: 659.. \tTraining_loss: 9.281024.. \tValid_loss: 5.171486.. \tAccuracy: 76.92%\n",
            "Epochs: 660.. \tTraining_loss: 12.999974.. \tValid_loss: 4.987166.. \tAccuracy: 70.19%\n",
            "Epochs: 661.. \tTraining_loss: 10.211801.. \tValid_loss: 5.180403.. \tAccuracy: 71.15%\n",
            "Epochs: 662.. \tTraining_loss: 9.712683.. \tValid_loss: 5.719907.. \tAccuracy: 69.23%\n",
            "Epochs: 663.. \tTraining_loss: 10.062102.. \tValid_loss: 5.931634.. \tAccuracy: 71.15%\n",
            "Epochs: 664.. \tTraining_loss: 9.265545.. \tValid_loss: 6.071338.. \tAccuracy: 75.00%\n",
            "Epochs: 665.. \tTraining_loss: 10.175747.. \tValid_loss: 5.373368.. \tAccuracy: 75.96%\n",
            "Epochs: 666.. \tTraining_loss: 11.973168.. \tValid_loss: 4.896945.. \tAccuracy: 72.12%\n",
            "Epochs: 667.. \tTraining_loss: 10.153162.. \tValid_loss: 6.143113.. \tAccuracy: 67.31%\n",
            "Epochs: 668.. \tTraining_loss: 11.026085.. \tValid_loss: 5.137691.. \tAccuracy: 75.00%\n",
            "Epochs: 669.. \tTraining_loss: 10.515116.. \tValid_loss: 6.258653.. \tAccuracy: 69.23%\n",
            "Epochs: 670.. \tTraining_loss: 10.773982.. \tValid_loss: 5.790584.. \tAccuracy: 71.15%\n",
            "Epochs: 671.. \tTraining_loss: 10.350998.. \tValid_loss: 5.704680.. \tAccuracy: 72.12%\n",
            "Epochs: 672.. \tTraining_loss: 9.794957.. \tValid_loss: 5.892744.. \tAccuracy: 70.19%\n",
            "Epochs: 673.. \tTraining_loss: 9.190235.. \tValid_loss: 5.436308.. \tAccuracy: 74.04%\n",
            "Epochs: 674.. \tTraining_loss: 10.288825.. \tValid_loss: 6.359744.. \tAccuracy: 70.19%\n",
            "Epochs: 675.. \tTraining_loss: 10.093002.. \tValid_loss: 6.023553.. \tAccuracy: 71.15%\n",
            "Epochs: 676.. \tTraining_loss: 12.147398.. \tValid_loss: 5.677704.. \tAccuracy: 69.23%\n",
            "Epochs: 677.. \tTraining_loss: 9.051156.. \tValid_loss: 5.815558.. \tAccuracy: 75.00%\n",
            "Epochs: 678.. \tTraining_loss: 9.290881.. \tValid_loss: 6.573090.. \tAccuracy: 70.19%\n",
            "Epochs: 679.. \tTraining_loss: 10.644123.. \tValid_loss: 5.375872.. \tAccuracy: 73.08%\n",
            "Epochs: 680.. \tTraining_loss: 10.734822.. \tValid_loss: 6.863950.. \tAccuracy: 71.15%\n",
            "Epochs: 681.. \tTraining_loss: 11.546815.. \tValid_loss: 5.624723.. \tAccuracy: 74.04%\n",
            "Epochs: 682.. \tTraining_loss: 10.780627.. \tValid_loss: 4.905005.. \tAccuracy: 75.00%\n",
            "Epochs: 683.. \tTraining_loss: 8.652239.. \tValid_loss: 6.178507.. \tAccuracy: 68.27%\n",
            "Epochs: 684.. \tTraining_loss: 9.601271.. \tValid_loss: 6.695208.. \tAccuracy: 67.31%\n",
            "Epochs: 685.. \tTraining_loss: 10.007836.. \tValid_loss: 5.881131.. \tAccuracy: 70.19%\n",
            "Epochs: 686.. \tTraining_loss: 10.087585.. \tValid_loss: 5.793664.. \tAccuracy: 73.08%\n",
            "Epochs: 687.. \tTraining_loss: 10.089309.. \tValid_loss: 5.718893.. \tAccuracy: 75.96%\n",
            "Epochs: 688.. \tTraining_loss: 8.785471.. \tValid_loss: 5.483759.. \tAccuracy: 74.04%\n",
            "Epochs: 689.. \tTraining_loss: 9.926401.. \tValid_loss: 5.686401.. \tAccuracy: 68.27%\n",
            "Epochs: 690.. \tTraining_loss: 10.699357.. \tValid_loss: 6.556234.. \tAccuracy: 68.27%\n",
            "Epochs: 691.. \tTraining_loss: 9.150925.. \tValid_loss: 5.165669.. \tAccuracy: 74.04%\n",
            "Epochs: 692.. \tTraining_loss: 10.198570.. \tValid_loss: 5.222021.. \tAccuracy: 75.00%\n",
            "Epochs: 693.. \tTraining_loss: 10.486577.. \tValid_loss: 5.537216.. \tAccuracy: 72.12%\n",
            "Epochs: 694.. \tTraining_loss: 9.993787.. \tValid_loss: 5.004916.. \tAccuracy: 76.92%\n",
            "Epochs: 695.. \tTraining_loss: 11.117917.. \tValid_loss: 5.758840.. \tAccuracy: 75.96%\n",
            "Epochs: 696.. \tTraining_loss: 10.154579.. \tValid_loss: 6.432300.. \tAccuracy: 71.15%\n",
            "Epochs: 697.. \tTraining_loss: 10.747318.. \tValid_loss: 5.210232.. \tAccuracy: 75.96%\n",
            "Epochs: 698.. \tTraining_loss: 11.314167.. \tValid_loss: 4.466875.. \tAccuracy: 77.88%\n",
            "Epochs: 699.. \tTraining_loss: 10.575443.. \tValid_loss: 5.707630.. \tAccuracy: 67.31%\n",
            "Epochs: 700.. \tTraining_loss: 11.363649.. \tValid_loss: 6.124733.. \tAccuracy: 67.31%\n",
            "Epochs: 701.. \tTraining_loss: 13.078503.. \tValid_loss: 5.804394.. \tAccuracy: 67.31%\n",
            "Epochs: 702.. \tTraining_loss: 9.297814.. \tValid_loss: 5.716472.. \tAccuracy: 71.15%\n",
            "Epochs: 703.. \tTraining_loss: 9.371526.. \tValid_loss: 6.050915.. \tAccuracy: 67.31%\n",
            "Epochs: 704.. \tTraining_loss: 10.642898.. \tValid_loss: 6.084800.. \tAccuracy: 71.15%\n",
            "Epochs: 705.. \tTraining_loss: 9.316317.. \tValid_loss: 5.896514.. \tAccuracy: 76.92%\n",
            "Epochs: 706.. \tTraining_loss: 9.358033.. \tValid_loss: 6.616676.. \tAccuracy: 67.31%\n",
            "Epochs: 707.. \tTraining_loss: 9.540423.. \tValid_loss: 6.648844.. \tAccuracy: 73.08%\n",
            "Epochs: 708.. \tTraining_loss: 11.086502.. \tValid_loss: 5.237746.. \tAccuracy: 76.92%\n",
            "Epochs: 709.. \tTraining_loss: 9.073987.. \tValid_loss: 6.347040.. \tAccuracy: 73.08%\n",
            "Epochs: 710.. \tTraining_loss: 8.326721.. \tValid_loss: 4.831970.. \tAccuracy: 75.96%\n",
            "Epochs: 711.. \tTraining_loss: 10.324488.. \tValid_loss: 5.412393.. \tAccuracy: 74.04%\n",
            "Epochs: 712.. \tTraining_loss: 9.611569.. \tValid_loss: 5.855835.. \tAccuracy: 76.92%\n",
            "Epochs: 713.. \tTraining_loss: 8.776270.. \tValid_loss: 5.207178.. \tAccuracy: 75.00%\n",
            "Epochs: 714.. \tTraining_loss: 10.019727.. \tValid_loss: 5.272765.. \tAccuracy: 70.19%\n",
            "Epochs: 715.. \tTraining_loss: 9.876359.. \tValid_loss: 6.686075.. \tAccuracy: 70.19%\n",
            "Epochs: 716.. \tTraining_loss: 10.229885.. \tValid_loss: 4.710162.. \tAccuracy: 72.12%\n",
            "Epochs: 717.. \tTraining_loss: 10.419215.. \tValid_loss: 4.693676.. \tAccuracy: 75.96%\n",
            "Epochs: 718.. \tTraining_loss: 10.141091.. \tValid_loss: 5.082074.. \tAccuracy: 75.96%\n",
            "Epochs: 719.. \tTraining_loss: 9.301162.. \tValid_loss: 5.626261.. \tAccuracy: 69.23%\n",
            "Epochs: 720.. \tTraining_loss: 9.091456.. \tValid_loss: 5.648508.. \tAccuracy: 73.08%\n",
            "Epochs: 721.. \tTraining_loss: 9.818145.. \tValid_loss: 5.736944.. \tAccuracy: 67.31%\n",
            "Epochs: 722.. \tTraining_loss: 8.840622.. \tValid_loss: 5.637094.. \tAccuracy: 73.08%\n",
            "Epochs: 723.. \tTraining_loss: 10.735287.. \tValid_loss: 5.404787.. \tAccuracy: 71.15%\n",
            "Epochs: 724.. \tTraining_loss: 10.025216.. \tValid_loss: 4.834896.. \tAccuracy: 76.92%\n",
            "Epochs: 725.. \tTraining_loss: 11.395597.. \tValid_loss: 5.371004.. \tAccuracy: 75.00%\n",
            "Epochs: 726.. \tTraining_loss: 9.709895.. \tValid_loss: 6.986803.. \tAccuracy: 65.38%\n",
            "Epochs: 727.. \tTraining_loss: 8.951211.. \tValid_loss: 5.098963.. \tAccuracy: 74.04%\n",
            "Epochs: 728.. \tTraining_loss: 9.265684.. \tValid_loss: 5.766325.. \tAccuracy: 73.08%\n",
            "Epochs: 729.. \tTraining_loss: 10.144773.. \tValid_loss: 5.860339.. \tAccuracy: 74.04%\n",
            "Epochs: 730.. \tTraining_loss: 9.988552.. \tValid_loss: 5.607543.. \tAccuracy: 73.08%\n",
            "Epochs: 731.. \tTraining_loss: 8.559010.. \tValid_loss: 6.342889.. \tAccuracy: 68.27%\n",
            "Epochs: 732.. \tTraining_loss: 8.572673.. \tValid_loss: 5.386514.. \tAccuracy: 75.00%\n",
            "Epochs: 733.. \tTraining_loss: 9.685804.. \tValid_loss: 6.322788.. \tAccuracy: 73.08%\n",
            "Epochs: 734.. \tTraining_loss: 10.019865.. \tValid_loss: 6.874033.. \tAccuracy: 69.23%\n",
            "Epochs: 735.. \tTraining_loss: 10.394013.. \tValid_loss: 4.867939.. \tAccuracy: 76.92%\n",
            "Epochs: 736.. \tTraining_loss: 8.732019.. \tValid_loss: 6.392433.. \tAccuracy: 70.19%\n",
            "Epochs: 737.. \tTraining_loss: 9.790559.. \tValid_loss: 5.058367.. \tAccuracy: 75.00%\n",
            "Epochs: 738.. \tTraining_loss: 9.664036.. \tValid_loss: 5.965119.. \tAccuracy: 73.08%\n",
            "Epochs: 739.. \tTraining_loss: 9.306059.. \tValid_loss: 5.236941.. \tAccuracy: 75.96%\n",
            "Epochs: 740.. \tTraining_loss: 11.354896.. \tValid_loss: 5.189809.. \tAccuracy: 69.23%\n",
            "Epochs: 741.. \tTraining_loss: 10.673036.. \tValid_loss: 5.121261.. \tAccuracy: 74.04%\n",
            "Epochs: 742.. \tTraining_loss: 9.061948.. \tValid_loss: 4.776919.. \tAccuracy: 72.12%\n",
            "Epochs: 743.. \tTraining_loss: 9.644059.. \tValid_loss: 5.745748.. \tAccuracy: 73.08%\n",
            "Epochs: 744.. \tTraining_loss: 9.302792.. \tValid_loss: 7.061531.. \tAccuracy: 74.04%\n",
            "Epochs: 745.. \tTraining_loss: 8.657895.. \tValid_loss: 5.590998.. \tAccuracy: 71.15%\n",
            "Epochs: 746.. \tTraining_loss: 9.951297.. \tValid_loss: 5.961091.. \tAccuracy: 73.08%\n",
            "Epochs: 747.. \tTraining_loss: 10.095865.. \tValid_loss: 5.813016.. \tAccuracy: 68.27%\n",
            "Epochs: 748.. \tTraining_loss: 9.744915.. \tValid_loss: 5.760979.. \tAccuracy: 71.15%\n",
            "Epochs: 749.. \tTraining_loss: 9.718912.. \tValid_loss: 5.541450.. \tAccuracy: 69.23%\n",
            "Epochs: 750.. \tTraining_loss: 9.853147.. \tValid_loss: 6.822519.. \tAccuracy: 60.58%\n",
            "Epochs: 751.. \tTraining_loss: 9.734581.. \tValid_loss: 6.598682.. \tAccuracy: 72.12%\n",
            "Epochs: 752.. \tTraining_loss: 10.002857.. \tValid_loss: 6.106592.. \tAccuracy: 74.04%\n",
            "Epochs: 753.. \tTraining_loss: 9.243097.. \tValid_loss: 6.522129.. \tAccuracy: 71.15%\n",
            "Epochs: 754.. \tTraining_loss: 9.419133.. \tValid_loss: 5.302761.. \tAccuracy: 74.04%\n",
            "Epochs: 755.. \tTraining_loss: 8.963538.. \tValid_loss: 5.443919.. \tAccuracy: 74.04%\n",
            "Epochs: 756.. \tTraining_loss: 10.794305.. \tValid_loss: 6.069397.. \tAccuracy: 73.08%\n",
            "Epochs: 757.. \tTraining_loss: 9.397005.. \tValid_loss: 4.774502.. \tAccuracy: 75.96%\n",
            "Epochs: 758.. \tTraining_loss: 9.964199.. \tValid_loss: 5.418165.. \tAccuracy: 69.23%\n",
            "Epochs: 759.. \tTraining_loss: 9.028777.. \tValid_loss: 5.699746.. \tAccuracy: 70.19%\n",
            "Epochs: 760.. \tTraining_loss: 8.595291.. \tValid_loss: 5.923715.. \tAccuracy: 71.15%\n",
            "Epochs: 761.. \tTraining_loss: 8.566694.. \tValid_loss: 6.337328.. \tAccuracy: 68.27%\n",
            "Epochs: 762.. \tTraining_loss: 9.352075.. \tValid_loss: 5.977927.. \tAccuracy: 71.15%\n",
            "Epochs: 763.. \tTraining_loss: 9.111422.. \tValid_loss: 6.354603.. \tAccuracy: 65.38%\n",
            "Epochs: 764.. \tTraining_loss: 9.940414.. \tValid_loss: 6.041289.. \tAccuracy: 68.27%\n",
            "Epochs: 765.. \tTraining_loss: 9.806543.. \tValid_loss: 5.616490.. \tAccuracy: 70.19%\n",
            "Epochs: 766.. \tTraining_loss: 10.835004.. \tValid_loss: 6.255668.. \tAccuracy: 69.23%\n",
            "Epochs: 767.. \tTraining_loss: 9.289642.. \tValid_loss: 5.492572.. \tAccuracy: 72.12%\n",
            "Epochs: 768.. \tTraining_loss: 10.934399.. \tValid_loss: 5.374503.. \tAccuracy: 76.92%\n",
            "Epochs: 769.. \tTraining_loss: 8.856588.. \tValid_loss: 5.846646.. \tAccuracy: 70.19%\n",
            "Epochs: 770.. \tTraining_loss: 7.440243.. \tValid_loss: 5.803674.. \tAccuracy: 68.27%\n",
            "Epochs: 771.. \tTraining_loss: 7.876178.. \tValid_loss: 7.046274.. \tAccuracy: 71.15%\n",
            "Epochs: 772.. \tTraining_loss: 9.132312.. \tValid_loss: 6.939971.. \tAccuracy: 69.23%\n",
            "Epochs: 773.. \tTraining_loss: 9.206260.. \tValid_loss: 4.768848.. \tAccuracy: 74.04%\n",
            "Epochs: 774.. \tTraining_loss: 8.816440.. \tValid_loss: 6.733298.. \tAccuracy: 68.27%\n",
            "Epochs: 775.. \tTraining_loss: 9.471658.. \tValid_loss: 5.588277.. \tAccuracy: 75.00%\n",
            "Epochs: 776.. \tTraining_loss: 8.984919.. \tValid_loss: 5.949478.. \tAccuracy: 74.04%\n",
            "Epochs: 777.. \tTraining_loss: 7.876657.. \tValid_loss: 5.144982.. \tAccuracy: 75.96%\n",
            "Epochs: 778.. \tTraining_loss: 9.726738.. \tValid_loss: 5.571398.. \tAccuracy: 70.19%\n",
            "Epochs: 779.. \tTraining_loss: 9.629986.. \tValid_loss: 5.732578.. \tAccuracy: 70.19%\n",
            "Epochs: 780.. \tTraining_loss: 9.952379.. \tValid_loss: 6.023371.. \tAccuracy: 68.27%\n",
            "Epochs: 781.. \tTraining_loss: 9.761099.. \tValid_loss: 5.761666.. \tAccuracy: 69.23%\n",
            "Epochs: 782.. \tTraining_loss: 10.339193.. \tValid_loss: 5.797766.. \tAccuracy: 72.12%\n",
            "Epochs: 783.. \tTraining_loss: 10.277100.. \tValid_loss: 4.969062.. \tAccuracy: 74.04%\n",
            "Epochs: 784.. \tTraining_loss: 9.846812.. \tValid_loss: 6.192280.. \tAccuracy: 75.96%\n",
            "Epochs: 785.. \tTraining_loss: 9.005247.. \tValid_loss: 6.399437.. \tAccuracy: 72.12%\n",
            "Epochs: 786.. \tTraining_loss: 8.562470.. \tValid_loss: 5.524620.. \tAccuracy: 72.12%\n",
            "Epochs: 787.. \tTraining_loss: 9.805663.. \tValid_loss: 5.785674.. \tAccuracy: 75.96%\n",
            "Epochs: 788.. \tTraining_loss: 10.918046.. \tValid_loss: 5.347281.. \tAccuracy: 76.92%\n",
            "Epochs: 789.. \tTraining_loss: 9.644291.. \tValid_loss: 6.533546.. \tAccuracy: 66.35%\n",
            "Epochs: 790.. \tTraining_loss: 10.564038.. \tValid_loss: 5.617374.. \tAccuracy: 75.96%\n",
            "Epochs: 791.. \tTraining_loss: 8.288511.. \tValid_loss: 4.673922.. \tAccuracy: 78.85%\n",
            "Epochs: 792.. \tTraining_loss: 8.576492.. \tValid_loss: 5.253177.. \tAccuracy: 72.12%\n",
            "Epochs: 793.. \tTraining_loss: 8.826049.. \tValid_loss: 5.537550.. \tAccuracy: 70.19%\n",
            "Epochs: 794.. \tTraining_loss: 10.213746.. \tValid_loss: 6.117888.. \tAccuracy: 70.19%\n",
            "Epochs: 795.. \tTraining_loss: 9.637418.. \tValid_loss: 5.810724.. \tAccuracy: 71.15%\n",
            "Epochs: 796.. \tTraining_loss: 9.364026.. \tValid_loss: 6.282366.. \tAccuracy: 75.00%\n",
            "Epochs: 797.. \tTraining_loss: 10.315592.. \tValid_loss: 6.749491.. \tAccuracy: 67.31%\n",
            "Epochs: 798.. \tTraining_loss: 8.130614.. \tValid_loss: 6.664602.. \tAccuracy: 70.19%\n",
            "Epochs: 799.. \tTraining_loss: 10.094759.. \tValid_loss: 5.838273.. \tAccuracy: 74.04%\n",
            "Epochs: 800.. \tTraining_loss: 8.931423.. \tValid_loss: 5.361831.. \tAccuracy: 77.88%\n",
            "Epochs: 801.. \tTraining_loss: 9.466397.. \tValid_loss: 5.917666.. \tAccuracy: 70.19%\n",
            "Epochs: 802.. \tTraining_loss: 9.714096.. \tValid_loss: 6.001516.. \tAccuracy: 75.00%\n",
            "Epochs: 803.. \tTraining_loss: 9.175123.. \tValid_loss: 5.244819.. \tAccuracy: 73.08%\n",
            "Epochs: 804.. \tTraining_loss: 9.359470.. \tValid_loss: 5.960868.. \tAccuracy: 68.27%\n",
            "Epochs: 805.. \tTraining_loss: 9.561223.. \tValid_loss: 5.558567.. \tAccuracy: 66.35%\n",
            "Epochs: 806.. \tTraining_loss: 9.093921.. \tValid_loss: 6.435399.. \tAccuracy: 70.19%\n",
            "Epochs: 807.. \tTraining_loss: 8.076127.. \tValid_loss: 5.588412.. \tAccuracy: 71.15%\n",
            "Epochs: 808.. \tTraining_loss: 8.273900.. \tValid_loss: 5.751217.. \tAccuracy: 69.23%\n",
            "Epochs: 809.. \tTraining_loss: 9.818724.. \tValid_loss: 6.148767.. \tAccuracy: 72.12%\n",
            "Epochs: 810.. \tTraining_loss: 10.440669.. \tValid_loss: 5.758462.. \tAccuracy: 75.96%\n",
            "Epochs: 811.. \tTraining_loss: 10.485757.. \tValid_loss: 5.819260.. \tAccuracy: 71.15%\n",
            "Epochs: 812.. \tTraining_loss: 9.251493.. \tValid_loss: 5.972047.. \tAccuracy: 72.12%\n",
            "Epochs: 813.. \tTraining_loss: 9.215346.. \tValid_loss: 5.984885.. \tAccuracy: 71.15%\n",
            "Epochs: 814.. \tTraining_loss: 10.277790.. \tValid_loss: 5.586857.. \tAccuracy: 69.23%\n",
            "Epochs: 815.. \tTraining_loss: 9.978771.. \tValid_loss: 5.546931.. \tAccuracy: 73.08%\n",
            "Epochs: 816.. \tTraining_loss: 8.857983.. \tValid_loss: 4.947129.. \tAccuracy: 75.00%\n",
            "Epochs: 817.. \tTraining_loss: 9.220708.. \tValid_loss: 6.025275.. \tAccuracy: 70.19%\n",
            "Epochs: 818.. \tTraining_loss: 9.802307.. \tValid_loss: 5.541145.. \tAccuracy: 71.15%\n",
            "Epochs: 819.. \tTraining_loss: 9.397547.. \tValid_loss: 6.347103.. \tAccuracy: 67.31%\n",
            "Epochs: 820.. \tTraining_loss: 9.278457.. \tValid_loss: 4.725026.. \tAccuracy: 77.88%\n",
            "Epochs: 821.. \tTraining_loss: 10.215406.. \tValid_loss: 5.361302.. \tAccuracy: 74.04%\n",
            "Epochs: 822.. \tTraining_loss: 9.988772.. \tValid_loss: 4.216150.. \tAccuracy: 75.00%\n",
            "Epochs: 823.. \tTraining_loss: 9.977203.. \tValid_loss: 4.832786.. \tAccuracy: 75.96%\n",
            "Epochs: 824.. \tTraining_loss: 9.609491.. \tValid_loss: 6.629838.. \tAccuracy: 70.19%\n",
            "Epochs: 825.. \tTraining_loss: 8.186677.. \tValid_loss: 6.182155.. \tAccuracy: 73.08%\n",
            "Epochs: 826.. \tTraining_loss: 9.437141.. \tValid_loss: 6.699859.. \tAccuracy: 75.00%\n",
            "Epochs: 827.. \tTraining_loss: 8.532130.. \tValid_loss: 5.400381.. \tAccuracy: 71.15%\n",
            "Epochs: 828.. \tTraining_loss: 8.748810.. \tValid_loss: 5.232955.. \tAccuracy: 75.96%\n",
            "Epochs: 829.. \tTraining_loss: 9.079899.. \tValid_loss: 5.628236.. \tAccuracy: 74.04%\n",
            "Epochs: 830.. \tTraining_loss: 8.983647.. \tValid_loss: 6.117225.. \tAccuracy: 70.19%\n",
            "Epochs: 831.. \tTraining_loss: 9.533772.. \tValid_loss: 4.850177.. \tAccuracy: 76.92%\n",
            "Epochs: 832.. \tTraining_loss: 8.543090.. \tValid_loss: 5.935947.. \tAccuracy: 70.19%\n",
            "Epochs: 833.. \tTraining_loss: 8.975465.. \tValid_loss: 6.102450.. \tAccuracy: 74.04%\n",
            "Epochs: 834.. \tTraining_loss: 10.542856.. \tValid_loss: 5.153591.. \tAccuracy: 75.96%\n",
            "Epochs: 835.. \tTraining_loss: 8.776913.. \tValid_loss: 6.315365.. \tAccuracy: 67.31%\n",
            "Epochs: 836.. \tTraining_loss: 8.842312.. \tValid_loss: 5.945543.. \tAccuracy: 75.96%\n",
            "Epochs: 837.. \tTraining_loss: 8.009163.. \tValid_loss: 6.776882.. \tAccuracy: 67.31%\n",
            "Epochs: 838.. \tTraining_loss: 8.643649.. \tValid_loss: 5.897296.. \tAccuracy: 73.08%\n",
            "Epochs: 839.. \tTraining_loss: 9.919148.. \tValid_loss: 5.315529.. \tAccuracy: 70.19%\n",
            "Epochs: 840.. \tTraining_loss: 8.695319.. \tValid_loss: 6.089104.. \tAccuracy: 75.96%\n",
            "Epochs: 841.. \tTraining_loss: 9.825044.. \tValid_loss: 5.154043.. \tAccuracy: 77.88%\n",
            "Epochs: 842.. \tTraining_loss: 8.193405.. \tValid_loss: 6.033653.. \tAccuracy: 72.12%\n",
            "Epochs: 843.. \tTraining_loss: 8.115731.. \tValid_loss: 5.783833.. \tAccuracy: 75.00%\n",
            "Epochs: 844.. \tTraining_loss: 9.053972.. \tValid_loss: 6.290313.. \tAccuracy: 71.15%\n",
            "Epochs: 845.. \tTraining_loss: 9.489644.. \tValid_loss: 5.313080.. \tAccuracy: 72.12%\n",
            "Epochs: 846.. \tTraining_loss: 8.891183.. \tValid_loss: 6.001454.. \tAccuracy: 69.23%\n",
            "Epochs: 847.. \tTraining_loss: 8.212387.. \tValid_loss: 5.522973.. \tAccuracy: 75.96%\n",
            "Epochs: 848.. \tTraining_loss: 9.595350.. \tValid_loss: 5.722505.. \tAccuracy: 77.88%\n",
            "Epochs: 849.. \tTraining_loss: 8.488779.. \tValid_loss: 6.293585.. \tAccuracy: 74.04%\n",
            "Epochs: 850.. \tTraining_loss: 9.538512.. \tValid_loss: 5.508530.. \tAccuracy: 76.92%\n",
            "Epochs: 851.. \tTraining_loss: 8.485737.. \tValid_loss: 6.633818.. \tAccuracy: 73.08%\n",
            "Epochs: 852.. \tTraining_loss: 9.859971.. \tValid_loss: 5.856854.. \tAccuracy: 68.27%\n",
            "Epochs: 853.. \tTraining_loss: 8.984417.. \tValid_loss: 6.332579.. \tAccuracy: 71.15%\n",
            "Epochs: 854.. \tTraining_loss: 9.139551.. \tValid_loss: 5.158212.. \tAccuracy: 73.08%\n",
            "Epochs: 855.. \tTraining_loss: 10.290760.. \tValid_loss: 6.325259.. \tAccuracy: 69.23%\n",
            "Epochs: 856.. \tTraining_loss: 8.043338.. \tValid_loss: 6.853186.. \tAccuracy: 72.12%\n",
            "Epochs: 857.. \tTraining_loss: 8.188592.. \tValid_loss: 6.101319.. \tAccuracy: 70.19%\n",
            "Epochs: 858.. \tTraining_loss: 9.805375.. \tValid_loss: 6.229588.. \tAccuracy: 70.19%\n",
            "Epochs: 859.. \tTraining_loss: 10.054547.. \tValid_loss: 5.732712.. \tAccuracy: 72.12%\n",
            "Epochs: 860.. \tTraining_loss: 9.102937.. \tValid_loss: 5.426975.. \tAccuracy: 73.08%\n",
            "Epochs: 861.. \tTraining_loss: 7.881898.. \tValid_loss: 7.031595.. \tAccuracy: 68.27%\n",
            "Epochs: 862.. \tTraining_loss: 9.669206.. \tValid_loss: 6.087190.. \tAccuracy: 71.15%\n",
            "Epochs: 863.. \tTraining_loss: 8.651271.. \tValid_loss: 5.408453.. \tAccuracy: 69.23%\n",
            "Epochs: 864.. \tTraining_loss: 8.555402.. \tValid_loss: 5.479929.. \tAccuracy: 73.08%\n",
            "Epochs: 865.. \tTraining_loss: 10.129151.. \tValid_loss: 5.958007.. \tAccuracy: 74.04%\n",
            "Epochs: 866.. \tTraining_loss: 9.591950.. \tValid_loss: 7.024490.. \tAccuracy: 68.27%\n",
            "Epochs: 867.. \tTraining_loss: 8.782906.. \tValid_loss: 7.638989.. \tAccuracy: 71.15%\n",
            "Epochs: 868.. \tTraining_loss: 9.505344.. \tValid_loss: 5.241910.. \tAccuracy: 74.04%\n",
            "Epochs: 869.. \tTraining_loss: 8.804047.. \tValid_loss: 5.405307.. \tAccuracy: 72.12%\n",
            "Epochs: 870.. \tTraining_loss: 9.163202.. \tValid_loss: 4.946479.. \tAccuracy: 76.92%\n",
            "Epochs: 871.. \tTraining_loss: 9.306671.. \tValid_loss: 6.622481.. \tAccuracy: 68.27%\n",
            "Epochs: 872.. \tTraining_loss: 8.124741.. \tValid_loss: 5.842856.. \tAccuracy: 71.15%\n",
            "Epochs: 873.. \tTraining_loss: 9.403307.. \tValid_loss: 6.165460.. \tAccuracy: 75.00%\n",
            "Epochs: 874.. \tTraining_loss: 8.457561.. \tValid_loss: 6.210349.. \tAccuracy: 71.15%\n",
            "Epochs: 875.. \tTraining_loss: 9.683366.. \tValid_loss: 6.764048.. \tAccuracy: 72.12%\n",
            "Epochs: 876.. \tTraining_loss: 9.000562.. \tValid_loss: 6.684277.. \tAccuracy: 66.35%\n",
            "Epochs: 877.. \tTraining_loss: 9.030696.. \tValid_loss: 6.110714.. \tAccuracy: 70.19%\n",
            "Epochs: 878.. \tTraining_loss: 9.003261.. \tValid_loss: 6.051552.. \tAccuracy: 71.15%\n",
            "Epochs: 879.. \tTraining_loss: 7.307382.. \tValid_loss: 5.501946.. \tAccuracy: 75.96%\n",
            "Epochs: 880.. \tTraining_loss: 9.099480.. \tValid_loss: 6.444142.. \tAccuracy: 75.00%\n",
            "Epochs: 881.. \tTraining_loss: 7.828100.. \tValid_loss: 5.173988.. \tAccuracy: 73.08%\n",
            "Epochs: 882.. \tTraining_loss: 9.060517.. \tValid_loss: 6.785837.. \tAccuracy: 67.31%\n",
            "Epochs: 883.. \tTraining_loss: 7.813581.. \tValid_loss: 5.208690.. \tAccuracy: 76.92%\n",
            "Epochs: 884.. \tTraining_loss: 8.775649.. \tValid_loss: 5.068036.. \tAccuracy: 74.04%\n",
            "Epochs: 885.. \tTraining_loss: 9.158063.. \tValid_loss: 5.743532.. \tAccuracy: 68.27%\n",
            "Epochs: 886.. \tTraining_loss: 7.954636.. \tValid_loss: 5.481139.. \tAccuracy: 74.04%\n",
            "Epochs: 887.. \tTraining_loss: 8.673899.. \tValid_loss: 6.252898.. \tAccuracy: 69.23%\n",
            "Epochs: 888.. \tTraining_loss: 8.672805.. \tValid_loss: 5.808022.. \tAccuracy: 70.19%\n",
            "Epochs: 889.. \tTraining_loss: 8.308602.. \tValid_loss: 6.000084.. \tAccuracy: 70.19%\n",
            "Epochs: 890.. \tTraining_loss: 8.368530.. \tValid_loss: 6.300543.. \tAccuracy: 72.12%\n",
            "Epochs: 891.. \tTraining_loss: 8.084550.. \tValid_loss: 6.098959.. \tAccuracy: 76.92%\n",
            "Epochs: 892.. \tTraining_loss: 9.141011.. \tValid_loss: 5.215303.. \tAccuracy: 73.08%\n",
            "Epochs: 893.. \tTraining_loss: 7.973672.. \tValid_loss: 6.133991.. \tAccuracy: 67.31%\n",
            "Epochs: 894.. \tTraining_loss: 7.930822.. \tValid_loss: 5.694932.. \tAccuracy: 73.08%\n",
            "Epochs: 895.. \tTraining_loss: 8.225531.. \tValid_loss: 5.960666.. \tAccuracy: 69.23%\n",
            "Epochs: 896.. \tTraining_loss: 9.442540.. \tValid_loss: 5.919953.. \tAccuracy: 66.35%\n",
            "Epochs: 897.. \tTraining_loss: 7.524619.. \tValid_loss: 5.942379.. \tAccuracy: 71.15%\n",
            "Epochs: 898.. \tTraining_loss: 9.279167.. \tValid_loss: 6.188334.. \tAccuracy: 72.12%\n",
            "Epochs: 899.. \tTraining_loss: 9.549809.. \tValid_loss: 6.327885.. \tAccuracy: 66.35%\n",
            "Epochs: 900.. \tTraining_loss: 8.863636.. \tValid_loss: 5.471285.. \tAccuracy: 72.12%\n",
            "Epochs: 901.. \tTraining_loss: 9.464198.. \tValid_loss: 6.441955.. \tAccuracy: 72.12%\n",
            "Epochs: 902.. \tTraining_loss: 8.171453.. \tValid_loss: 6.104027.. \tAccuracy: 70.19%\n",
            "Epochs: 903.. \tTraining_loss: 8.625714.. \tValid_loss: 5.304107.. \tAccuracy: 73.08%\n",
            "Epochs: 904.. \tTraining_loss: 8.702632.. \tValid_loss: 5.167177.. \tAccuracy: 75.96%\n",
            "Epochs: 905.. \tTraining_loss: 8.916730.. \tValid_loss: 6.187517.. \tAccuracy: 71.15%\n",
            "Epochs: 906.. \tTraining_loss: 8.203668.. \tValid_loss: 5.630099.. \tAccuracy: 75.96%\n",
            "Epochs: 907.. \tTraining_loss: 8.012933.. \tValid_loss: 6.511565.. \tAccuracy: 69.23%\n",
            "Epochs: 908.. \tTraining_loss: 8.235338.. \tValid_loss: 6.465990.. \tAccuracy: 65.38%\n",
            "Epochs: 909.. \tTraining_loss: 9.238634.. \tValid_loss: 5.682358.. \tAccuracy: 72.12%\n",
            "Epochs: 910.. \tTraining_loss: 9.122268.. \tValid_loss: 5.862519.. \tAccuracy: 73.08%\n",
            "Epochs: 911.. \tTraining_loss: 7.621879.. \tValid_loss: 5.312693.. \tAccuracy: 77.88%\n",
            "Epochs: 912.. \tTraining_loss: 8.953690.. \tValid_loss: 5.255577.. \tAccuracy: 77.88%\n",
            "Epochs: 913.. \tTraining_loss: 8.290429.. \tValid_loss: 4.982789.. \tAccuracy: 74.04%\n",
            "Epochs: 914.. \tTraining_loss: 9.659862.. \tValid_loss: 6.077032.. \tAccuracy: 69.23%\n",
            "Epochs: 915.. \tTraining_loss: 8.250800.. \tValid_loss: 6.002166.. \tAccuracy: 69.23%\n",
            "Epochs: 916.. \tTraining_loss: 9.047657.. \tValid_loss: 6.438885.. \tAccuracy: 72.12%\n",
            "Epochs: 917.. \tTraining_loss: 8.817714.. \tValid_loss: 5.579863.. \tAccuracy: 73.08%\n",
            "Epochs: 918.. \tTraining_loss: 9.864401.. \tValid_loss: 5.586185.. \tAccuracy: 75.00%\n",
            "Epochs: 919.. \tTraining_loss: 8.211518.. \tValid_loss: 5.670859.. \tAccuracy: 68.27%\n",
            "Epochs: 920.. \tTraining_loss: 8.298312.. \tValid_loss: 6.041136.. \tAccuracy: 74.04%\n",
            "Epochs: 921.. \tTraining_loss: 8.973625.. \tValid_loss: 5.856774.. \tAccuracy: 72.12%\n",
            "Epochs: 922.. \tTraining_loss: 8.369580.. \tValid_loss: 6.791031.. \tAccuracy: 71.15%\n",
            "Epochs: 923.. \tTraining_loss: 7.865521.. \tValid_loss: 5.863990.. \tAccuracy: 78.85%\n",
            "Epochs: 924.. \tTraining_loss: 9.126128.. \tValid_loss: 5.495058.. \tAccuracy: 73.08%\n",
            "Epochs: 925.. \tTraining_loss: 9.492785.. \tValid_loss: 5.511918.. \tAccuracy: 69.23%\n",
            "Epochs: 926.. \tTraining_loss: 9.822697.. \tValid_loss: 5.767263.. \tAccuracy: 74.04%\n",
            "Epochs: 927.. \tTraining_loss: 8.883182.. \tValid_loss: 6.136096.. \tAccuracy: 74.04%\n",
            "Epochs: 928.. \tTraining_loss: 8.379009.. \tValid_loss: 6.664887.. \tAccuracy: 70.19%\n",
            "Epochs: 929.. \tTraining_loss: 9.345113.. \tValid_loss: 5.589170.. \tAccuracy: 75.96%\n",
            "Epochs: 930.. \tTraining_loss: 9.235790.. \tValid_loss: 6.475910.. \tAccuracy: 72.12%\n",
            "Epochs: 931.. \tTraining_loss: 8.913199.. \tValid_loss: 6.912939.. \tAccuracy: 72.12%\n",
            "Epochs: 932.. \tTraining_loss: 9.720743.. \tValid_loss: 5.781213.. \tAccuracy: 69.23%\n",
            "Epochs: 933.. \tTraining_loss: 7.975058.. \tValid_loss: 6.029981.. \tAccuracy: 77.88%\n",
            "Epochs: 934.. \tTraining_loss: 8.590983.. \tValid_loss: 6.247962.. \tAccuracy: 72.12%\n",
            "Epochs: 935.. \tTraining_loss: 8.498593.. \tValid_loss: 6.192333.. \tAccuracy: 67.31%\n",
            "Epochs: 936.. \tTraining_loss: 7.253235.. \tValid_loss: 5.843747.. \tAccuracy: 69.23%\n",
            "Epochs: 937.. \tTraining_loss: 8.236987.. \tValid_loss: 6.213709.. \tAccuracy: 72.12%\n",
            "Epochs: 938.. \tTraining_loss: 8.921985.. \tValid_loss: 6.321340.. \tAccuracy: 72.12%\n",
            "Epochs: 939.. \tTraining_loss: 8.559229.. \tValid_loss: 4.837924.. \tAccuracy: 74.04%\n",
            "Epochs: 940.. \tTraining_loss: 8.872006.. \tValid_loss: 5.781199.. \tAccuracy: 76.92%\n",
            "Epochs: 941.. \tTraining_loss: 7.344961.. \tValid_loss: 6.436274.. \tAccuracy: 72.12%\n",
            "Epochs: 942.. \tTraining_loss: 7.246730.. \tValid_loss: 5.877463.. \tAccuracy: 73.08%\n",
            "Epochs: 943.. \tTraining_loss: 7.479745.. \tValid_loss: 5.070526.. \tAccuracy: 75.00%\n",
            "Epochs: 944.. \tTraining_loss: 8.416634.. \tValid_loss: 6.142028.. \tAccuracy: 70.19%\n",
            "Epochs: 945.. \tTraining_loss: 7.747195.. \tValid_loss: 6.034163.. \tAccuracy: 69.23%\n",
            "Epochs: 946.. \tTraining_loss: 7.747990.. \tValid_loss: 5.188140.. \tAccuracy: 73.08%\n",
            "Epochs: 947.. \tTraining_loss: 8.079898.. \tValid_loss: 5.887063.. \tAccuracy: 69.23%\n",
            "Epochs: 948.. \tTraining_loss: 9.114606.. \tValid_loss: 5.709790.. \tAccuracy: 68.27%\n",
            "Epochs: 949.. \tTraining_loss: 9.057259.. \tValid_loss: 6.117538.. \tAccuracy: 71.15%\n",
            "Epochs: 950.. \tTraining_loss: 7.256965.. \tValid_loss: 5.715977.. \tAccuracy: 71.15%\n",
            "Epochs: 951.. \tTraining_loss: 7.979681.. \tValid_loss: 5.520625.. \tAccuracy: 68.27%\n",
            "Epochs: 952.. \tTraining_loss: 7.346763.. \tValid_loss: 6.240709.. \tAccuracy: 72.12%\n",
            "Epochs: 953.. \tTraining_loss: 7.802811.. \tValid_loss: 6.104133.. \tAccuracy: 71.15%\n",
            "Epochs: 954.. \tTraining_loss: 7.517080.. \tValid_loss: 6.463695.. \tAccuracy: 70.19%\n",
            "Epochs: 955.. \tTraining_loss: 8.400753.. \tValid_loss: 6.302481.. \tAccuracy: 67.31%\n",
            "Epochs: 956.. \tTraining_loss: 7.863529.. \tValid_loss: 6.351091.. \tAccuracy: 70.19%\n",
            "Epochs: 957.. \tTraining_loss: 7.166601.. \tValid_loss: 5.500688.. \tAccuracy: 71.15%\n",
            "Epochs: 958.. \tTraining_loss: 8.501010.. \tValid_loss: 6.092524.. \tAccuracy: 68.27%\n",
            "Epochs: 959.. \tTraining_loss: 8.842657.. \tValid_loss: 6.065178.. \tAccuracy: 72.12%\n",
            "Epochs: 960.. \tTraining_loss: 8.804090.. \tValid_loss: 5.699343.. \tAccuracy: 74.04%\n",
            "Epochs: 961.. \tTraining_loss: 7.267316.. \tValid_loss: 6.837033.. \tAccuracy: 71.15%\n",
            "Epochs: 962.. \tTraining_loss: 6.897948.. \tValid_loss: 6.943354.. \tAccuracy: 65.38%\n",
            "Epochs: 963.. \tTraining_loss: 8.821136.. \tValid_loss: 6.051436.. \tAccuracy: 75.00%\n",
            "Epochs: 964.. \tTraining_loss: 8.616181.. \tValid_loss: 6.361598.. \tAccuracy: 66.35%\n",
            "Epochs: 965.. \tTraining_loss: 8.652378.. \tValid_loss: 5.717007.. \tAccuracy: 69.23%\n",
            "Epochs: 966.. \tTraining_loss: 8.690255.. \tValid_loss: 6.805963.. \tAccuracy: 69.23%\n",
            "Epochs: 967.. \tTraining_loss: 8.172287.. \tValid_loss: 5.959343.. \tAccuracy: 74.04%\n",
            "Epochs: 968.. \tTraining_loss: 7.738964.. \tValid_loss: 4.808434.. \tAccuracy: 75.96%\n",
            "Epochs: 969.. \tTraining_loss: 8.675505.. \tValid_loss: 6.482232.. \tAccuracy: 65.38%\n",
            "Epochs: 970.. \tTraining_loss: 8.948546.. \tValid_loss: 5.587240.. \tAccuracy: 75.96%\n",
            "Epochs: 971.. \tTraining_loss: 9.282586.. \tValid_loss: 5.661930.. \tAccuracy: 75.00%\n",
            "Epochs: 972.. \tTraining_loss: 9.220279.. \tValid_loss: 5.960735.. \tAccuracy: 72.12%\n",
            "Epochs: 973.. \tTraining_loss: 8.998876.. \tValid_loss: 6.477736.. \tAccuracy: 70.19%\n",
            "Epochs: 974.. \tTraining_loss: 8.579598.. \tValid_loss: 5.751437.. \tAccuracy: 71.15%\n",
            "Epochs: 975.. \tTraining_loss: 8.341763.. \tValid_loss: 6.918126.. \tAccuracy: 67.31%\n",
            "Epochs: 976.. \tTraining_loss: 7.953109.. \tValid_loss: 5.589109.. \tAccuracy: 73.08%\n",
            "Epochs: 977.. \tTraining_loss: 7.180604.. \tValid_loss: 6.007427.. \tAccuracy: 75.00%\n",
            "Epochs: 978.. \tTraining_loss: 7.683014.. \tValid_loss: 5.472047.. \tAccuracy: 73.08%\n",
            "Epochs: 979.. \tTraining_loss: 7.916303.. \tValid_loss: 5.297488.. \tAccuracy: 73.08%\n",
            "Epochs: 980.. \tTraining_loss: 8.188437.. \tValid_loss: 4.781770.. \tAccuracy: 76.92%\n",
            "Epochs: 981.. \tTraining_loss: 7.888863.. \tValid_loss: 7.286748.. \tAccuracy: 67.31%\n",
            "Epochs: 982.. \tTraining_loss: 8.412861.. \tValid_loss: 6.226865.. \tAccuracy: 74.04%\n",
            "Epochs: 983.. \tTraining_loss: 9.210466.. \tValid_loss: 7.551310.. \tAccuracy: 67.31%\n",
            "Epochs: 984.. \tTraining_loss: 8.496480.. \tValid_loss: 5.749668.. \tAccuracy: 71.15%\n",
            "Epochs: 985.. \tTraining_loss: 7.524121.. \tValid_loss: 6.362486.. \tAccuracy: 71.15%\n",
            "Epochs: 986.. \tTraining_loss: 8.266259.. \tValid_loss: 6.634381.. \tAccuracy: 71.15%\n",
            "Epochs: 987.. \tTraining_loss: 7.867862.. \tValid_loss: 6.671379.. \tAccuracy: 72.12%\n",
            "Epochs: 988.. \tTraining_loss: 7.910397.. \tValid_loss: 5.371814.. \tAccuracy: 72.12%\n",
            "Epochs: 989.. \tTraining_loss: 7.981923.. \tValid_loss: 6.914565.. \tAccuracy: 70.19%\n",
            "Epochs: 990.. \tTraining_loss: 6.377635.. \tValid_loss: 5.645577.. \tAccuracy: 72.12%\n",
            "Epochs: 991.. \tTraining_loss: 8.339311.. \tValid_loss: 4.981952.. \tAccuracy: 74.04%\n",
            "Epochs: 992.. \tTraining_loss: 8.577579.. \tValid_loss: 5.999498.. \tAccuracy: 73.08%\n",
            "Epochs: 993.. \tTraining_loss: 8.814137.. \tValid_loss: 5.361015.. \tAccuracy: 77.88%\n",
            "Epochs: 994.. \tTraining_loss: 7.194820.. \tValid_loss: 6.010467.. \tAccuracy: 70.19%\n",
            "Epochs: 995.. \tTraining_loss: 7.418632.. \tValid_loss: 6.243227.. \tAccuracy: 75.00%\n",
            "Epochs: 996.. \tTraining_loss: 8.475469.. \tValid_loss: 5.458825.. \tAccuracy: 70.19%\n",
            "Epochs: 997.. \tTraining_loss: 7.800726.. \tValid_loss: 6.010499.. \tAccuracy: 68.27%\n",
            "Epochs: 998.. \tTraining_loss: 8.233446.. \tValid_loss: 6.511403.. \tAccuracy: 65.38%\n",
            "Epochs: 999.. \tTraining_loss: 7.678521.. \tValid_loss: 6.010451.. \tAccuracy: 71.15%\n"
          ]
        }
      ],
      "source": [
        "train(model, epochs, min_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "de154d7e-1447-455b-b4a7-28bd514bf366",
        "_uuid": "d11e3af8-2c8f-46d5-8b0f-269c38121410",
        "execution": {
          "iopub.execute_input": "2022-03-14T16:31:02.333657Z",
          "iopub.status.busy": "2022-03-14T16:31:02.333404Z",
          "iopub.status.idle": "2022-03-14T16:31:03.894833Z",
          "shell.execute_reply": "2022-03-14T16:31:03.894065Z",
          "shell.execute_reply.started": "2022-03-14T16:31:02.333627Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18b2mMlcEX8X",
        "outputId": "f499c2c6-0cd0-4421-8ab5-c13527877baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: Queen-Resized.. Confidence: 61.63%.. Ground Truth: bishop_resized\n",
            "Predicted Class: Rook-resize.. Confidence: 59.63%.. Ground Truth: Rook-resize\n",
            "Predicted Class: knight-resize.. Confidence: 96.19%.. Ground Truth: knight-resize\n",
            "Predicted Class: bishop_resized.. Confidence: 62.09%.. Ground Truth: bishop_resized\n",
            "Predicted Class: knight-resize.. Confidence: 94.50%.. Ground Truth: knight-resize\n",
            "Predicted Class: knight-resize.. Confidence: 99.34%.. Ground Truth: knight-resize\n",
            "Predicted Class: bishop_resized.. Confidence: 99.20%.. Ground Truth: bishop_resized\n",
            "Predicted Class: knight-resize.. Confidence: 98.30%.. Ground Truth: knight-resize\n",
            "Predicted Class: Rook-resize.. Confidence: 84.88%.. Ground Truth: Rook-resize\n",
            "Predicted Class: Rook-resize.. Confidence: 100.00%.. Ground Truth: Rook-resize\n",
            "Predicted Class: knight-resize.. Confidence: 84.41%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: pawn_resized.. Confidence: 97.93%.. Ground Truth: pawn_resized\n",
            "Predicted Class: knight-resize.. Confidence: 87.77%.. Ground Truth: knight-resize\n",
            "Predicted Class: Rook-resize.. Confidence: 97.53%.. Ground Truth: Rook-resize\n",
            "Predicted Class: knight-resize.. Confidence: 87.52%.. Ground Truth: knight-resize\n",
            "Predicted Class: Queen-Resized.. Confidence: 95.05%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: Rook-resize.. Confidence: 94.96%.. Ground Truth: Rook-resize\n",
            "Predicted Class: Queen-Resized.. Confidence: 77.01%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: Queen-Resized.. Confidence: 83.47%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: Queen-Resized.. Confidence: 56.48%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: Queen-Resized.. Confidence: 85.32%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: knight-resize.. Confidence: 71.51%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: knight-resize.. Confidence: 98.89%.. Ground Truth: knight-resize\n",
            "Predicted Class: knight-resize.. Confidence: 99.75%.. Ground Truth: knight-resize\n",
            "Predicted Class: Queen-Resized.. Confidence: 63.93%.. Ground Truth: Queen-Resized\n",
            "Predicted Class: Queen-Resized.. Confidence: 40.45%.. Ground Truth: pawn_resized\n",
            "Predicted Class: Rook-resize.. Confidence: 47.24%.. Ground Truth: bishop_resized\n",
            "\n",
            "\n",
            "Total Correct: 22/27\n",
            "Percentage Correct: 81.48%..\n"
          ]
        }
      ],
      "source": [
        "total_correct = 0\n",
        "count = 0\n",
        "classes = dataset.classes\n",
        "model.load_state_dict(torch.load('./chess.pt'))\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        yhat = model(images)\n",
        "        yhat = nn.Softmax(dim = 1)(yhat)\n",
        "        top_p, top_class = yhat.topk(1, dim = 1)\n",
        "        eq = top_class == labels.view(-1, 1)\n",
        "        # print(classes[top_class.item()])\n",
        "        total_correct += eq.sum().item()\n",
        "        \n",
        "        if count % 1 == 0:\n",
        "            print(\"Predicted Class: {}.. Confidence: {:.2f}%.. Ground Truth: {}\".format(classes[top_class.item()], top_p.item() * 100, classes[labels.item()]))\n",
        "        else:\n",
        "            print(f\"count%1 = {count % 1}\")\n",
        "        count += 1\n",
        "        \n",
        "print()\n",
        "print()\n",
        "print(\"Total Correct: {}/{}\".format(total_correct, len(test_data)))\n",
        "print(\"Percentage Correct: {:.2f}%..\".format((total_correct/len(test_data)) * 100))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = []\n",
        "test_labels = []\n",
        "for images, labels in test_loader_ordered:\n",
        "  images = images.to(device)\n",
        "  test_images.append(images)\n",
        "  labels = labels.to(device)\n",
        "  test_labels.append(labels)\n",
        "\n",
        "ind = 6\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  yp = model(test_images[ind])\n",
        "  yp = nn.Softmax(dim=1)(yp)\n",
        "  top_p, top_class = yp.topk(1, dim = 1)\n",
        "  print(classes[top_class.item()])\n",
        "  print(top_p*100)\n"
      ],
      "metadata": {
        "id": "lbwvJQilwJMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.array(test_loader.dataset)\n",
        "plt.imshow(np.array(t[ind][0][2]))"
      ],
      "metadata": {
        "id": "pPOn_6V-5P4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pmn2k39_OJt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(dataset.imgs[23][0])"
      ],
      "metadata": {
        "id": "V7l6uQfjOdQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img)"
      ],
      "metadata": {
        "id": "jZeF-YP70p7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "U27n0nOJAwGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52UyoHRdDD82"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}